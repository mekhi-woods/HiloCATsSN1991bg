{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMo1wBXMI6h2mfHG5b/LBhp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mekhi-woods/HiloCATsSN1991bg/blob/master/amadeus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OwP9smghsDpU"
      },
      "outputs": [],
      "source": [
        "# \"\"\" START UP \"\"\"\n",
        "# import os\n",
        "# import shutil\n",
        "# if os.path.exists('/content/HiloCATsSN1991bg') == True:\n",
        "#     shutil.rmtree('/content/HiloCATsSN1991bg')\n",
        "#     !git clone https://github.com/mekhi-woods/HiloCATsSN1991bg.git\n",
        "# else:\n",
        "#     !git clone https://github.com/mekhi-woods/HiloCATsSN1991bg.git\n",
        "\n",
        "# !pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple snpy\n",
        "# !pip install requests\n",
        "# !pip install sncosmo\n",
        "# !pip install iminuit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" IMPORTS \"\"\"\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "import snpy\n",
        "import shutil\n",
        "import sncosmo\n",
        "import requests\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import time as systime\n",
        "import matplotlib.pyplot as plt\n",
        "from zipfile import ZipFile\n",
        "from requests.auth import HTTPBasicAuth\n",
        "from HiloCATsSN1991bg.scripts import tns_redshifts\n",
        "from astropy.table import QTable, Table, Column\n",
        "from astropy import units as u"
      ],
      "metadata": {
        "id": "rlZU1P2htj5x"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" GLOBALS \"\"\"\n",
        "# TNS CREDINTIALS\n",
        "tns_bot_id, tns_bot_name, tns_bot_api_key = '73181', 'YSE_Bot1', '0d771345fa6b876a5bb99cd5042ab8b5ae91fc67'\n",
        "\n",
        "# PATHS\n",
        "ROOT_PATH = '/content/HiloCATsSN1991bg/'\n",
        "\n",
        "DATA_ATLAS = ROOT_PATH+'data/ATLAS/'\n",
        "DATA_ZTF = ROOT_PATH+'data/ZTF/'\n",
        "\n",
        "SNPY_ROOT = ROOT_PATH+'snpy/'\n",
        "SNPY_BURNS = SNPY_ROOT+'burns/'\n",
        "SNPY_BURNS_PLOTS = SNPY_BURNS+'plots/'\n",
        "SNPY_ATLAS = SNPY_ROOT+'atlas/'\n",
        "SNPY_ATLAS_PLOTS = SNPY_ATLAS+'plots/'\n",
        "SNPY_ATLAS_ASCII = SNPY_ATLAS+'ascii/'\n",
        "\n",
        "PLOTS_ROOT = ROOT_PATH+'plots/'\n",
        "\n",
        "PROB_CHILD_TXT = ROOT_PATH+'problem_children.txt'\n",
        "TNS_KEY_TXT = ROOT_PATH+'TNS_key.txt'\n"
      ],
      "metadata": {
        "id": "_QakJM19tnqE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" GENERAL \"\"\"\n",
        "def recover_dir():\n",
        "    directories = [ROOT_PATH,\n",
        "                   DATA_ATLAS,\n",
        "                   SNPY_ROOT, SNPY_BURNS, SNPY_BURNS_PLOTS,\n",
        "                   SNPY_ATLAS, SNPY_ATLAS_PLOTS, SNPY_ATLAS_ASCII,\n",
        "                   PLOTS_ROOT]\n",
        "    files = [PROB_CHILD_TXT, TNS_KEY_TXT]\n",
        "    for dir in directories:\n",
        "        if os.path.exists(dir) == False:\n",
        "            os.mkdir(dir)\n",
        "    for n_file in files:\n",
        "        if os.path.exists(n_file) == False:\n",
        "            with open(n_file, 'w') as f:\n",
        "                pass\n",
        "    return\n",
        "\n",
        "def TNS_details(ra, dec):\n",
        "    # Code from David\n",
        "    headers = tns_redshifts.build_tns_header(tns_bot_id, tns_bot_name)\n",
        "    tns_api_url = f\"https://www.wis-tns.org/api/get\"\n",
        "\n",
        "    # get the API URLs\n",
        "    search_tns_url = tns_redshifts.build_tns_url(tns_api_url, mode=\"search\")\n",
        "    get_tns_url = tns_redshifts.build_tns_url(tns_api_url, mode=\"get\")\n",
        "\n",
        "    search_data = tns_redshifts.build_tns_search_query_data(tns_bot_api_key, ra, dec)\n",
        "    transients = tns_redshifts.rate_limit_query_tns(search_data, headers, search_tns_url)\n",
        "\n",
        "    get_data = tns_redshifts.build_tns_get_query_data(tns_bot_api_key, transients[0])\n",
        "    transient_detail = tns_redshifts.rate_limit_query_tns(get_data, headers, get_tns_url)\n",
        "\n",
        "    return transient_detail\n",
        "\n",
        "def snpy_fit(path, objname, save_loc, plot_save_loc, fit_filters=None, skip_problems=False, use_saved=False, snpy_plots=True):\n",
        "    problem_children = handle_problem_children(state='READ') # Open problem children\n",
        "\n",
        "    if skip_problems and (objname in problem_children):\n",
        "        return None\n",
        "    else:\n",
        "        try:\n",
        "            if use_saved and os.path.exists(save_loc+objname+'_EBV_model2.snpy'):\n",
        "                n_s = snpy.get_sn(save_loc+objname+'_EBV_model2.snpy')\n",
        "            else:\n",
        "                n_s = snpy.get_sn(path)\n",
        "                n_s.choose_model('EBV_model2', stype='st')\n",
        "                n_s.set_restbands() # Auto pick appropriate rest-bands\n",
        "                n_s.fit(bands=fit_filters, dokcorr=True, k_stretch=False, reset_kcorrs=True, **{'mangle':1,'calibration':0})\n",
        "                n_s.save(save_loc+objname+'_EBV_model2.snpy')\n",
        "            if snpy_plots:\n",
        "                n_s.plot(outfile=plot_save_loc+objname+'_snpyplots.png')\n",
        "                plt.show()\n",
        "        except:\n",
        "            problem_children = np.append(problem_children, objname)\n",
        "            handle_problem_children(state='WRITE', problem_c=problem_children) # Commit problem children\n",
        "            return None\n",
        "\n",
        "    plt.close()\n",
        "    return {'mu': n_s.get_distmod(), 'z': n_s.z, 'st': n_s.st, 'Tmax': n_s.Tmax, 'EBVHost': n_s.EBVhost}\n",
        "\n",
        "def read_DR3(loc='/content/HiloCATsSN1991bg/DR3_fits.dat'):\n",
        "    data = np.genfromtxt(loc, dtype=str, skip_header=1)\n",
        "    dr3 = {}\n",
        "    for n in range(len(data[:, 0])):\n",
        "        dr3.update({data[:, 0][n]: {'st': float(data[:, 1][n]), 'e_st': float(data[:, 2][n]), 'z': float(data[:, 3][n]),\n",
        "                           'Tmax': float(data[:, 5][n]), 'e_Tmax': float(data[:, 6][n]),\n",
        "                           'EBVHost': float(data[:, 25][n]), 'e_EBVHost': float(data[:, 26][n])}})\n",
        "    return dr3\n",
        "\n",
        "def dict_unpacker(path, delimiter=', '):\n",
        "    with open(path, 'r') as f:\n",
        "        hdr = f.readline()[:-1].split(delimiter)\n",
        "\n",
        "    data = np.genfromtxt(path, delimiter=delimiter, dtype=str, skip_header=1)\n",
        "    temp_objs = {}\n",
        "    for i in range(len(data[:, 0])):\n",
        "        obj = data[:, 0][i]\n",
        "        temp_objs.update({obj: {}})\n",
        "        for j in range(len(hdr)):\n",
        "            temp_objs[obj].update({hdr[j]: data[i, j]})\n",
        "    return temp_objs\n",
        "\n",
        "def dict_packer(data_dict, save_loc, delimiter=', '):\n",
        "    catagories = list(data_dict[list(data_dict.keys())[0]].keys())\n",
        "    with open(save_loc, 'w') as f:\n",
        "        f.write('objname')\n",
        "        for category in catagories:\n",
        "            f.write(delimiter+category)\n",
        "        f.write('\\n')\n",
        "        for objname in data_dict:\n",
        "            f.write(objname)\n",
        "            for category in catagories:\n",
        "                f.write(delimiter+str(data_dict[objname][category]))\n",
        "            f.write('\\n')\n",
        "    return\n",
        "\n",
        "def handle_problem_children(state, problem_c=None):\n",
        "    if state == 'READ':\n",
        "        # Read problem children\n",
        "        problem_c = np.genfromtxt(PROB_CHILD_TXT, dtype=str)\n",
        "        return problem_c\n",
        "    elif state == 'WRITE':\n",
        "        # Write problem children\n",
        "        problem_c = np.unique(problem_c)\n",
        "        with open(PROB_CHILD_TXT, 'w') as f:\n",
        "            for c in problem_c:\n",
        "                f.write(c+'\\n')\n",
        "        return None\n",
        "    else:\n",
        "        raise Exception(\"Invalid state: '\"+state+\"' [READ/WRITE]\")\n",
        "\n"
      ],
      "metadata": {
        "id": "zsrqLqM4t0tX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" BURNS/CSP \"\"\"\n",
        "def burns_cspvdr3():\n",
        "    print('Fitting CSP data with SNooPy...')\n",
        "    # Get Chris Burns Data\n",
        "    objnames = np.genfromtxt('/content/HiloCATsSN1991bg/targetLists/91bglike_justnames.txt', dtype=str, delimiter=', ')\n",
        "\n",
        "    # Get CSP paths of Chris Burns Data\n",
        "    objpaths = []\n",
        "    for name in objnames:\n",
        "        if os.path.exists('/content/HiloCATsSN1991bg/data/CSPdata/SN'+name+'_snpy.txt'):\n",
        "            objpaths.append('/content/HiloCATsSN1991bg/data/CSPdata/SN'+name+'_snpy.txt')\n",
        "        else:\n",
        "            print(name, 'not found...')\n",
        "\n",
        "    objs = {}\n",
        "    for n in range(len(objpaths)):\n",
        "        tracker = '['+str(n+1)+'/'+str(len(objpaths))+']' # Purely cosmetic\n",
        "        objname = objpaths[n][39:-9]\n",
        "        temp_dict = snpy_fit(objpaths[n], objname, save_loc=SNPY_BURNS, plot_save_loc=SNPY_BURNS_PLOTS, skip_problems=True, use_saved=True, snpy_plots=False)\n",
        "        if temp_dict is not None:\n",
        "            print(tracker, objname, '\\t| mu:', temp_dict['mu'], 'z =', temp_dict['z'], 'st =', temp_dict['st'], 'Tmax =', temp_dict['Tmax'], 'EBVHost =', temp_dict['EBVHost'])\n",
        "            objs.update({objname: temp_dict})\n",
        "        else:\n",
        "            print(tracker, objname, '\\t| problem child, skipping...')\n",
        "\n",
        "    dict_packer(objs, SNPY_BURNS+'saved.txt', delimiter=', ') # Save data from fitting\n",
        "    return\n",
        "\n",
        "def burns_plotting(choice):\n",
        "    if 'reg_hist' in choice:\n",
        "        print('Ploting Histogram of SNooPy Fitting Parameters...')\n",
        "        data = np.genfromtxt(SNPY_ROOT+'saved.txt', dtype=str, delimiter=', ', skip_header=1)\n",
        "        objnames, st, Tmax, EBVHost = data[:, 0], data[:, 3].astype(float), data[:, 4].astype(float), data[:, 5].astype(float)\n",
        "        reg_params = [st, Tmax, EBVHost]\n",
        "        bins_reg = [15, 20, 15]\n",
        "        plot_title = 'CSP SNooPy Parameters'\n",
        "\n",
        "        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
        "        titles = ['st', plot_title+'\\nTmax', 'EBVhost']\n",
        "        for i in range(len(titles)):\n",
        "            ax[i].hist(reg_params[i], bins=bins_reg[i])\n",
        "            ax[i].set_title(titles[i])\n",
        "        plt.show()\n",
        "\n",
        "    if 'res_hist' in choice:\n",
        "        print('Ploting Histogram of SNooPy-Chris Burns Parameters Residuals...')\n",
        "        data = np.genfromtxt(SNPY_ROOT+'saved.txt', dtype=str, delimiter=', ', skip_header=1)\n",
        "        objnames, st, Tmax, EBVHost = data[:, 0], data[:, 3].astype(float), data[:, 4].astype(float), data[:, 5].astype(float)\n",
        "\n",
        "        st_res, Tmax_res, EBVHost_res = [], [], []\n",
        "        dr3 = read_DR3()\n",
        "        for n in range(len(objnames)):\n",
        "            if objnames[n] in dr3:\n",
        "                st_res.append(st[n] - dr3[objnames[n]]['st'])\n",
        "                Tmax_res.append(Tmax[n] - dr3[objnames[n]]['Tmax'])\n",
        "                EBVHost_res.append(EBVHost[n] - dr3[objnames[n]]['EBVHost'])\\\n",
        "\n",
        "        res_params = [st_res, Tmax_res, EBVHost_res]\n",
        "        bins_res = [30, 50, 20]\n",
        "        plot_title = 'SNooPy-Chris Burns Parameters'\n",
        "\n",
        "        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
        "        titles = ['st', plot_title+'\\nTmax', 'EBVhost']\n",
        "        for i in range(len(titles)):\n",
        "            ax[i].hist(res_params[i], bins=bins_res[i])\n",
        "            ax[i].set_title(titles[i])\n",
        "        plt.show()\n",
        "\n",
        "    if 'zvmu' in choice:\n",
        "        print('Ploting redshift [z] vs distance mod [mu] of SNooPy Parameters...')\n",
        "        data = np.genfromtxt(SNPY_ROOT+'saved.txt', dtype=str, delimiter=', ', skip_header=1)\n",
        "        objnames, mu, z = data[:, 0], data[:, 1].astype(float), data[:, 2].astype(float)\n",
        "\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        for n in range(len(objnames)):\n",
        "            plt.loglog(z[n], mu[n], label=objnames[n], marker='o')\n",
        "        plt.title('CSP Redshift vs. Distance Mod\\n SNe # = '+str(len(objnames)))\n",
        "        plt.xlabel('Redshift')\n",
        "        plt.ylabel('Distance Mod')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "RCIf-58euEIX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" ATLAS \"\"\"\n",
        "def atlas_collection(quiet=False, check_data=True):\n",
        "    api_token = '7f4e1dee8f52cf0c8cdaf55bf29d04bef4810fb4'\n",
        "\n",
        "    if check_data and len(glob.glob(DATA_ATLAS+'*.txt')) > 1:\n",
        "        print('ATLAS data already collected, passing step...')\n",
        "        return\n",
        "    else:\n",
        "        print('No data detected, collecting ATLAS data...')\n",
        "        if os.path.exists(DATA_ATLAS+'tmp.npz'):\n",
        "            pickle = np.load(DATA_ATLAS+'tmp.npz', allow_pickle=True)\n",
        "            data = pickle['data']\n",
        "\n",
        "        data = requests.post('https://star.pst.qub.ac.uk/sne/atlas4/api/objectlist/',\n",
        "                             headers={'Authorization': f'Token {api_token}'},\n",
        "                             data={'objectlistid':2}).json()\n",
        "\n",
        "        np.savez(DATA_ATLAS+'tmp.npz', data=data)\n",
        "\n",
        "        count = 0\n",
        "        for d in data:\n",
        "            if d['observation_status'] is not None and d['observation_status'].startswith('SN Ia') and '91bg' in d['observation_status']:\n",
        "                count += 1\n",
        "                if not quiet:\n",
        "                    print(d['atlas_designation'],d['observation_status'].replace(' ',''),d['ra'],d['dec'])\n",
        "\n",
        "\n",
        "                ids = d['id']\n",
        "                base_url = 'https://star.pst.qub.ac.uk/sne/atlas4/lightcurveforced/1161048951013729300/'\n",
        "                new_url = base_url.replace('1161048951013729300/',str(ids))\n",
        "                if not quiet:\n",
        "                    print(new_url)\n",
        "\n",
        "                idfile = DATA_ATLAS+'/' + str(ids)+'.txt'\n",
        "                if os.path.exists(idfile):\n",
        "                    continue\n",
        "                urllib.request.urlretrieve(str(new_url), str(idfile))\n",
        "                if not quiet:\n",
        "                    print(idfile)\n",
        "\n",
        "            if count > 300:\n",
        "                break\n",
        "    return\n",
        "\n",
        "def atlas_processing(err_max=100, n_iter=10, sleep_t=5, use_TNS=False):\n",
        "    print('Retrieving data from...', DATA_ATLAS)\n",
        "    # Retrieve file paths\n",
        "    files = glob.glob(DATA_ATLAS+'/*.txt')\n",
        "    if n_iter != 0 and n_iter <= len(files):\n",
        "        files = files[:n_iter]\n",
        "\n",
        "    objs = {}\n",
        "    for n in range(len(files)):\n",
        "        # Tracking/Cosmetics\n",
        "        ATLAS_name = files[n][len(DATA_ATLAS):-4]\n",
        "        tracker = '['+str(n+1)+'/'+str(len(files))+']' # Purely cosmetic\n",
        "        print(tracker, '\\n', '\\t\\tPulling', ATLAS_name, 'data...')\n",
        "\n",
        "        # Reading file path\n",
        "        try:\n",
        "            data = np.genfromtxt(files[n], dtype=str, delimiter=',', skip_header=1)\n",
        "            if len(data) == 0: # Handling empty files\n",
        "                print('[!!!] \\t\\tFile '+ATLAS_name+' empty...skipping') # If empty, skips\n",
        "                continue\n",
        "        except:\n",
        "            print('[!!!] \\t\\tUnknown error, skipping...') # Numpy was doing a weird thing, so crash hander until i figure it out\n",
        "            continue\n",
        "        ra, dec = np.average(data[:, 1].astype(float)), np.average(data[:, 2].astype(float)) # Recoring RA & DEC (average of columns)\n",
        "\n",
        "        # Using TNS to get object name\n",
        "        objname = ATLAS_name\n",
        "        tns_sens = 0.1\n",
        "        z = 0.00000000001\n",
        "        if use_TNS:\n",
        "            try:\n",
        "                try:\n",
        "                    print('\\t\\tChecking TNS key for', ATLAS_name, 'details...')\n",
        "                    exsisting_tns = dict_unpacker(TNS_KEY_TXT)\n",
        "                    for obj in exsisting_tns:\n",
        "                        if abs(exsisting_tns[obj]['ra'] - ra) < tns_sens and abs(exsisting_tns[obj]['dec'] - dec) < tns_sens:\n",
        "                            print('\\t\\tFound details for', ATLAS_name)\n",
        "                            objname = obj\n",
        "                            z = exsisting_tns[obj]['z']\n",
        "                            break\n",
        "                except:\n",
        "                    print('\\t\\tRetrieving TNS data for...', ATLAS_name, '[sleeping for', sleep_t, 'seconds...]')\n",
        "                    systime.sleep(sleep_t)\n",
        "                    details = TNS_details(ra, dec)\n",
        "                    objname = details['objname']\n",
        "                    z = details['redshift']\n",
        "                    exsisting_tns.update({objname: {'ra': ra, 'dec': dec, 'z': z}})\n",
        "                    dict_packer(exsisting_tns, TNS_KEY_TXT)\n",
        "            except:\n",
        "                print('\\t\\tProblem retrieving TNS data, using ATLAS name...')\n",
        "\n",
        "        mag = np.char.replace(data[:, 3], '>', '') # Removes greater than symbols\n",
        "        dmag, filters, time, flux, dflux = data[:, 4], data[:, 6], data[:, 8], data[:, 24], data[:, 25] # Reads rest of categories\n",
        "        objs.update({objname: {'ra': ra, 'dec': dec, 'z': z, 'time': time, 'flux': flux, 'dflux': dflux, 'mag': mag, 'dmag': dmag, 'filters': filters}})\n",
        "\n",
        "        ## SLICING DATA\n",
        "        # ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "        # Remove 'None' from categories\n",
        "        mod_empty = np.array([])\n",
        "        for cat in ['time', 'flux', 'dflux', 'mag', 'dmag', 'filters']:\n",
        "            mod_empty = np.append(mod_empty, np.where(objs[objname][cat] == 'None')[0])\n",
        "        mod_empty = np.unique(mod_empty).astype(int) # Remove dupes\n",
        "        for cat in ['time', 'flux', 'dflux', 'mag', 'dmag', 'filters']:\n",
        "            objs[objname][cat] = np.delete(objs[objname][cat], mod_empty)\n",
        "\n",
        "        # Finds negative fluxes\n",
        "        mod_positive = np.array([])\n",
        "        for cat in ['time', 'flux', 'dflux', 'mag', 'dmag']:\n",
        "            mod_positive = np.append(mod_positive, np.where(objs[objname][cat].astype(float) <= 0)[0])\n",
        "        mod_positive = np.unique(mod_positive).astype(int) # Remove dupes\n",
        "        for cat in ['time', 'flux', 'dflux', 'mag', 'dmag', 'filters']:\n",
        "            objs[objname][cat] = np.delete(objs[objname][cat], mod_positive)\n",
        "\n",
        "        # Find outliers beyond error limit\n",
        "        mod_err = np.array([])\n",
        "        for cat in ['dflux', 'dmag']:\n",
        "            mod_err = np.append(mod_err, np.where(np.abs(objs[objname][cat].astype(float)) > err_max)[0])\n",
        "        mod_err = np.unique(mod_err).astype(int) # Remove dupes\n",
        "        for cat in ['time', 'flux', 'dflux', 'mag', 'dmag', 'filters']:\n",
        "            objs[objname][cat] = np.delete(objs[objname][cat], mod_err)\n",
        "\n",
        "        # Set everything as floats\n",
        "        for cat in ['time', 'flux', 'dflux', 'mag', 'dmag']:\n",
        "            objs[objname][cat] = objs[objname][cat].astype(float)\n",
        "\n",
        "        # Seperate into orange & cyan channels\n",
        "        for cat in ['time', 'flux', 'dflux', 'mag', 'dmag']:\n",
        "            objs[objname].update({cat+'_o': objs[objname][cat][np.where(objs[objname]['filters'] == 'o')[0]]})\n",
        "            objs[objname].update({cat+'_c': objs[objname][cat][np.where(objs[objname]['filters'] == 'c')[0]]})\n",
        "        # ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "        print('\\t\\tRetrived:', objname+' |', 'ra:', ra, '\\\\', 'dec:', dec)\n",
        "    print('[!!!]\\t\\tRetrieved & processed', len(objs), 'SNe from ATLAS!')\n",
        "    return objs\n",
        "\n",
        "def atlas_write_ASCII(atlas_objs, save_loc, quiet=True):\n",
        "    print('Saving data to ASCII files for SNooPy...')\n",
        "    for obj in atlas_objs:\n",
        "        with open(save_loc+obj+'_snpy.txt', 'w') as f:\n",
        "            # Line 1 -- Objname, Helio-Z, RA, Dec (Ex. SN1981D 0.005871 50.65992 -37.23272)\n",
        "            f.write(str(obj)+' '+str(atlas_objs[obj]['z'])+' '+str(atlas_objs[obj]['ra'])+' '+str(atlas_objs[obj]['dec'])+'\\n')\n",
        "\n",
        "            # 'o'/'ATri'-filter photometry block -- Date (JD/MJD), mag, err (674.8593 12.94 0.11)\n",
        "            f.write('filter ATri\\n')\n",
        "            for i in range(len(atlas_objs[obj]['time_o'])):\n",
        "                f.write(str(atlas_objs[obj]['time_o'][i])+'\\t'+str(atlas_objs[obj]['mag_o'][i])+'\\t'+str(atlas_objs[obj]['dmag_o'][i])+'\\n')\n",
        "\n",
        "            # # 'c'/'ATgr'-filter photometry block\n",
        "            f.write('filter ATgr\\n')\n",
        "            for i in range(len(atlas_objs[obj]['time_c'])):\n",
        "                f.write(str(atlas_objs[obj]['time_c'][i])+'\\t'+str(atlas_objs[obj]['mag_c'][i])+'\\t'+str(atlas_objs[obj]['dmag_c'][i])+'\\n')\n",
        "    return\n",
        "\n",
        "def atlas_snpy_fitting(skip_problems=True, use_saved=True, snpy_plots=True):\n",
        "    print('Fitting ATLAS data with SNooPy...')\n",
        "    objpaths = glob.glob(SNPY_ATLAS_ASCII+'*')\n",
        "    objs = {}\n",
        "    for n in range(len(objpaths)):\n",
        "        tracker = '['+str(n+1)+'/'+str(len(objpaths))+']' # Purely cosmetic\n",
        "        objname = objpaths[n][len(SNPY_ATLAS_ASCII):-9]\n",
        "        temp_dict = snpy_fit(objpaths[n], objname, save_loc=SNPY_ATLAS, plot_save_loc=SNPY_ATLAS_PLOTS, skip_problems=skip_problems, use_saved=use_saved, snpy_plots=snpy_plots)\n",
        "        if temp_dict is not None:\n",
        "            print(tracker, objname, '\\t| mu:', temp_dict['mu'], 'z =', temp_dict['z'], 'st =', temp_dict['st'], 'Tmax =', temp_dict['Tmax'], 'EBVHost =', temp_dict['EBVHost'])\n",
        "            objs.update({objname: temp_dict})\n",
        "        else:\n",
        "            print(tracker, objname, '\\t| problem child, skipping...')\n",
        "\n",
        "    dict_packer(objs, SNPY_ATLAS+'atlas_saved.txt', delimiter=', ') # Save data from fitting\n",
        "\n",
        "    return\n",
        "\n",
        "def atlas_plotting(choice):\n",
        "    if 'reg_hist' in choice:\n",
        "        print('Ploting Histogram of ATLAS SNooPy Fitting Parameters...')\n",
        "        data = np.genfromtxt(SNPY_ATLAS+'atlas_saved.txt', dtype=str, delimiter=', ', skip_header=1)\n",
        "        objnames, st, Tmax, EBVHost = data[:, 0], data[:, 3].astype(float), data[:, 4].astype(float), data[:, 5].astype(float)\n",
        "        reg_params = [st, Tmax, EBVHost]\n",
        "        bins_reg = [15, 20, 15]\n",
        "        plot_title = 'ATLAS SNooPy Parameters'\n",
        "\n",
        "        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
        "        titles = ['st', plot_title+'\\nTmax', 'EBVhost']\n",
        "        for i in range(len(titles)):\n",
        "            ax[i].hist(reg_params[i], bins=bins_reg[i])\n",
        "            ax[i].set_title(titles[i])\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "nMom96ltQcJ4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" MAIN \"\"\"\n",
        "if __name__ == '__main__':\n",
        "    start = systime.time() # Runtime tracker\n",
        "\n",
        "    recover_dir() # Recovering vital directories\n",
        "\n",
        "    # burns_cspvdr3()\n",
        "    # burns_plotting(['reg_hist', 'res_hist', 'zvmu']) # Options: ['reg_hist', 'res_hist', 'zvmu']\n",
        "\n",
        "    atlas_collection(quiet=False, check_data=True)\n",
        "    atlas_objs = atlas_processing(err_max=1000, n_iter=5, sleep_t=4, use_TNS=True)\n",
        "    # atlas_write_ASCII(atlas_objs, save_loc=SNPY_ATLAS_ASCII, quiet=False)\n",
        "    # atlas_snpy_fitting(skip_problems=True, use_saved=True, snpy_plots=False)\n",
        "    # atlas_plotting(['reg_hist'])\n",
        "\n",
        "    print('|---------------------------|\\n Run-time: ', round(systime.time()-start, 4), 'seconds\\n|---------------------------|')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO9qvltNuI9Y",
        "outputId": "f8962005-f040-461f-96d5-cf624bb993d2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ATLAS data already collected, passing step...\n",
            "Retrieving data from... /content/HiloCATsSN1991bg/data/ATLAS/\n",
            "[1/5] \n",
            " \t\tPulling 1122632231312545000 data...\n",
            "\t\tChecking TNS key for 1122632231312545000 details...\n",
            "\t\tRetrieving TNS data for... 1122632231312545000 [sleeping for 4 seconds...]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-4d11ba6a1bb3>:74: UserWarning: genfromtxt: Empty input file: \"/content/HiloCATsSN1991bg/TNS_key.txt\"\n",
            "  data = np.genfromtxt(path, delimiter=delimiter, dtype=str, skip_header=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tProblem retrieving TNS data, using ATLAS name...\n",
            "\t\tRetrived: 2021gel | ra: 186.63443073399623 \\ dec: 31.42834243488069\n",
            "[2/5] \n",
            " \t\tPulling 1141702841104919500 data...\n",
            "\t\tChecking TNS key for 1141702841104919500 details...\n",
            "\t\tRetrieving TNS data for... 1141702841104919500 [sleeping for 4 seconds...]\n",
            "\t\tProblem retrieving TNS data, using ATLAS name...\n",
            "\t\tRetrived: 2023omo | ra: 214.2615808939578 \\ dec: 10.821996814290793\n",
            "[3/5] \n",
            " \t\tPulling 1191628721415324300 data...\n",
            "\t\tChecking TNS key for 1191628721415324300 details...\n",
            "\t\tRetrieving TNS data for... 1191628721415324300 [sleeping for 4 seconds...]\n",
            "\t\tProblem retrieving TNS data, using ATLAS name...\n",
            "\t\tRetrived: 2022ubt | ra: 289.1201163647384 \\ dec: 41.889354239490345\n",
            "[4/5] \n",
            " \t\tPulling 1115510700075033500 data...\n",
            "\t\tChecking TNS key for 1115510700075033500 details...\n",
            "\t\tRetrieving TNS data for... 1115510700075033500 [sleeping for 4 seconds...]\n",
            "\t\tProblem retrieving TNS data, using ATLAS name...\n",
            "\t\tRetrived: 2021mab | ra: 178.79425241592884 \\ dec: -7.843156338771086\n",
            "[5/5] \n",
            " \t\tPulling 1234414950233145500 data...\n",
            "\t\tChecking TNS key for 1234414950233145500 details...\n",
            "\t\tRetrieving TNS data for... 1234414950233145500 [sleeping for 4 seconds...]\n",
            "\t\tProblem retrieving TNS data, using ATLAS name...\n",
            "\t\tRetrived: 2023sps | ra: 356.06325290770553 \\ dec: -23.52918120588744\n",
            "[!!!]\t\tRetrieved & processed 5 SNe from ATLAS!\n",
            "|---------------------------|\n",
            " Run-time:  27.9548 seconds\n",
            "|---------------------------|\n"
          ]
        }
      ]
    }
  ]
}