{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBiuwxlkS7OdTq3yAZLU9r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mekhi-woods/HiloCATsSN1991bg/blob/master/amadeus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "OwP9smghsDpU"
      },
      "outputs": [],
      "source": [
        "# \"\"\" START UP \"\"\"\n",
        "# import os\n",
        "# import shutil\n",
        "# if os.path.exists('/content/HiloCATsSN1991bg') == True:\n",
        "#     shutil.rmtree('/content/HiloCATsSN1991bg')\n",
        "#     !git clone https://github.com/mekhi-woods/HiloCATsSN1991bg.git\n",
        "# else:\n",
        "#     !git clone https://github.com/mekhi-woods/HiloCATsSN1991bg.git\n",
        "\n",
        "# !pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple snpy\n",
        "# !pip install requests\n",
        "# !pip install sncosmo\n",
        "# !pip install iminuit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" IMPORTS \"\"\"\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "import snpy\n",
        "import shutil\n",
        "import sncosmo\n",
        "import requests\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import time as systime\n",
        "import matplotlib.pyplot as plt\n",
        "from zipfile import ZipFile\n",
        "from requests.auth import HTTPBasicAuth\n",
        "from HiloCATsSN1991bg.scripts import tns_redshifts\n",
        "from astropy.table import QTable, Table, Column\n",
        "from astropy import units as u"
      ],
      "metadata": {
        "id": "rlZU1P2htj5x"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" GLOBALS \"\"\"\n",
        "# TNS CREDINTIALS\n",
        "tns_bot_id, tns_bot_name, tns_bot_api_key = '73181', 'YSE_Bot1', '0d771345fa6b876a5bb99cd5042ab8b5ae91fc67'\n",
        "\n",
        "# PATHS\n",
        "ROOT_PATH = '/content/HiloCATsSN1991bg/'\n",
        "SNPY_ROOT = ROOT_PATH+'snpy/'\n",
        "PLOTS_ROOT = ROOT_PATH+'plots/'\n",
        "TEST_ROOT = ROOT_PATH+'test/'\n",
        "\n",
        "SNPY_BURNS = SNPY_ROOT+'burns/'\n",
        "SNPY_BURNS_PLOTS = SNPY_BURNS+'plots/'\n",
        "BURNS_SAVE_TXT = SNPY_BURNS+'burns_saved.txt'\n",
        "\n",
        "DATA_ATLAS = ROOT_PATH+'data/ATLAS/'\n",
        "SNPY_ATLAS = SNPY_ROOT+'atlas/'\n",
        "SNPY_ATLAS_PLOTS = SNPY_ATLAS+'plots/'\n",
        "SNPY_ATLAS_ASCII = SNPY_ATLAS+'ascii/'\n",
        "ATLAS_SAVE_TXT = SNPY_ATLAS+'atlas_saved.txt'\n",
        "\n",
        "DATA_ZTF = ROOT_PATH+'data/ZTF/'\n",
        "\n",
        "\n",
        "PROB_CHILD_TXT = ROOT_PATH+'problem_children.txt'\n",
        "TNS_KEY_TXT = ROOT_PATH+'TNS_key.txt'\n"
      ],
      "metadata": {
        "id": "_QakJM19tnqE"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" GENERAL \"\"\"\n",
        "def recover_dir():\n",
        "    directories = [ROOT_PATH,\n",
        "                   DATA_ATLAS,\n",
        "                   SNPY_ROOT, SNPY_BURNS, SNPY_BURNS_PLOTS,\n",
        "                   SNPY_ATLAS, SNPY_ATLAS_PLOTS, SNPY_ATLAS_ASCII,\n",
        "                   PLOTS_ROOT, TEST_ROOT]\n",
        "    files = [PROB_CHILD_TXT, TNS_KEY_TXT,\n",
        "             BURNS_SAVE_TXT, ATLAS_SAVE_TXT]\n",
        "    for dir in directories:\n",
        "        if os.path.exists(dir) == False:\n",
        "            os.mkdir(dir)\n",
        "    for n_file in files:\n",
        "        if os.path.exists(n_file) == False:\n",
        "            with open(n_file, 'w') as f:\n",
        "                pass\n",
        "    return\n",
        "\n",
        "def TNS_details(ra, dec):\n",
        "    # Code from David\n",
        "    headers = tns_redshifts.build_tns_header(tns_bot_id, tns_bot_name)\n",
        "    tns_api_url = f\"https://www.wis-tns.org/api/get\"\n",
        "\n",
        "    # get the API URLs\n",
        "    search_tns_url = tns_redshifts.build_tns_url(tns_api_url, mode=\"search\")\n",
        "    get_tns_url = tns_redshifts.build_tns_url(tns_api_url, mode=\"get\")\n",
        "\n",
        "    search_data = tns_redshifts.build_tns_search_query_data(tns_bot_api_key, ra, dec)\n",
        "    transients = tns_redshifts.rate_limit_query_tns(search_data, headers, search_tns_url)\n",
        "\n",
        "    get_data = tns_redshifts.build_tns_get_query_data(tns_bot_api_key, transients[0])\n",
        "    transient_detail = tns_redshifts.rate_limit_query_tns(get_data, headers, get_tns_url)\n",
        "\n",
        "    return transient_detail\n",
        "\n",
        "def snpy_fit(path, objname, save_loc, plot_save_loc, fit_filters=None, skip_problems=False, use_saved=False, snpy_plots=True):\n",
        "    problem_children = handle_problem_children(state='READ') # Open problem children\n",
        "\n",
        "    if skip_problems and (objname in problem_children):\n",
        "        return None\n",
        "    else:\n",
        "        try:\n",
        "            if use_saved and os.path.exists(save_loc+objname+'_EBV_model2.snpy'):\n",
        "                n_s = snpy.get_sn(save_loc+objname+'_EBV_model2.snpy')\n",
        "            else:\n",
        "                n_s = snpy.get_sn(path)\n",
        "                n_s.choose_model('EBV_model2', stype='st')\n",
        "                n_s.set_restbands() # Auto pick appropriate rest-bands\n",
        "\n",
        "                # Sort out empty filters & get start and end time\n",
        "                mjds, mjde = [], []\n",
        "                filter_wheel = []\n",
        "                for filter in list(n_s.data.keys()):\n",
        "                    if len(n_s.data[filter].MJD) <= 3:\n",
        "                        print('\\t', objname, 'has too few points in', filter, 'filter')\n",
        "                        continue\n",
        "                    mjds.append(min(n_s.data[filter].MJD))\n",
        "                    mjde.append(max(n_s.data[filter].MJD))\n",
        "                    filter_wheel.append(filter)\n",
        "\n",
        "                n_s.fit(bands=filter_wheel, dokcorr=True, k_stretch=False, reset_kcorrs=True, **{'mangle':1,'calibration':0})\n",
        "                n_s.save(save_loc+objname+'_EBV_model2.snpy')\n",
        "\n",
        "            if snpy_plots:\n",
        "                n_s.plot(outfile=plot_save_loc+objname+'_snpyplots.png')\n",
        "                plt.show()\n",
        "        except:\n",
        "            problem_children = np.append(problem_children, objname)\n",
        "            handle_problem_children(state='WRITE', problem_c=problem_children) # Commit problem children\n",
        "            return None\n",
        "\n",
        "    plt.close()\n",
        "    return {'ra': n_s.ra, 'dec': n_s.decl, 'mu': n_s.get_distmod(), 'z': n_s.z, 'st': n_s.st, 'Tmax': n_s.Tmax, 'EBVHost': n_s.EBVhost, 'MJDs': min(mjds), 'MJDe': max(mjde)}\n",
        "\n",
        "def snpy_fit_indv(path, fit_filters=None, show_plot=True):\n",
        "    s = snpy.get_sn(path)\n",
        "    s.choose_model('EBV_model2', stype='st')\n",
        "    s.set_restbands() # Auto pick appropriate rest-bands\n",
        "    s.fit(bands=fit_filters, dokcorr=True, k_stretch=False, reset_kcorrs=True, **{'mangle':1,'calibration':0})\n",
        "    if show_plot:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close()\n",
        "    return {'mu': s.get_distmod(), 'z': s.z, 'st': s.st, 'Tmax': s.Tmax, 'EBVHost': s.EBVhost}, s\n",
        "\n",
        "def snpy_fit_comprehensive(path, objname, save_loc, plot_save_loc, fit_filters=None, skip_problems=False, use_saved=False, snpy_plots=True):\n",
        "    problem_children = handle_problem_children(state='READ') # Open problem children\n",
        "\n",
        "    if skip_problems and (objname in problem_children):\n",
        "        return None\n",
        "    else:\n",
        "        try:\n",
        "            if use_saved and os.path.exists(save_loc+objname+'_EBV_model2.snpy'):\n",
        "                n_s = snpy.get_sn(save_loc+objname+'_EBV_model2.snpy')\n",
        "            else:\n",
        "                n_s = snpy.get_sn(path)\n",
        "                n_s.choose_model('EBV_model2', stype='st')\n",
        "                n_s.set_restbands() # Auto pick appropriate rest-bands\n",
        "                n_s.fit(bands=fit_filters, dokcorr=True, k_stretch=False, reset_kcorrs=True, **{'mangle':1,'calibration':0})\n",
        "                n_s.save(save_loc+objname+'_EBV_model2.snpy')\n",
        "            if snpy_plots:\n",
        "                n_s.plot(outfile=plot_save_loc+objname+'_snpyplots.png')\n",
        "                plt.show()\n",
        "        except:\n",
        "            problem_children = np.append(problem_children, objname)\n",
        "            handle_problem_children(state='WRITE', problem_c=problem_children) # Commit problem children\n",
        "            return None\n",
        "\n",
        "    plt.close()\n",
        "    return {'mu': n_s.get_distmod(), 'z': n_s.z, 'st': n_s.st, 'Tmax': n_s.Tmax, 'EBVHost': n_s.EBVhost}\n",
        "\n",
        "def read_DR3(loc='/content/HiloCATsSN1991bg/DR3_fits.dat'):\n",
        "    data = np.genfromtxt(loc, dtype=str, skip_header=1)\n",
        "    dr3 = {}\n",
        "    for n in range(len(data[:, 0])):\n",
        "        dr3.update({data[:, 0][n]: {'st': float(data[:, 1][n]), 'e_st': float(data[:, 2][n]), 'z': float(data[:, 3][n]),\n",
        "                           'Tmax': float(data[:, 5][n]), 'e_Tmax': float(data[:, 6][n]),\n",
        "                           'EBVHost': float(data[:, 25][n]), 'e_EBVHost': float(data[:, 26][n])}})\n",
        "    return dr3\n",
        "\n",
        "def dict_unpacker(path, delimiter=', '):\n",
        "    with open(path, 'r') as f:\n",
        "        hdr = f.readline()[:-1].split(delimiter)\n",
        "\n",
        "    data = np.genfromtxt(path, delimiter=delimiter, dtype=str, skip_header=1)\n",
        "    temp_objs = {}\n",
        "    for i in range(len(data[:, 0])):\n",
        "        obj = data[:, 0][i]\n",
        "        temp_objs.update({obj: {}})\n",
        "        for j in range(len(hdr)):\n",
        "            temp_objs[obj].update({hdr[j]: data[i, j]})\n",
        "    return temp_objs\n",
        "\n",
        "def dict_packer(data_dict, save_loc, delimiter=', '):\n",
        "    catagories = list(data_dict[list(data_dict.keys())[0]].keys())\n",
        "    with open(save_loc, 'w') as f:\n",
        "        f.write('objname')\n",
        "        for category in catagories:\n",
        "            f.write(delimiter+category)\n",
        "        f.write('\\n')\n",
        "        for objname in data_dict:\n",
        "            f.write(objname)\n",
        "            for category in catagories:\n",
        "                f.write(delimiter+str(data_dict[objname][category]))\n",
        "            f.write('\\n')\n",
        "    return\n",
        "\n",
        "def handle_problem_children(state, problem_c=None):\n",
        "    if state == 'READ':\n",
        "        # Read problem children\n",
        "        problem_c = np.genfromtxt(PROB_CHILD_TXT, dtype=str)\n",
        "        return problem_c\n",
        "    elif state == 'WRITE':\n",
        "        # Write problem children\n",
        "        problem_c = np.unique(problem_c)\n",
        "        with open(PROB_CHILD_TXT, 'w') as f:\n",
        "            for c in problem_c:\n",
        "                f.write(c+'\\n')\n",
        "        return None\n",
        "    else:\n",
        "        raise Exception(\"Invalid state: '\"+state+\"' [READ/WRITE]\")\n",
        "\n"
      ],
      "metadata": {
        "id": "zsrqLqM4t0tX"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" ATLAS \"\"\"\n",
        "def atlas_collection(quiet=False, check_data=True):\n",
        "    api_token = '7f4e1dee8f52cf0c8cdaf55bf29d04bef4810fb4'\n",
        "\n",
        "    if check_data and len(glob.glob(DATA_ATLAS+'*.txt')) > 1:\n",
        "        print('ATLAS data already collected, passing step...')\n",
        "        return\n",
        "    else:\n",
        "        print('No data detected, collecting ATLAS data...')\n",
        "        if os.path.exists(DATA_ATLAS+'tmp.npz'):\n",
        "            pickle = np.load(DATA_ATLAS+'tmp.npz', allow_pickle=True)\n",
        "            data = pickle['data']\n",
        "\n",
        "        data = requests.post('https://star.pst.qub.ac.uk/sne/atlas4/api/objectlist/',\n",
        "                             headers={'Authorization': f'Token {api_token}'},\n",
        "                             data={'objectlistid':2}).json()\n",
        "\n",
        "        np.savez(DATA_ATLAS+'tmp.npz', data=data)\n",
        "\n",
        "        count = 0\n",
        "        for d in data:\n",
        "            if d['observation_status'] is not None and d['observation_status'].startswith('SN Ia') and '91bg' in d['observation_status']:\n",
        "                count += 1\n",
        "                if not quiet:\n",
        "                    print(d['atlas_designation'],d['observation_status'].replace(' ',''),d['ra'],d['dec'])\n",
        "\n",
        "\n",
        "                ids = d['id']\n",
        "                base_url = 'https://star.pst.qub.ac.uk/sne/atlas4/lightcurveforced/1161048951013729300/'\n",
        "                new_url = base_url.replace('1161048951013729300/',str(ids))\n",
        "                if not quiet:\n",
        "                    print(new_url)\n",
        "\n",
        "                idfile = DATA_ATLAS+'/' + str(ids)+'.txt'\n",
        "                if os.path.exists(idfile):\n",
        "                    continue\n",
        "                urllib.request.urlretrieve(str(new_url), str(idfile))\n",
        "                if not quiet:\n",
        "                    print(idfile)\n",
        "\n",
        "            if count > 300:\n",
        "                break\n",
        "    return\n",
        "\n",
        "def atlas_tns_collection(files, quiet=False, check_data=False):\n",
        "    for n in range(len(files)):\n",
        "        ATLAS_name = files[n][len(DATA_ATLAS):-4]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return\n",
        "\n",
        "def atlas_processing(err_max=100, n_iter=10, sleep_t=5, use_TNS=False):\n",
        "    print('Retrieving data from...', DATA_ATLAS)\n",
        "    # Retrieve file paths\n",
        "    files = glob.glob(DATA_ATLAS+'/*.txt')\n",
        "    if n_iter != 0 and n_iter <= len(files):\n",
        "        files = files[:n_iter]\n",
        "\n",
        "    # TNS name sort\n",
        "    atlas_tns_collection(files)\n",
        "\n",
        "\n",
        "    objs = {}\n",
        "    for n in range(len(files)):\n",
        "        # Tracking/Cosmetics\n",
        "        ATLAS_name = files[n][len(DATA_ATLAS):-4]\n",
        "        tracker = '['+str(n+1)+'/'+str(len(files))+']' # Purely cosmetic\n",
        "        print(tracker, '\\n', '\\t\\tPulling', ATLAS_name, 'data...')\n",
        "\n",
        "        # Reading file path\n",
        "        try:\n",
        "            data = np.genfromtxt(files[n], dtype=str, delimiter=',', skip_header=1)\n",
        "            if len(data) == 0: # Handling empty files\n",
        "                print('[!!!] \\t\\tFile '+ATLAS_name+' empty...skipping') # If empty, skips\n",
        "                continue\n",
        "        except:\n",
        "            print('[!!!] \\t\\tUnknown error, skipping...') # Numpy was doing a weird thing, so crash hander until i figure it out\n",
        "            continue\n",
        "        ra, dec = np.average(data[:, 1].astype(float)), np.average(data[:, 2].astype(float)) # Recoring RA & DEC (average of columns)\n",
        "\n",
        "        # Using TNS to get object name\n",
        "        objname = ATLAS_name\n",
        "        tns_sens = 0.1\n",
        "        z = 0.00000000001\n",
        "        if use_TNS:\n",
        "            try:\n",
        "                try:\n",
        "                    print('\\t\\tChecking TNS key for', ATLAS_name, 'details...')\n",
        "                    exsisting_tns = dict_unpacker(TNS_KEY_TXT)\n",
        "                    for obj in exsisting_tns:\n",
        "                        if abs(exsisting_tns[obj]['ra'] - ra) < tns_sens and abs(exsisting_tns[obj]['dec'] - dec) < tns_sens:\n",
        "                            print('\\t\\tFound details for', ATLAS_name)\n",
        "                            objname = obj\n",
        "                            z = exsisting_tns[obj]['z']\n",
        "                            break\n",
        "                except:\n",
        "                    print('\\t\\tRetrieving TNS data for...', ATLAS_name, '[sleeping for', sleep_t, 'seconds...]')\n",
        "                    systime.sleep(sleep_t)\n",
        "                    details = TNS_details(ra, dec)\n",
        "                    objname = details['objname']\n",
        "                    z = details['redshift']\n",
        "                    exsisting_tns.update({objname: {'ra': ra, 'dec': dec, 'z': z}})\n",
        "                    dict_packer(exsisting_tns, TNS_KEY_TXT)\n",
        "            except:\n",
        "                print('\\t\\tProblem retrieving TNS data, using ATLAS name...')\n",
        "\n",
        "        mag = np.char.replace(data[:, 3], '>', '') # Removes greater than symbols\n",
        "        dmag, filters, time, flux, dflux = data[:, 4], data[:, 6], data[:, 8], data[:, 24], data[:, 25] # Reads rest of categories\n",
        "        objs.update({objname: {'ra': ra, 'dec': dec, 'z': z, 'time': time, 'flux': flux, 'dflux': dflux, 'mag': mag, 'dmag': dmag, 'filters': filters}})\n",
        "\n",
        "        ## SLICING DATA\n",
        "        # ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "        # Remove 'None' from categories\n",
        "        mod_empty = np.array([])\n",
        "        for cat in ['time', 'flux', 'dflux', 'mag', 'dmag', 'filters']:\n",
        "            mod_empty = np.append(mod_empty, np.where(objs[objname][cat] == 'None')[0])\n",
        "        mod_empty = np.unique(mod_empty).astype(int) # Remove dupes\n",
        "        for cat in ['time', 'flux', 'dflux', 'mag', 'dmag', 'filters']:\n",
        "            objs[objname][cat] = np.delete(objs[objname][cat], mod_empty)\n",
        "\n",
        "        # Finds negative fluxes\n",
        "        mod_positive = np.array([])\n",
        "        for cat in ['time', 'flux', 'dflux', 'mag', 'dmag']:\n",
        "            mod_positive = np.append(mod_positive, np.where(objs[objname][cat].astype(float) <= 0)[0])\n",
        "        mod_positive = np.unique(mod_positive).astype(int) # Remove dupes\n",
        "        for cat in ['time', 'flux', 'dflux', 'mag', 'dmag', 'filters']:\n",
        "            objs[objname][cat] = np.delete(objs[objname][cat], mod_positive)\n",
        "\n",
        "        # Find outliers beyond error limit\n",
        "        mod_err = np.array([])\n",
        "        for cat in ['dflux', 'dmag']:\n",
        "            mod_err = np.append(mod_err, np.where(np.abs(objs[objname][cat].astype(float)) > err_max)[0])\n",
        "        mod_err = np.unique(mod_err).astype(int) # Remove dupes\n",
        "        for cat in ['time', 'flux', 'dflux', 'mag', 'dmag', 'filters']:\n",
        "            objs[objname][cat] = np.delete(objs[objname][cat], mod_err)\n",
        "\n",
        "        # Set everything as floats\n",
        "        for cat in ['time', 'flux', 'dflux', 'mag', 'dmag']:\n",
        "            objs[objname][cat] = objs[objname][cat].astype(float)\n",
        "\n",
        "        # Seperate into orange & cyan channels\n",
        "        for cat in ['time', 'flux', 'dflux', 'mag', 'dmag']:\n",
        "            objs[objname].update({cat+'_o': objs[objname][cat][np.where(objs[objname]['filters'] == 'o')[0]]})\n",
        "            objs[objname].update({cat+'_c': objs[objname][cat][np.where(objs[objname]['filters'] == 'c')[0]]})\n",
        "        # ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "        print('\\t\\tRetrived:', objname+' |', 'ra:', ra, '\\\\', 'dec:', dec)\n",
        "    print('[!!!]\\t\\tRetrieved & processed', len(objs), 'SNe from ATLAS!')\n",
        "    return objs\n",
        "\n",
        "def atlas_write_ASCII(atlas_objs, save_loc, quiet=True):\n",
        "    print('Saving data to ASCII files for SNooPy...')\n",
        "    for obj in atlas_objs:\n",
        "        with open(save_loc+obj+'_snpy.txt', 'w') as f:\n",
        "            # Line 1 -- Objname, Helio-Z, RA, Dec (Ex. SN1981D 0.005871 50.65992 -37.23272)\n",
        "            f.write(str(obj)+' '+str(atlas_objs[obj]['z'])+' '+str(atlas_objs[obj]['ra'])+' '+str(atlas_objs[obj]['dec'])+'\\n')\n",
        "\n",
        "            # 'o'/'ATri'-filter photometry block -- Date (JD/MJD), mag, err (674.8593 12.94 0.11)\n",
        "            f.write('filter ATri\\n')\n",
        "            for i in range(len(atlas_objs[obj]['time_o'])):\n",
        "                f.write(str(atlas_objs[obj]['time_o'][i])+'\\t'+str(atlas_objs[obj]['mag_o'][i])+'\\t'+str(atlas_objs[obj]['dmag_o'][i])+'\\n')\n",
        "\n",
        "            # # 'c'/'ATgr'-filter photometry block\n",
        "            f.write('filter ATgr\\n')\n",
        "            for i in range(len(atlas_objs[obj]['time_c'])):\n",
        "                f.write(str(atlas_objs[obj]['time_c'][i])+'\\t'+str(atlas_objs[obj]['mag_c'][i])+'\\t'+str(atlas_objs[obj]['dmag_c'][i])+'\\n')\n",
        "    return\n",
        "\n",
        "def atlas_snpy_fitting(skip_problems=True, use_saved=True, snpy_plots=True, fit_filters=None):\n",
        "    print('Fitting ATLAS data with SNooPy...')\n",
        "    fit_args = {'skip_problems': skip_problems, 'use_saved': use_saved, 'snpy_plots': snpy_plots, 'fit_filters': fit_filters}\n",
        "    print('Fitting arguments: ', fit_args)\n",
        "    objpaths = glob.glob(SNPY_ATLAS_ASCII+'*')\n",
        "    objs = {}\n",
        "    for n in range(len(objpaths)):\n",
        "        tracker = '['+str(n+1)+'/'+str(len(objpaths))+']' # Purely cosmetic\n",
        "        objname = objpaths[n][len(SNPY_ATLAS_ASCII):-9]\n",
        "        print(tracker, objname)\n",
        "        temp_dict = snpy_fit(objpaths[n], objname, save_loc=SNPY_ATLAS, plot_save_loc=SNPY_ATLAS_PLOTS, **fit_args)\n",
        "        if temp_dict is not None:\n",
        "            print('\\tResults: mu:', temp_dict['mu'], 'z =', temp_dict['z'], 'st =', temp_dict['st'], 'Tmax =', temp_dict['Tmax'], 'EBVHost =', temp_dict['EBVHost'])\n",
        "            print('\\tMJD min:', temp_dict['MJDs'], '+/- 100 MJD', '| MJD max:', temp_dict['MJDe'], '+/- 100 MJD')\n",
        "            objs.update({objname: temp_dict})\n",
        "        else:\n",
        "            print('[!!!]\\t'+objname+' is a problem child, skipping...')\n",
        "\n",
        "    dict_packer(objs, ATLAS_SAVE_TXT, delimiter=', ') # Save data from fitting\n",
        "\n",
        "    return\n",
        "\n",
        "def atlas_plotting(choice):\n",
        "    if 'reg_hist' in choice:\n",
        "        print('Ploting Histogram of ATLAS SNooPy Fitting Parameters...')\n",
        "        data = np.genfromtxt(SNPY_ATLAS+'atlas_saved.txt', dtype=str, delimiter=', ', skip_header=1)\n",
        "        objnames, st, Tmax, EBVHost = data[:, 0], data[:, 3].astype(float), data[:, 4].astype(float), data[:, 5].astype(float)\n",
        "        reg_params = [st, Tmax, EBVHost]\n",
        "        bins_reg = [15, 20, 15]\n",
        "        plot_title = 'ATLAS SNooPy Parameters'\n",
        "\n",
        "        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
        "        titles = ['st', plot_title+'\\nTmax', 'EBVhost']\n",
        "        for i in range(len(titles)):\n",
        "            ax[i].hist(reg_params[i], bins=bins_reg[i])\n",
        "            ax[i].set_title(titles[i])\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "nMom96ltQcJ4"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" ZTF \"\"\"\n",
        "def ztf_collection(submit=False, limit=1000):\n",
        "    objs = dict_unpacker(ATLAS_SAVE_TXT)\n",
        "    print(\"Number of targets =\", len(objs))\n",
        "    ralist, declist, jdslist, jdelist = [], [], [], []\n",
        "    i = 0\n",
        "    for obj in objs:\n",
        "        ralist.append(float(objs[obj]['ra']))\n",
        "        declist.append(float(objs[obj]['dec']))\n",
        "        jdslist.append(float(objs[obj]['MJDs'])-100)\n",
        "        jdelist.append(float(objs[obj]['MJDe'])+100)\n",
        "        i += 1\n",
        "        if i % limit == 0:\n",
        "            if submit:\n",
        "                ztf_submit_post(ralist, declist, jdslist, jdelist)\n",
        "            ralist, declist, jdslist, jdelist = [], [], [], []\n",
        "    if submit and len(ralist) > 0:\n",
        "        ztf_submit_post(ralist, declist, jdslist, jdelist)\n",
        "\n",
        "    return\n",
        "\n",
        "def ztf_submit_post(ra_list, dec_list, jds, jde):\n",
        "    print('Submiting request to ZTF...')\n",
        "\n",
        "    email = 'mekhidw@hawaii.edu' # email you subscribed with.\n",
        "    userpass = 'wxdk286' # password that was issued to you.\n",
        "\n",
        "    ra, dec = json.dumps(ra_list), json.dumps(dec_list)\n",
        "    jdend, jdstart = json.dumps(jde), json.dumps(jds)\n",
        "    payload = {'ra': ra, 'dec': dec, 'jdstart': jdstart, 'jdend': jdend, 'email': email, 'userpass': userpass}\n",
        "\n",
        "    # fixed IP address/URL where requests are submitted:\n",
        "    url = 'https://ztfweb.ipac.caltech.edu/cgi-bin/batchfp.py/submit'\n",
        "    r = requests.post(url, auth=('ztffps', 'dontgocrazy!'), data=payload)\n",
        "\n",
        "    print('RA ['+str(type(payload['ra'][0]))+']:', payload['ra'])\n",
        "    print('DEC ['+str(type(payload['dec'][0]))+']:', payload['dec'])\n",
        "    print('MJD Start ['+str(type(payload['jdstart'][0]))+']:', payload['jdstart'])\n",
        "    print('MJD End ['+str(type(payload['jdend'][0]))+']:', payload['jdend'])\n",
        "    print(\"Status_code=\", r.status_code)\n",
        "    return\n",
        "\n",
        "def ztf_alt_collection():\n",
        "    ra, dec, jds, jde = 186.07860833333334, 10.446222222222222, 2460350, 2460450\n",
        "\n",
        "    email = 'mekhidw@hawaii.edu' # email you subscribed with.\n",
        "    userpass = 'wxdk286' # password that was issued to you.\n",
        "\n",
        "    cmd = f\"wget --http-user=ztffps --http-passwd=dontgocrazy! -O log.txt \\\"https://ztfweb.ipac.caltech.edu/cgi-bin/requestForcedPhotometry.cgi?ra={dec}&dec={ra}&jdstart={jds}&jdend={jde}&email={email}&userpass={userpass}\\\"\"\n",
        "    print(cmd)\n",
        "    os.system(cmd)\n",
        "\n",
        "    return\n"
      ],
      "metadata": {
        "id": "th67irAgJGDB"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" BURNS/CSP \"\"\"\n",
        "def burns_cspvdr3(fit_filters=None, skip_problems=False, use_saved=False, snpy_plots=True):\n",
        "    print('Fitting CSP data with SNooPy...')\n",
        "    # Get Chris Burns Data\n",
        "    objnames = np.genfromtxt('/content/HiloCATsSN1991bg/targetLists/91bglike_justnames.txt', dtype=str, delimiter=', ')\n",
        "\n",
        "    # Get CSP paths of Chris Burns Data\n",
        "    objpaths = []\n",
        "    for name in objnames:\n",
        "        if os.path.exists('/content/HiloCATsSN1991bg/data/CSPdata/SN'+name+'_snpy.txt'):\n",
        "            objpaths.append('/content/HiloCATsSN1991bg/data/CSPdata/SN'+name+'_snpy.txt')\n",
        "        else:\n",
        "            print(name, 'not found...')\n",
        "\n",
        "    # Fitting\n",
        "    objs = {}\n",
        "    fit_args = {'skip_problems': skip_problems, 'use_saved': use_saved, 'snpy_plots': snpy_plots, 'fit_filters': fit_filters}\n",
        "    print('Fitting arguments: ', fit_args)\n",
        "    for n in range(len(objpaths)):\n",
        "        tracker = '['+str(n+1)+'/'+str(len(objpaths))+']' # Purely cosmetic\n",
        "        objname = objpaths[n][39:-9]\n",
        "        print(tracker, objname)\n",
        "        temp_dict = snpy_fit(objpaths[n], objname, save_loc=SNPY_BURNS, plot_save_loc=SNPY_BURNS_PLOTS, **fit_args)\n",
        "        if temp_dict is not None:\n",
        "            print('\\tResults: mu:', temp_dict['mu'], 'z =', temp_dict['z'], 'st =', temp_dict['st'], 'Tmax =', temp_dict['Tmax'], 'EBVHost =', temp_dict['EBVHost'])\n",
        "            print('\\tMJD min:', temp_dict['MJDs'], '+/- 100 MJD', '| MJD max:', temp_dict['MJDe'], '+/- 100 MJD')\n",
        "            objs.update({objname: temp_dict})\n",
        "        else:\n",
        "            print('[!!!]\\t '+objname+' is a problem child, skipping...')\n",
        "\n",
        "    # Announce problem children\n",
        "    print('Problem children: ', handle_problem_children(state='READ'))\n",
        "\n",
        "    # Saving\n",
        "    dict_packer(objs, BURNS_SAVE_TXT, delimiter=', ') # Save data from fitting\n",
        "    return\n",
        "\n",
        "def burns_plotting(choice):\n",
        "    if 'reg_hist' in choice:\n",
        "        print('Ploting Histogram of SNooPy Fitting Parameters...')\n",
        "        data = np.genfromtxt(BURNS_SAVE_TXT, dtype=str, delimiter=', ', skip_header=1)\n",
        "        objnames, st, Tmax, EBVHost = data[:, 0], data[:, 3].astype(float), data[:, 4].astype(float), data[:, 5].astype(float)\n",
        "        reg_params = [st, Tmax, EBVHost]\n",
        "        bins_reg = [15, 20, 15]\n",
        "        plot_title = 'CSP SNooPy Parameters'\n",
        "\n",
        "        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
        "        titles = ['st', plot_title+'\\nTmax', 'EBVhost']\n",
        "        for i in range(len(titles)):\n",
        "            ax[i].hist(reg_params[i], bins=bins_reg[i])\n",
        "            ax[i].set_title(titles[i])\n",
        "        plt.show()\n",
        "\n",
        "    if 'res_hist' in choice:\n",
        "        print('Ploting Histogram of SNooPy-Chris Burns Parameters Residuals...')\n",
        "        data = np.genfromtxt(BURNS_SAVE_TXT, dtype=str, delimiter=', ', skip_header=1)\n",
        "        objnames, st, Tmax, EBVHost = data[:, 0], data[:, 3].astype(float), data[:, 4].astype(float), data[:, 5].astype(float)\n",
        "\n",
        "        # Take the difference between CSP and DR3 file\n",
        "        st_res, Tmax_res, EBVHost_res = [], [], []\n",
        "        dr3 = read_DR3()\n",
        "        for n in range(len(objnames)):\n",
        "            if objnames[n] in dr3:\n",
        "                st_res.append(st[n] - dr3[objnames[n]]['st'])\n",
        "                Tmax_res.append(Tmax[n] - dr3[objnames[n]]['Tmax'])\n",
        "                EBVHost_res.append(EBVHost[n] - dr3[objnames[n]]['EBVHost'])\\\n",
        "\n",
        "        # Correct for MJD -- 53000\n",
        "        for i in range(len(Tmax_res)):\n",
        "            Tmax_res[i] = Tmax_res[i] + 53000\n",
        "\n",
        "        # Plot\n",
        "        res_params = [st_res, Tmax_res, EBVHost_res]\n",
        "        bins_res = [30, 50, 20]\n",
        "        xlims = [[-0.1, 0.1], [-3, 3], [-0.15, 0.15]]\n",
        "        plot_title = 'SNooPy-Chris Burns Parameters'\n",
        "        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
        "        titles = ['st', plot_title+'\\nTmax', 'EBVhost']\n",
        "        for i in range(len(titles)):\n",
        "            ax[i].hist(res_params[i], bins=bins_res[i])\n",
        "            ax[i].set_title(titles[i])\n",
        "            ax[i].set_xlim(xlims[i])\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    if 'zvmu' in choice:\n",
        "        print('Ploting redshift [z] vs distance mod [mu] of SNooPy Parameters...')\n",
        "        data = np.genfromtxt(BURNS_SAVE_TXT, dtype=str, delimiter=', ', skip_header=1)\n",
        "        objnames, mu, z = data[:, 0], data[:, 1].astype(float), data[:, 2].astype(float)\n",
        "\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        for n in range(len(objnames)):\n",
        "            plt.loglog(z[n], mu[n], label=objnames[n], marker='o')\n",
        "        plt.title('CSP Redshift vs. Distance Mod\\n SNe # = '+str(len(objnames)))\n",
        "        plt.xlabel('Redshift')\n",
        "        plt.ylabel('Distance Mod')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    return\n"
      ],
      "metadata": {
        "id": "RCIf-58euEIX"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" MAIN \"\"\"\n",
        "if __name__ == '__main__':\n",
        "    start = systime.time() # Runtime tracker\n",
        "\n",
        "    recover_dir() # Recovering vital directories\n",
        "\n",
        "    # burns_cspvdr3(fit_filters=None, skip_problems=False, use_saved=False, snpy_plots=False)\n",
        "    # burns_plotting([]) # Options: ['reg_hist', 'res_hist', 'zvmu']\n",
        "\n",
        "    # atlas_collection(quiet=False, check_data=True)\n",
        "    # atlas_objs = atlas_processing(err_max=1000, n_iter=10, sleep_t=8, use_TNS=True)\n",
        "    # atlas_write_ASCII(atlas_objs, save_loc=SNPY_ATLAS_ASCII, quiet=False)\n",
        "    # atlas_snpy_fitting(skip_problems=False, use_saved=False, snpy_plots=False)\n",
        "    # atlas_plotting(['reg_hist'])\n",
        "\n",
        "    # ztf_collection(submit=True)\n",
        "    ztf_alt_collection()\n",
        "\n",
        "\n",
        "    print('|---------------------------|\\n Run-time: ', round(systime.time()-start, 4), 'seconds\\n|---------------------------|')"
      ],
      "metadata": {
        "id": "yO9qvltNuI9Y",
        "outputId": "3adf44da-4aab-4215-da86-2f75771ae829",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wget --http-user=ztffps --http-passwd=dontgocrazy! -O log.txt \"https://ztfweb.ipac.caltech.edu/cgi-bin/requestForcedPhotometry.cgi?ra=10.446222222222222&dec=186.07860833333334&jdstart=2460350&jdend=2460450&email=mekhidw@hawaii.edu&userpass=wxdk286\"\n",
            "|---------------------------|\n",
            " Run-time:  0.2141 seconds\n",
            "|---------------------------|\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# objname = 'SN2007al'\n",
        "# path = '/content/HiloCATsSN1991bg/data/CSPdata/'+objname+'_snpy.txt'\n",
        "\n",
        "# s = snpy.get_sn(path)\n",
        "# s.choose_model('EBV_model2', stype='st')\n",
        "# s.set_restbands() # Auto pick appropriate rest-bands\n",
        "\n",
        "# # s = snpy.get_sn(TEST_ROOT+objname+'_EBV_model2.snpy')\n",
        "\n",
        "\n",
        "# s.decl\n",
        "# # s.data['u'].__dict__\n",
        "\n",
        "\n",
        "# # min_pts = 3\n",
        "# # mjds, mjde = [], []\n",
        "# # filter_wheel = []\n",
        "# # for filter in list(s.data.keys()):\n",
        "# #     print(filter, len(s.data[filter].MJD))\n",
        "# #     if len(s.data[filter].MJD) <= min_pts:\n",
        "# #         print('[!!!]\\t', objname, 'has too few points in', filter, 'filter')\n",
        "# #         continue\n",
        "# #     mjds.append(min(s.data[filter].MJD))\n",
        "# #     mjde.append(max(s.data[filter].MJD))\n",
        "# #     filter_wheel.append(filter)\n",
        "# # print('MJD min:', min(mjds), '+/- 100 MJD', '\\nMJD max:', max(mjde), '+/- 100 MJD')\n",
        "# # print('Viable filters:', filter_wheel)\n",
        "\n",
        "# # s.fit(bands=filter_wheel, dokcorr=True, k_stretch=False, reset_kcorrs=True)\n",
        "# # s.save(TEST_ROOT+'SN2004dt_EBV_model2.snpy')\n"
      ],
      "metadata": {
        "id": "m28_Tv_1Bzry"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "    # path = '/content/HiloCATsSN1991bg/data/CSPdata/SN2004gc_snpy.txt'\n",
        "    # objname = 'SN2004gc'\n",
        "    # save_loc = ROOT_PATH+'test/'\n",
        "    # plot_save_loc = ROOT_PATH+'test/'\n",
        "    # fit_filters = None\n",
        "    # skip_problems = False\n",
        "    # use_saved = False\n",
        "    # snpy_plots = True\n",
        "\n",
        "    # results = None\n",
        "\n",
        "    # problem_children = handle_problem_children(state='READ') # Open problem children\n",
        "\n",
        "    # if skip_problems and (objname in problem_children):\n",
        "    #     results = None\n",
        "    # else:\n",
        "    #     try:\n",
        "    #         if use_saved and os.path.exists(save_loc+objname+'_EBV_model2.snpy'):\n",
        "    #             n_s = snpy.get_sn(save_loc+objname+'_EBV_model2.snpy')\n",
        "    #         else:\n",
        "    #             n_s = snpy.get_sn(path)\n",
        "    #             n_s.choose_model('EBV_model2', stype='st')\n",
        "    #             n_s.set_restbands() # Auto pick appropriate rest-bands\n",
        "    #             n_s.fit(bands=fit_filters, dokcorr=True, k_stretch=False, reset_kcorrs=True, **{'mangle':1,'calibration':0})\n",
        "    #             n_s.save(save_loc+objname+'_EBV_model2.snpy')\n",
        "    #             results = {'mu': n_s.get_distmod(), 'z': n_s.z, 'st': n_s.st, 'Tmax': n_s.Tmax, 'EBVHost': n_s.EBVhost}\n",
        "    #         if snpy_plots:\n",
        "    #             n_s.plot(outfile=plot_save_loc+objname+'_snpyplots.png')\n",
        "    #             plt.show()\n",
        "    #     except:\n",
        "    #         problem_children = np.append(problem_children, objname)\n",
        "    #         handle_problem_children(state='WRITE', problem_c=problem_children) # Commit problem children\n",
        "    #         results = None\n",
        "    # plt.close()\n",
        "\n",
        "    # print(results)"
      ],
      "metadata": {
        "id": "-bMyKN1eoQRA"
      },
      "execution_count": 152,
      "outputs": []
    }
  ]
}