{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMadWdeuUJaAv7xLv3T8bDz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mekhi-woods/HiloCATsSN1991bg/blob/master/amadeus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "OwP9smghsDpU"
      },
      "outputs": [],
      "source": [
        "# \"\"\" START UP \"\"\"\n",
        "# import os\n",
        "# import shutil\n",
        "# if os.path.exists('/content/HiloCATsSN1991bg') == True:\n",
        "#     shutil.rmtree('/content/HiloCATsSN1991bg')\n",
        "#     !git clone https://github.com/mekhi-woods/HiloCATsSN1991bg.git\n",
        "# else:\n",
        "#     !git clone https://github.com/mekhi-woods/HiloCATsSN1991bg.git\n",
        "# !pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple snpy\n",
        "# !pip install requests\n",
        "# !pip install sncosmo\n",
        "# !pip install iminuit\n",
        "# !pip install pandas\n",
        "# !pip install astro_ghost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" IMPORTS \"\"\"\n",
        "import os\n",
        "import time\n",
        "import glob\n",
        "import json\n",
        "import snpy\n",
        "import scipy\n",
        "import shutil\n",
        "import sncosmo\n",
        "import requests\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import time as systime\n",
        "import matplotlib.pyplot as plt\n",
        "from zipfile import ZipFile\n",
        "from requests.auth import HTTPBasicAuth\n",
        "from HiloCATsSN1991bg.scripts import tns_redshifts\n",
        "from astropy.table import QTable, Table, Column\n",
        "from astropy import units as u\n",
        "\n",
        "import astro_ghost\n",
        "from astro_ghost.ghostHelperFunctions import getTransientHosts\n",
        "from astropy.cosmology import FlatLambdaCDM\n",
        "from astropy.coordinates import SkyCoord\n",
        "\n",
        "import astropy.cosmology as cosmo\n"
      ],
      "metadata": {
        "id": "rlZU1P2htj5x"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" GLOBALS \"\"\"\n",
        "# TNS CREDINTIALS\n",
        "tns_bot_id, tns_bot_name, tns_bot_api_key = '73181', 'YSE_Bot1', '0d771345fa6b876a5bb99cd5042ab8b5ae91fc67'\n",
        "\n",
        "# PATHS\n",
        "ROOT_PATH = '/content/HiloCATsSN1991bg/'\n",
        "SNPY_ROOT = ROOT_PATH+'snpy/'\n",
        "PLOTS_ROOT = ROOT_PATH+'plots/'\n",
        "TEST_ROOT = ROOT_PATH+'test/'\n",
        "\n",
        "SNPY_BURNS = SNPY_ROOT+'burns/'\n",
        "SNPY_BURNS_PLOTS = SNPY_BURNS+'plots/'\n",
        "BURNS_SAVE_TXT = SNPY_BURNS+'burns_saved.txt'\n",
        "\n",
        "DATA_ATLAS = ROOT_PATH+'data/ATLAS/'\n",
        "SNPY_ATLAS = SNPY_ROOT+'atlas/'\n",
        "SNPY_ATLAS_PLOTS = SNPY_ATLAS+'plots/'\n",
        "SNPY_ATLAS_ASCII = SNPY_ATLAS+'ascii/'\n",
        "ATLAS_SAVE_TXT = SNPY_ATLAS+'atlas_saved.txt'\n",
        "\n",
        "DATA_ZTF = ROOT_PATH+'data/ZTF/'\n",
        "\n",
        "GHOST_DATA = ROOT_PATH+'data/GHOST/'\n",
        "\n",
        "PROB_CHILD_TXT = ROOT_PATH+'problem_children.txt'\n",
        "TNS_KEY_TXT = ROOT_PATH+'TNS_key.txt'\n",
        "\n",
        "COSMO_MODEL = cosmo.FlatLambdaCDM(H0=70, Om0=0.3)\n"
      ],
      "metadata": {
        "id": "_QakJM19tnqE"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" ZTF \"\"\"\n",
        "def ztf_collection(submit=False, limit=1000):\n",
        "    objs = dict_unpacker(ATLAS_SAVE_TXT)\n",
        "    print(\"Number of targets =\", len(objs))\n",
        "    ralist, declist, jdslist, jdelist = [], [], [], []\n",
        "    i = 0\n",
        "    for obj in objs:\n",
        "        ralist.append(float(objs[obj]['ra']))\n",
        "        declist.append(float(objs[obj]['dec']))\n",
        "        jdslist.append(float(objs[obj]['MJDs'])-100)\n",
        "        jdelist.append(float(objs[obj]['MJDe'])+100)\n",
        "        i += 1\n",
        "        if i % limit == 0:\n",
        "            if submit:\n",
        "                ztf_submit_post(ralist, declist, jdslist, jdelist)\n",
        "            ralist, declist, jdslist, jdelist = [], [], [], []\n",
        "    if submit and len(ralist) > 0:\n",
        "        ztf_submit_post(ralist, declist, jdslist, jdelist)\n",
        "\n",
        "    return\n",
        "\n",
        "def ztf_submit_post(ra_list, dec_list, jds, jde):\n",
        "    print('Submiting request to ZTF...')\n",
        "\n",
        "    email = 'mekhidw@hawaii.edu' # email you subscribed with.\n",
        "    userpass = 'wxdk286' # password that was issued to you.\n",
        "\n",
        "    ra, dec = json.dumps(ra_list), json.dumps(dec_list)\n",
        "    jdend, jdstart = json.dumps(jde), json.dumps(jds)\n",
        "    payload = {'ra': ra, 'dec': dec, 'jdstart': jdstart, 'jdend': jdend, 'email': email, 'userpass': userpass}\n",
        "\n",
        "    # fixed IP address/URL where requests are submitted:\n",
        "    url = 'https://ztfweb.ipac.caltech.edu/cgi-bin/batchfp.py/submit'\n",
        "    r = requests.post(url, auth=('ztffps', 'dontgocrazy!'), data=payload)\n",
        "\n",
        "    print('RA ['+str(type(payload['ra'][0]))+']:', payload['ra'])\n",
        "    print('DEC ['+str(type(payload['dec'][0]))+']:', payload['dec'])\n",
        "    print('MJD Start ['+str(type(payload['jdstart'][0]))+']:', payload['jdstart'])\n",
        "    print('MJD End ['+str(type(payload['jdend'][0]))+']:', payload['jdend'])\n",
        "    print(\"Status_code=\", r.status_code)\n",
        "    return\n",
        "\n",
        "def ztf_alt_collection():\n",
        "    ra, dec, jds, jde = 186.07860833333334, 10.446222222222222, 2460350, 2460450\n",
        "\n",
        "    email = 'mekhidw@hawaii.edu' # email you subscribed with.\n",
        "    userpass = 'wxdk286' # password that was issued to you.\n",
        "\n",
        "    cmd = f\"wget --http-user=ztffps --http-passwd=dontgocrazy! -O log.txt \\\"https://ztfweb.ipac.caltech.edu/cgi-bin/requestForcedPhotometry.cgi?ra={dec}&dec={ra}&jdstart={jds}&jdend={jde}&email={email}&userpass={userpass}\\\"\"\n",
        "    print(cmd)\n",
        "    os.system(cmd)\n",
        "\n",
        "    return\n"
      ],
      "metadata": {
        "id": "th67irAgJGDB"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" ATLAS \"\"\"\n",
        "def atlas_collection(quiet=False, check_data=True):\n",
        "    api_token = '7f4e1dee8f52cf0c8cdaf55bf29d04bef4810fb4'\n",
        "\n",
        "    if check_data and len(glob.glob(DATA_ATLAS+'*.txt')) > 1:\n",
        "        print('[+++] ATLAS data already collected, passing step...')\n",
        "        return\n",
        "    else:\n",
        "        print('[+++] No data detected, collecting ATLAS data...')\n",
        "        if os.path.exists(DATA_ATLAS+'tmp.npz'):\n",
        "            pickle = np.load(DATA_ATLAS+'tmp.npz', allow_pickle=True)\n",
        "            data = pickle['data']\n",
        "\n",
        "        data = requests.post('https://star.pst.qub.ac.uk/sne/atlas4/api/objectlist/',\n",
        "                             headers={'Authorization': f'Token {api_token}'},\n",
        "                             data={'objectlistid':2}).json()\n",
        "\n",
        "        np.savez(DATA_ATLAS+'tmp.npz', data=data)\n",
        "\n",
        "        count = 0\n",
        "        for d in data:\n",
        "            if d['observation_status'] is not None and d['observation_status'].startswith('SN Ia') and '91bg' in d['observation_status']:\n",
        "                count += 1\n",
        "                if not quiet:\n",
        "                    print(d['atlas_designation'],d['observation_status'].replace(' ',''),d['ra'],d['dec'])\n",
        "\n",
        "\n",
        "                ids = d['id']\n",
        "                base_url = 'https://star.pst.qub.ac.uk/sne/atlas4/lightcurveforced/1161048951013729300/'\n",
        "                new_url = base_url.replace('1161048951013729300/',str(ids))\n",
        "                if not quiet:\n",
        "                    print(new_url)\n",
        "\n",
        "                idfile = DATA_ATLAS+'/' + str(ids)+'.txt'\n",
        "                if os.path.exists(idfile):\n",
        "                    continue\n",
        "                urllib.request.urlretrieve(str(new_url), str(idfile))\n",
        "                if not quiet:\n",
        "                    print(idfile)\n",
        "\n",
        "            if count > 300:\n",
        "                break\n",
        "    return\n",
        "\n",
        "def atlas_tns_collection(quiet=False, t_sleep=5, max_attempts=5):\n",
        "    files = glob.glob(DATA_ATLAS+'/*.txt')\n",
        "    tns_key = dict_unpacker(TNS_KEY_TXT)\n",
        "\n",
        "    attempts = max_attempts\n",
        "    while attempts > 0:\n",
        "        try:\n",
        "            f = open(TNS_KEY_TXT, 'a')\n",
        "            if len(tns_key) == 0:\n",
        "                f.write('atlas_name, objname, ra, dec, z\\n')\n",
        "            for n in range(len(files)):\n",
        "                tracker = '['+str(n+1)+'/'+str(len(files))+']' # Purely cosmetic\n",
        "                atlas_name = files[n][len(DATA_ATLAS):-4]\n",
        "                data = np.genfromtxt(files[n], dtype=float, delimiter=',', skip_header=1)\n",
        "                ra = np.average(data[:, 1])\n",
        "                dec = np.average(data[:, 2])\n",
        "\n",
        "                if atlas_name not in tns_key:\n",
        "                    details = TNS_details(ra, dec)\n",
        "                    tns_key.update({atlas_name: {'objname': details['objname'], 'ra': ra, 'dec': dec, 'z': details['redshift']}})\n",
        "                    f.write(atlas_name+', '+str(details['objname'])+', '+str(ra)+', '+str(dec)+', '+str(details['redshift'])+'\\n')\n",
        "                    if not quiet:\n",
        "                        print(tracker, details['objname']+':', ra, '|', dec, '|', details['redshift'])\n",
        "            f.close()\n",
        "        except:\n",
        "            print('[', attempts, '/', max_attempts, '] Hit time error, sleeping for '+str(t_sleep)+' seconds...')\n",
        "            time.sleep(t_sleep)\n",
        "            attempts -= 1\n",
        "    if attempts == 0:\n",
        "        print('[!!!] ATTEMPT LIMIT HIT')\n",
        "        return\n",
        "\n",
        "    dict_packer(tns_key, TNS_KEY_TXT)\n",
        "\n",
        "    return tns_key\n",
        "\n",
        "def atlas_processing(err_max=100, n_iter=10, sleep_t=5, use_TNS=False):\n",
        "    print('[+++] Retrieving data from...', DATA_ATLAS)\n",
        "    # Retrieve file paths\n",
        "    files = glob.glob(DATA_ATLAS+'/*.txt')\n",
        "    if n_iter != 0 and n_iter <= len(files):\n",
        "        files = files[:n_iter]\n",
        "\n",
        "    objs = {}\n",
        "    for n in range(len(files)):\n",
        "        # Tracking/Cosmetics\n",
        "        ATLAS_name = files[n][len(DATA_ATLAS):-4]\n",
        "        tracker = '['+str(n+1)+'/'+str(len(files))+']' # Purely cosmetic\n",
        "        print(tracker, '\\n', '\\t\\tPulling', ATLAS_name, 'data...')\n",
        "\n",
        "        # Reading file path\n",
        "        try:\n",
        "            data = np.genfromtxt(files[n], dtype=str, delimiter=',', skip_header=1)\n",
        "            if len(data) == 0: # Handling empty files\n",
        "                print('[!!!] \\t\\tFile '+ATLAS_name+' empty...skipping') # If empty, skips\n",
        "                continue\n",
        "        except:\n",
        "            print('[!!!] \\t\\tUnknown error, skipping...') # Numpy was doing a weird thing, so crash hander until i figure it out\n",
        "            continue\n",
        "        ra, dec = np.average(data[:, 1].astype(float)), np.average(data[:, 2].astype(float)) # Recoring RA & DEC (average of columns)\n",
        "\n",
        "        # Using TNS to get object name\n",
        "        tns_key = dict_unpacker(TNS_KEY_TXT)\n",
        "        if use_TNS and (ATLAS_name in tns_key):\n",
        "            print('\\t\\tAttempting to use TNS key for objname...')\n",
        "            objname = tns_key[ATLAS_name]['objname']\n",
        "            z = tns_key[ATLAS_name]['z']\n",
        "        else:\n",
        "            print('\\t\\tRetrieving TNS data for...', ATLAS_name, '[sleeping for', sleep_t, 'seconds...]')\n",
        "            systime.sleep(sleep_t)\n",
        "            details = TNS_details(ra, dec)\n",
        "            objname = details['objname']\n",
        "            z = details['redshift']\n",
        "            with open(TNS_KEY_TXT, 'a') as f:\n",
        "                f.write(ATLAS_name+', '+str(objname)+', '+str(ra)+', '+str(dec)+', '+str(z)+'\\n')\n",
        "            print('\\t\\tSaved TNS data to TNS key...')\n",
        "\n",
        "        mag = np.char.replace(data[:, 3], '>', '') # Removes greater than symbols\n",
        "        dmag, filters, time, flux, dflux = data[:, 4], data[:, 6], data[:, 8], data[:, 24], data[:, 25] # Reads rest of categories\n",
        "        objs.update({objname: {'ra': ra, 'dec': dec, 'z': z, 'time': time, 'flux': flux, 'dflux': dflux, 'mag': mag, 'dmag': dmag, 'filters': filters}})\n",
        "\n",
        "        ## SLICING DATA\n",
        "        # ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "        # Remove 'None' from categories\n",
        "        mod_empty = np.array([])\n",
        "        for cat in ['time', 'flux', 'dflux', 'mag', 'dmag', 'filters']:\n",
        "            mod_empty = np.append(mod_empty, np.where(objs[objname][cat] == 'None')[0])\n",
        "        mod_empty = np.unique(mod_empty).astype(int) # Remove dupes\n",
        "        for cat in ['time', 'flux', 'dflux', 'mag', 'dmag', 'filters']:\n",
        "            objs[objname][cat] = np.delete(objs[objname][cat], mod_empty)\n",
        "\n",
        "        # Finds negative fluxes\n",
        "        mod_positive = np.array([])\n",
        "        for cat in ['time', 'flux', 'dflux', 'mag', 'dmag']:\n",
        "            mod_positive = np.append(mod_positive, np.where(objs[objname][cat].astype(float) <= 0)[0])\n",
        "        mod_positive = np.unique(mod_positive).astype(int) # Remove dupes\n",
        "        for cat in ['time', 'flux', 'dflux', 'mag', 'dmag', 'filters']:\n",
        "            objs[objname][cat] = np.delete(objs[objname][cat], mod_positive)\n",
        "\n",
        "        # Find outliers beyond error limit\n",
        "        mod_err = np.array([])\n",
        "        for cat in ['dflux', 'dmag']:\n",
        "            mod_err = np.append(mod_err, np.where(np.abs(objs[objname][cat].astype(float)) > err_max)[0])\n",
        "        mod_err = np.unique(mod_err).astype(int) # Remove dupes\n",
        "        for cat in ['time', 'flux', 'dflux', 'mag', 'dmag', 'filters']:\n",
        "            objs[objname][cat] = np.delete(objs[objname][cat], mod_err)\n",
        "\n",
        "        # Set everything as floats\n",
        "        for cat in ['time', 'flux', 'dflux', 'mag', 'dmag']:\n",
        "            objs[objname][cat] = objs[objname][cat].astype(float)\n",
        "\n",
        "        # Seperate into orange & cyan channels\n",
        "        for cat in ['time', 'flux', 'dflux', 'mag', 'dmag']:\n",
        "            objs[objname].update({cat+'_o': objs[objname][cat][np.where(objs[objname]['filters'] == 'o')[0]]})\n",
        "            objs[objname].update({cat+'_c': objs[objname][cat][np.where(objs[objname]['filters'] == 'c')[0]]})\n",
        "        # ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "        print('\\t\\tRetrived:', objname+' |', 'ra:', ra, '\\\\', 'dec:', dec)\n",
        "    print('[!!!]\\t\\tRetrieved & processed', len(objs), 'SNe from ATLAS!')\n",
        "    return objs\n",
        "\n",
        "def atlas_write_ASCII(atlas_objs, save_loc, quiet=True):\n",
        "    print('[+++] Saving data to ASCII files for SNooPy...')\n",
        "    for obj in atlas_objs:\n",
        "        with open(save_loc+obj+'_snpy.txt', 'w') as f:\n",
        "            # Line 1 -- Objname, Helio-Z, RA, Dec (Ex. SN1981D 0.005871 50.65992 -37.23272)\n",
        "            f.write(str(obj)+' '+str(atlas_objs[obj]['z'])+' '+str(atlas_objs[obj]['ra'])+' '+str(atlas_objs[obj]['dec'])+'\\n')\n",
        "\n",
        "            # 'o'/'ATri'-filter photometry block -- Date (JD/MJD), mag, err (674.8593 12.94 0.11)\n",
        "            f.write('filter ATri\\n')\n",
        "            for i in range(len(atlas_objs[obj]['time_o'])):\n",
        "                f.write(str(atlas_objs[obj]['time_o'][i])+'\\t'+str(atlas_objs[obj]['mag_o'][i])+'\\t'+str(atlas_objs[obj]['dmag_o'][i])+'\\n')\n",
        "\n",
        "            # # 'c'/'ATgr'-filter photometry block\n",
        "            f.write('filter ATgr\\n')\n",
        "            for i in range(len(atlas_objs[obj]['time_c'])):\n",
        "                f.write(str(atlas_objs[obj]['time_c'][i])+'\\t'+str(atlas_objs[obj]['mag_c'][i])+'\\t'+str(atlas_objs[obj]['dmag_c'][i])+'\\n')\n",
        "    return\n",
        "\n",
        "def atlas_snpy_fitting(n_iter=0, skip_problems=True, use_saved=True, snpy_plots=True, save_plots=True):\n",
        "    print('[+++] Fitting ATLAS data with SNooPy...')\n",
        "    fit_args = {'skip_problems': skip_problems, 'use_saved': use_saved, 'snpy_plots': snpy_plots, 'save_plots': save_plots}\n",
        "    print('Fitting arguments: ', fit_args)\n",
        "    objpaths = glob.glob(SNPY_ATLAS_ASCII+'*')\n",
        "    if n_iter != 0 and n_iter <= len(objpaths):\n",
        "        objpaths = objpaths[:n_iter]\n",
        "\n",
        "    objs = {}\n",
        "    err_i = 0\n",
        "    for n in range(len(objpaths)):\n",
        "        tracker = '['+str(n+1)+'/'+str(len(objpaths))+']' # Purely cosmetic\n",
        "        objname = objpaths[n][len(SNPY_ATLAS_ASCII):-9]\n",
        "        print(tracker, objname)\n",
        "        temp_dict = snpy_fit(objpaths[n], objname, save_loc=SNPY_ATLAS, plot_save_loc=SNPY_ATLAS_PLOTS, **fit_args)\n",
        "\n",
        "        if type(temp_dict) == dict:\n",
        "            print('\\tResults: \\n',\n",
        "                  '\\t\\tmu =', temp_dict['mu'], '+/-', temp_dict['mu_err'],'\\n',\n",
        "                  '\\t\\tst =', temp_dict['st'], '+/-', temp_dict['st_err'],'\\n',\n",
        "                  '\\t\\tTmax =', temp_dict['Tmax'], '+/-', temp_dict['Tmax_err'],'\\n',\n",
        "                  '\\t\\tEBVhost =', temp_dict['EBVhost'],  '+/-', temp_dict['EBVhost_err'])\n",
        "            print('\\tMJD min:', temp_dict['MJDs'], '+/- 100 MJD', '| MJD max:', temp_dict['MJDe'], '+/- 100 MJD\\n')\n",
        "            objs.update({objname: temp_dict})\n",
        "        else:\n",
        "            err_i += 1\n",
        "            print('[!!!]\\t', temp_dict, '\\n')\n",
        "    print('Finshed! Successfully fit', len(objpaths)-err_i, '/', len(objpaths), 'SNe from ATLAS! ['+str(round(((len(objpaths)-err_i) / len(objpaths))*100, 2))+'%]')\n",
        "\n",
        "    # Save Data\n",
        "    if len(objs) > 0:\n",
        "        dict_packer(objs, ATLAS_SAVE_TXT, delimiter=', ') # Save data from fitting\n",
        "    if snpy_plots and save_plots:\n",
        "        save_to_zip(SNPY_ATLAS_PLOTS, SNPY_ATLAS_PLOTS+'atlas_snpy_plots.zip')\n",
        "\n",
        "    return\n",
        "\n",
        "def atlas_plotting(choice):\n",
        "    if 'reg_hist' in choice:\n",
        "        print('[+++] Ploting Histogram of ATLAS SNooPy Fitting Parameters...')\n",
        "        data = np.genfromtxt(SNPY_ATLAS+'atlas_saved.txt', dtype=str, delimiter=', ', skip_header=1)\n",
        "        objnames, st, Tmax, EBVHost = data[:, 0], data[:, 3].astype(float), data[:, 4].astype(float), data[:, 5].astype(float)\n",
        "        reg_params = [st, Tmax, EBVHost]\n",
        "        bins_reg = [15, 20, 15]\n",
        "        plot_title = 'ATLAS SNooPy Parameters'\n",
        "\n",
        "        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
        "        titles = ['st', plot_title+'\\nTmax', 'EBVhost']\n",
        "        for i in range(len(titles)):\n",
        "            ax[i].hist(reg_params[i], bins=bins_reg[i])\n",
        "            ax[i].set_title(titles[i])\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "nMom96ltQcJ4"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" GENERAL \"\"\"\n",
        "def recover_dir():\n",
        "    directories = [ROOT_PATH,\n",
        "                   DATA_ATLAS,\n",
        "                   SNPY_ROOT, SNPY_BURNS, SNPY_BURNS_PLOTS,\n",
        "                   SNPY_ATLAS, SNPY_ATLAS_PLOTS, SNPY_ATLAS_ASCII,\n",
        "                   PLOTS_ROOT, TEST_ROOT, GHOST_DATA]\n",
        "    files = [PROB_CHILD_TXT, TNS_KEY_TXT,\n",
        "             BURNS_SAVE_TXT, ATLAS_SAVE_TXT]\n",
        "    for dir in directories:\n",
        "        if os.path.exists(dir) == False:\n",
        "            os.mkdir(dir)\n",
        "    for n_file in files:\n",
        "        if os.path.exists(n_file) == False:\n",
        "            with open(n_file, 'w') as f:\n",
        "                pass\n",
        "\n",
        "    astro_ghost.ghostHelperFunctions.getGHOST(real=False, verbose=True, installpath=GHOST_DATA, clobber=False)\n",
        "\n",
        "    return\n",
        "\n",
        "def TNS_details(ra, dec):\n",
        "    # Code from David\n",
        "    headers = tns_redshifts.build_tns_header(tns_bot_id, tns_bot_name)\n",
        "    tns_api_url = f\"https://www.wis-tns.org/api/get\"\n",
        "\n",
        "    # get the API URLs\n",
        "    search_tns_url = tns_redshifts.build_tns_url(tns_api_url, mode=\"search\")\n",
        "    get_tns_url = tns_redshifts.build_tns_url(tns_api_url, mode=\"get\")\n",
        "\n",
        "    search_data = tns_redshifts.build_tns_search_query_data(tns_bot_api_key, ra, dec)\n",
        "    transients = tns_redshifts.rate_limit_query_tns(search_data, headers, search_tns_url)\n",
        "\n",
        "    get_data = tns_redshifts.build_tns_get_query_data(tns_bot_api_key, transients[0])\n",
        "    transient_detail = tns_redshifts.rate_limit_query_tns(get_data, headers, get_tns_url)\n",
        "\n",
        "    return transient_detail\n",
        "\n",
        "def snpy_fit(path, objname, save_loc, plot_save_loc, skip_problems=False, use_saved=False, snpy_plots=True, save_plots=True):\n",
        "    problem_children = handle_problem_children(state='READ') # Open problem children\n",
        "\n",
        "    if skip_problems and (objname in problem_children):\n",
        "        return None\n",
        "    else:\n",
        "        try:\n",
        "            if use_saved and os.path.exists(save_loc+objname+'_EBV_model2.snpy'):\n",
        "                n_s = snpy.get_sn(save_loc+objname+'_EBV_model2.snpy')\n",
        "            else:\n",
        "                n_s = snpy.get_sn(path)\n",
        "                n_s.choose_model('EBV_model2', stype='st')\n",
        "                n_s.set_restbands() # Auto pick appropriate rest-bands\n",
        "\n",
        "                # Sort out empty filters & get start and end time\n",
        "                mjds, mjde = [], []\n",
        "                filter_wheel = []\n",
        "                for filter in list(n_s.data.keys()):\n",
        "                    if len(n_s.data[filter].MJD) <= 3:\n",
        "                        print('\\t', objname, 'has too few points in', filter, 'filter')\n",
        "                        continue\n",
        "                    mjds.append(min(n_s.data[filter].MJD))\n",
        "                    mjde.append(max(n_s.data[filter].MJD))\n",
        "                    filter_wheel.append(filter)\n",
        "                print('\\t', filter_wheel)\n",
        "\n",
        "                n_s.fit(bands=filter_wheel, dokcorr=True, k_stretch=False, reset_kcorrs=True, **{'mangle':1,'calibration':0})\n",
        "                n_s.save(save_loc+objname+'_EBV_model2.snpy')\n",
        "\n",
        "            if snpy_plots:\n",
        "                n_s.plot(outfile=plot_save_loc+objname+'_snpyplots.png')\n",
        "                plt.show()\n",
        "        except Exception as error:\n",
        "            problem_children = np.append(problem_children, objname)\n",
        "            handle_problem_children(state='WRITE', problem_c=problem_children) # Commit problem children\n",
        "            return error\n",
        "\n",
        "    plt.close()\n",
        "    return {'ra': n_s.ra, 'dec': n_s.decl, 'z': n_s.z, 'MJDs': min(mjds), 'MJDe': max(mjde),\n",
        "            'mu': n_s.parameters['DM'], 'st': n_s.parameters['st'], 'Tmax': n_s.parameters['Tmax'], 'EBVhost': n_s.parameters['EBVhost'],\n",
        "            'mu_err': n_s.errors['DM'], 'st_err': n_s.errors['st'], 'Tmax_err': n_s.errors['Tmax'], 'EBVhost_err': n_s.errors['EBVhost']}\n",
        "\n",
        "def snpy_fit_indv(objname):\n",
        "    path = '/content/HiloCATsSN1991bg/snpy/atlas/'+objname+'_EBV_model2.snpy'\n",
        "\n",
        "    n_s = snpy.get_sn(path)\n",
        "    n_s.choose_model('EBV_model2', stype='st')\n",
        "    n_s.set_restbands() # Auto pick appropriate rest-bands\n",
        "\n",
        "    # Sort out empty filters & get start and end time\n",
        "    mjds, mjde = [], []\n",
        "    filter_wheel = []\n",
        "    for filter in list(n_s.data.keys()):\n",
        "        if len(n_s.data[filter].MJD) <= 3:\n",
        "            print('\\t', objname, 'has too few points in', filter, 'filter')\n",
        "            continue\n",
        "        mjds.append(min(n_s.data[filter].MJD))\n",
        "        mjde.append(max(n_s.data[filter].MJD))\n",
        "        filter_wheel.append(filter)\n",
        "\n",
        "    n_s.fit(bands=filter_wheel, dokcorr=True, k_stretch=False, reset_kcorrs=True, **{'mangle':1,'calibration':0})\n",
        "    plt.show()\n",
        "\n",
        "    print('Results:',\n",
        "        'mu =', n_s.parameters['DM'], '+/-', n_s.errors['DM'],'\\n',\n",
        "        '\\t st =', n_s.parameters['st'], '+/-', n_s.errors['st'],'\\n',\n",
        "        '\\t Tmax =', n_s.parameters['Tmax'], '+/-', n_s.errors['Tmax'],'\\n',\n",
        "        '\\t EBVhost =', n_s.parameters['EBVhost'],  '+/-', n_s.errors['EBVhost'],'\\n',\n",
        "        '\\t MJD min:', min(mjds), '| MJD max:', max(mjde))\n",
        "\n",
        "    return\n",
        "\n",
        "def write_ASCII(objs, save_loc, quiet=True):\n",
        "    print('[+++] Saving data to ASCII files for SNooPy...')\n",
        "    for obj in objs:\n",
        "        with open(save_loc+obj+'_snpy.txt', 'w') as f:\n",
        "            # Line 1 -- Objname, Helio-Z, RA, Dec (Ex. SN1981D 0.005871 50.65992 -37.23272)\n",
        "            f.write(str(obj)+' '+str(objs[obj]['z'])+' '+str(objs[obj]['ra'])+' '+str(objs[obj]['dec'])+'\\n')\n",
        "\n",
        "            # 'o'/'ATri'-filter photometry block -- Date (JD/MJD), mag, err (674.8593 12.94 0.11)\n",
        "            f.write('filter ATri\\n')\n",
        "            for i in range(len(objs[obj]['time_o'])):\n",
        "                f.write(str(objs[obj]['time_o'][i])+'\\t'+str(objs[obj]['mag_o'][i])+'\\t'+str(objs[obj]['dmag_o'][i])+'\\n')\n",
        "\n",
        "            # # 'c'/'ATgr'-filter photometry block\n",
        "            f.write('filter ATgr\\n')\n",
        "            for i in range(len(objs[obj]['time_c'])):\n",
        "                f.write(str(objs[obj]['time_c'][i])+'\\t'+str(objs[obj]['mag_c'][i])+'\\t'+str(objs[obj]['dmag_c'][i])+'\\n')\n",
        "    return\n",
        "\n",
        "def read_DR3(loc='/content/HiloCATsSN1991bg/DR3_fits.dat'):\n",
        "    data = np.genfromtxt(loc, dtype=str, skip_header=1)\n",
        "    dr3 = {}\n",
        "    for n in range(len(data[:, 0])):\n",
        "        dr3.update({data[:, 0][n]: {'st': float(data[:, 1][n]), 'e_st': float(data[:, 2][n]), 'z': float(data[:, 3][n]),\n",
        "                           'Tmax': float(data[:, 5][n]), 'e_Tmax': float(data[:, 6][n]),\n",
        "                           'EBVHost': float(data[:, 25][n]), 'e_EBVHost': float(data[:, 26][n])}})\n",
        "    return dr3\n",
        "\n",
        "def dict_unpacker(path, delimiter=', '):\n",
        "    with open(path, 'r') as f:\n",
        "        hdr = f.readline()[:-1].split(delimiter)\n",
        "\n",
        "    data = np.genfromtxt(path, delimiter=delimiter, dtype=str, skip_header=1)\n",
        "    if len(data) == 0:\n",
        "        return {}\n",
        "    temp_objs = {}\n",
        "    for i in range(len(data[:, 0])):\n",
        "        obj = data[:, 0][i]\n",
        "        temp_objs.update({obj: {}})\n",
        "        for j in range(len(hdr)):\n",
        "            temp_objs[obj].update({hdr[j]: data[i, j]})\n",
        "    return temp_objs\n",
        "\n",
        "def dict_packer(data_dict, save_loc, delimiter=', '):\n",
        "    catagories = list(data_dict[list(data_dict.keys())[0]].keys())\n",
        "    with open(save_loc, 'w') as f:\n",
        "        f.write('objname')\n",
        "        for category in catagories:\n",
        "            f.write(delimiter+category)\n",
        "        f.write('\\n')\n",
        "        for objname in data_dict:\n",
        "            f.write(objname)\n",
        "            for category in catagories:\n",
        "                f.write(delimiter+str(data_dict[objname][category]))\n",
        "            f.write('\\n')\n",
        "    return\n",
        "\n",
        "def handle_problem_children(state, problem_c=None):\n",
        "    if state == 'READ':\n",
        "        # Read problem children\n",
        "        problem_c = np.genfromtxt(PROB_CHILD_TXT, dtype=str)\n",
        "        return problem_c\n",
        "    elif state == 'WRITE':\n",
        "        # Write problem children\n",
        "        problem_c = np.unique(problem_c)\n",
        "        with open(PROB_CHILD_TXT, 'w') as f:\n",
        "            for c in problem_c:\n",
        "                f.write(c+'\\n')\n",
        "        return None\n",
        "    else:\n",
        "        raise Exception(\"Invalid state: '\"+state+\"' [READ/WRITE]\")\n",
        "\n",
        "def save_to_zip(zip_loc, save_loc):\n",
        "    print('Saving zipped files to...', save_loc)\n",
        "    files = glob.glob(zip_loc+'*')\n",
        "    with ZipFile(save_loc, 'w') as zip:\n",
        "        for n_file in files:\n",
        "            zip.write(n_file)\n",
        "    return\n",
        "\n",
        "def malmquist_bias_corr(mu, z, mu_err, m, b):\n",
        "    summation = 0\n",
        "    for n in range(len(mu)):\n",
        "        summation = summation + (mu[n] - ((m*z[n])+b)) / (mu_err[n]**2)\n",
        "    return summation\n"
      ],
      "metadata": {
        "id": "zsrqLqM4t0tX"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" BURNS/CSP \"\"\"\n",
        "def burns_cspvdr3(fit_filters=None, skip_problems=False, use_saved=False, snpy_plots=True):\n",
        "    print('[+++] Fitting CSP data with SNooPy...')\n",
        "    # Get Chris Burns Data\n",
        "    objnames = np.genfromtxt('/content/HiloCATsSN1991bg/targetLists/91bglike_justnames.txt', dtype=str, delimiter=', ')\n",
        "\n",
        "    # Get CSP paths of Chris Burns Data\n",
        "    objpaths = []\n",
        "    for name in objnames:\n",
        "        if os.path.exists('/content/HiloCATsSN1991bg/data/CSPdata/SN'+name+'_snpy.txt'):\n",
        "            objpaths.append('/content/HiloCATsSN1991bg/data/CSPdata/SN'+name+'_snpy.txt')\n",
        "        else:\n",
        "            print(name, 'not found...')\n",
        "\n",
        "    # Fitting\n",
        "    objs = {}\n",
        "    err_i = 0\n",
        "    fit_args = {'skip_problems': skip_problems, 'use_saved': use_saved, 'snpy_plots': snpy_plots}\n",
        "    print('Fitting arguments: ', fit_args)\n",
        "    for n in range(len(objpaths)):\n",
        "        tracker = '['+str(n+1)+'/'+str(len(objpaths))+']' # Purely cosmetic\n",
        "        objname = objpaths[n][39:-9]\n",
        "        print(tracker, objname)\n",
        "        temp_dict = snpy_fit(objpaths[n], objname, save_loc=SNPY_BURNS, plot_save_loc=SNPY_BURNS_PLOTS, **fit_args)\n",
        "\n",
        "        if type(temp_dict) == dict:\n",
        "            print('\\tResults: \\n',\n",
        "                  '\\t\\tmu =', temp_dict['mu'], '+/-', temp_dict['mu_err'],'\\n',\n",
        "                  '\\t\\tst =', temp_dict['st'], '+/-', temp_dict['st_err'],'\\n',\n",
        "                  '\\t\\tTmax =', temp_dict['Tmax'], '+/-', temp_dict['Tmax_err'],'\\n',\n",
        "                  '\\t\\tEBVhost =', temp_dict['EBVhost'],  '+/-', temp_dict['EBVhost_err'])\n",
        "            print('\\tMJD min:', temp_dict['MJDs'], '+/- 100 MJD', '| MJD max:', temp_dict['MJDe'], '+/- 100 MJD\\n')\n",
        "            objs.update({objname: temp_dict})\n",
        "        else:\n",
        "            err_i += 1\n",
        "            print('[!!!]\\t', temp_dict, '\\n')\n",
        "    print('Finshed! Successfully fit', len(objpaths)-err_i, '/', len(objpaths), 'SNe from ATLAS! ['+str(round(((len(objpaths)-err_i) / len(objpaths))*100, 2))+'%]')\n",
        "\n",
        "    # Announce problem children\n",
        "    print('Problem children: ', handle_problem_children(state='READ'))\n",
        "\n",
        "    # Save Data\n",
        "    if len(objs) > 0:\n",
        "        dict_packer(objs, BURNS_SAVE_TXT, delimiter=', ') # Save data from fitting\n",
        "    return\n",
        "\n",
        "def burns_plotting(choice):\n",
        "    if 'reg_hist' in choice:\n",
        "        print('[+++] Ploting Histogram of SNooPy Fitting Parameters...')\n",
        "        data = np.genfromtxt(BURNS_SAVE_TXT, dtype=str, delimiter=', ', skip_header=1)\n",
        "        objnames, st, Tmax, EBVHost = data[:, 0], data[:, 3].astype(float), data[:, 4].astype(float), data[:, 5].astype(float)\n",
        "        reg_params = [st, Tmax, EBVHost]\n",
        "        bins_reg = [15, 20, 15]\n",
        "        plot_title = 'CSP SNooPy Parameters'\n",
        "\n",
        "        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
        "        titles = ['st', plot_title+'\\nTmax', 'EBVhost']\n",
        "        for i in range(len(titles)):\n",
        "            ax[i].hist(reg_params[i], bins=bins_reg[i])\n",
        "            ax[i].set_title(titles[i])\n",
        "        plt.show()\n",
        "\n",
        "    if 'res_hist' in choice:\n",
        "        print('[+++] Ploting Histogram of SNooPy-Chris Burns Parameters Residuals...')\n",
        "        data = np.genfromtxt(BURNS_SAVE_TXT, dtype=str, delimiter=', ', skip_header=1)\n",
        "        objnames, st, Tmax, EBVHost = data[:, 0], data[:, 3].astype(float), data[:, 4].astype(float), data[:, 5].astype(float)\n",
        "\n",
        "        # Take the difference between CSP and DR3 file\n",
        "        st_res, Tmax_res, EBVHost_res = [], [], []\n",
        "        dr3 = read_DR3()\n",
        "        for n in range(len(objnames)):\n",
        "            if objnames[n] in dr3:\n",
        "                st_res.append(st[n] - dr3[objnames[n]]['st'])\n",
        "                Tmax_res.append(Tmax[n] - dr3[objnames[n]]['Tmax'])\n",
        "                EBVHost_res.append(EBVHost[n] - dr3[objnames[n]]['EBVHost'])\\\n",
        "\n",
        "        # Correct for MJD -- 53000\n",
        "        for i in range(len(Tmax_res)):\n",
        "            Tmax_res[i] = Tmax_res[i] + 53000\n",
        "\n",
        "        # Plot\n",
        "        res_params = [st_res, Tmax_res, EBVHost_res]\n",
        "        bins_res = [30, 50, 20]\n",
        "        xlims = [[-0.1, 0.1], [-3, 3], [-0.15, 0.15]]\n",
        "        plot_title = 'SNooPy-Chris Burns Parameters'\n",
        "        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
        "        titles = ['st', plot_title+'\\nTmax', 'EBVhost']\n",
        "        for i in range(len(titles)):\n",
        "            ax[i].hist(res_params[i], bins=bins_res[i])\n",
        "            ax[i].set_title(titles[i])\n",
        "            ax[i].set_xlim(xlims[i])\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    if 'zvmu' in choice:\n",
        "        print('[+++] Ploting redshift [z] vs distance mod [mu] of SNooPy Parameters...')\n",
        "        data = np.genfromtxt(BURNS_SAVE_TXT, dtype=str, delimiter=', ', skip_header=1)\n",
        "        objnames, mu, z = data[:, 0], data[:, 1].astype(float), data[:, 2].astype(float)\n",
        "\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        for n in range(len(objnames)):\n",
        "            plt.loglog(z[n], mu[n], label=objnames[n], marker='o')\n",
        "        plt.title('CSP Redshift vs. Distance Mod\\n SNe # = '+str(len(objnames)))\n",
        "        plt.xlabel('Redshift')\n",
        "        plt.ylabel('Distance Mod')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    return\n"
      ],
      "metadata": {
        "id": "RCIf-58euEIX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" GHOST \"\"\"\n",
        "def ghost_host_galaxy(dict_path, save_loc=TEST_ROOT, keep_data=True, update_saved=False):\n",
        "    cosmo = FlatLambdaCDM(70, 0.3) # Hubble Constant, Omega-Matter\n",
        "    data = dict_unpacker(dict_path)\n",
        "    all_z, all_logstellarmass = [], []\n",
        "    print('[+++] Finding host galaxy mass using GHOST...')\n",
        "\n",
        "    i = 0\n",
        "    for obj in data:\n",
        "        ra, dec, z = float(data[obj]['ra']), float(data[obj]['dec']), float(data[obj]['z'])\n",
        "\n",
        "        print('\\n[', list(data).index(obj)+1, '/', len(data), ']', obj, '|', data[obj]['ra'], data[obj]['dec'], data[obj]['z'])\n",
        "        print('---------------------------------------------------------------------------------------------------------')\n",
        "\n",
        "        transient_position = SkyCoord(ra, dec, unit=u.deg)\n",
        "        try:\n",
        "            host_data = getTransientHosts(transientCoord=[transient_position], transientName=[obj], verbose=False, starcut=\"gentle\", savepath=save_loc+'ghost_stuff/', GHOSTpath=GHOST_DATA)\n",
        "\n",
        "            gMag, iMag, iAbsMag = host_data['gKronMag'].loc[0], host_data['iKronMag'].loc[0], (host_data['iKronMag'].loc[0] - cosmo.distmod(z).value)\n",
        "            gMagErr, iMagErr, iAbsMagErr = host_data['gKronMagErr'].loc[0], host_data['iKronMagErr'].loc[0], host_data['iKronMagErr'].loc[0]\n",
        "            giMagErr = np.sqrt((gMagErr**2) + (iMagErr**2))\n",
        "\n",
        "            logstellarmass = (1.15 + (0.7*(gMag - iMag)) - (0.4*(iAbsMag))) # Taylor et. al. 2011 -- eq. 8\n",
        "            logstellarmasserr = np.sqrt(((0.7**2)*(giMagErr**2)) + ((0.4**2)*(iAbsMagErr**2)))\n",
        "\n",
        "        except Exception as error:\n",
        "            print(obj+':', error)\n",
        "            logstellarmass, logstellarmasserr = 0.00, 0.00\n",
        "\n",
        "        if logstellarmass != np.nan and logstellarmass > 0:\n",
        "            print('Success!', obj, 'host galaxy has a mass of:', logstellarmass, '+/-', logstellarmasserr, 'logM_* / [Msun]')\n",
        "            all_z.append(z)\n",
        "            all_logstellarmass.append(logstellarmass)\n",
        "            if update_saved:\n",
        "                data[obj].update({'logstellarmass': logstellarmass, 'logstellarmasserr': logstellarmasserr})\n",
        "        else:\n",
        "            print('Failed to find host galaxy!')\n",
        "            if update_saved:\n",
        "                data[obj].update({'logstellarmass': 0.00, 'logstellarmasserr': 0.00})\n",
        "\n",
        "    print('\\nSuccessfully found mass of', len(all_z), '/', len(data), 'host galaxies!')\n",
        "    if not keep_data:\n",
        "        print('Removing GHOST data...')\n",
        "        shutil.rmtree(save_loc+'ghost_stuff/') # Clear messy data\n",
        "    if update_saved:\n",
        "        print('Saving data to'+dict_path+'...')\n",
        "        dict_packer(data, dict_path)\n",
        "\n",
        "    return all_z, all_logstellarmass\n",
        "\n",
        "def ghost_plotting(choice, plot_size = (18, 6), plot_ratio = [10, 1], hist_bins = [50, 50, 10], labels = True, raw = False):\n",
        "    if 'atlas_all' in choice:\n",
        "        choice = ['altas_muvmass', 'altas_muvz', 'altas_muvmu', 'altas_residualsvz', 'altas_residualsvmass']\n",
        "    if 'burns_all' in choice:\n",
        "        choice = ['burns_muvmass', 'burns_muvz', 'burns_muvmu', 'burns_residualsvz', 'burns_residualsvmass']\n",
        "\n",
        "    if ('burns_muvmass' in choice) or ('altas_muvmass' in choice):\n",
        "        try:\n",
        "            fig, axs = plt.subplots(1, 2, figsize=plot_size, gridspec_kw={'width_ratios': plot_ratio})\n",
        "\n",
        "            if 'burns_muvmass' in choice:\n",
        "                fig.suptitle('Host Mass of CSP 91bg-like SNe Ia') # Figure Title\n",
        "                objs = dict_unpacker(BURNS_SAVE_TXT)\n",
        "            elif 'altas_muvmass' in choice:\n",
        "                fig.suptitle('Host Mass of ATLAS 91bg-like SNe Ia') # Figure Title\n",
        "                objs = dict_unpacker(ATLAS_SAVE_TXT)\n",
        "\n",
        "            mass_hist = []\n",
        "            for obj in objs:\n",
        "                mu, mu_err, mass = float(objs[obj]['mu']), float(objs[obj]['mu_err']), float(objs[obj]['logstellarmass'])\n",
        "                if mass > 0:\n",
        "                    axs[0].errorbar(mu, mass, xerr=mu_err, fmt='o')\n",
        "                    if labels:\n",
        "                        axs[0].text(mu, mass, obj, size='x-small', va='top')\n",
        "                    mass_hist.append(mass)\n",
        "            axs[1].hist(mass_hist, bins=hist_bins[0], orientation=\"horizontal\")\n",
        "\n",
        "            axs[0].set(xlabel='Distance Modulus', ylabel='Host Mass') # Sub-plot Labels\n",
        "            axs[1].get_yaxis().set_visible(False)\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        except KeyError:\n",
        "            print(\"[KeyError] Please run 'ghost_host_galaxy()' before attempting to plot.\")\n",
        "\n",
        "    if ('burns_muvz' in choice) or ('altas_muvz' in choice):\n",
        "        plot_scale = 'linear'\n",
        "        sigma = 3\n",
        "\n",
        "        try:\n",
        "            fig, axs = plt.subplots(1, 2, figsize=plot_size, gridspec_kw={'width_ratios': plot_ratio})\n",
        "\n",
        "            if 'burns_muvz' in choice:\n",
        "                fig.suptitle('Distance Modulus vs. Redshift of CSP 91bg-like SNe Ia)') # Figure Title\n",
        "                objs = dict_unpacker(BURNS_SAVE_TXT)\n",
        "            elif 'altas_muvz' in choice:\n",
        "                fig.suptitle('Distance Modulus vs. Redshift of ATLAS 91bg-like SNe Ia') # Figure Title\n",
        "                objs = dict_unpacker(ATLAS_SAVE_TXT)\n",
        "\n",
        "            # Plot -- mu vs z\n",
        "            mu_hist = []\n",
        "            for obj in objs:\n",
        "                mu, mu_err, z = float(objs[obj]['mu']), float(objs[obj]['mu_err']), float(objs[obj]['z'])\n",
        "                if not raw and mu <= 0:\n",
        "                    continue\n",
        "                axs[0].errorbar(z, mu, yerr=mu_err*sigma, fmt='o')\n",
        "                if labels:\n",
        "                    axs[0].text(z, mu, obj, size='x-small', va='top')\n",
        "                mu_hist.append(mu)\n",
        "            axs[1].hist(mu_hist, bins=hist_bins[1], orientation=\"horizontal\")\n",
        "\n",
        "            # Plot cosmology -- Use the distmod method of the cosmology object\n",
        "            z_cosmo = np.linspace(0.001, 0.08, 100)\n",
        "            axs[0].plot(z_cosmo, COSMO_MODEL.distmod(z_cosmo), alpha=0.4, linewidth=5,\n",
        "                        label='H0:'+str(COSMO_MODEL._H0)+'\\nOm0: '+str(COSMO_MODEL._Om0)+'\\nOde0: '+str(COSMO_MODEL._Ode0))\n",
        "\n",
        "            # Formating\n",
        "            axs[0].set(xlabel='Redshift', ylabel='Distance Modulus') # Sub-plot Labels\n",
        "            axs[0].set_xscale(plot_scale); axs[0].set_yscale(plot_scale)\n",
        "            axs[0].legend()\n",
        "            axs[1].get_yaxis().set_visible(False)\n",
        "            fig.tight_layout()\n",
        "\n",
        "            plt.show()\n",
        "        except KeyError:\n",
        "            print(\"[KeyError] Please run 'snpy_fit()' before attempting to plot.\")\n",
        "\n",
        "    if ('burns_muvmu' in choice) or ('altas_muvmu' in choice):\n",
        "        plot_scale = 'linear'\n",
        "        plt.figure(figsize=plot_size)\n",
        "\n",
        "        try:\n",
        "            if 'burns_muvmu' in choice:\n",
        "                plt.title('SNooPy Distance Modulus vs. Cosmological Distance Modulus of CSP 91bg-like SNe Ia)') # Figure Title\n",
        "                objs = dict_unpacker(BURNS_SAVE_TXT)\n",
        "            elif 'altas_muvmu' in choice:\n",
        "                plt.title('SNooPy Distance Modulus vs. Cosmological Distance Modulus of ATLAS 91bg-like SNe Ia') # Figure Title\n",
        "                objs = dict_unpacker(ATLAS_SAVE_TXT)\n",
        "\n",
        "            # Plot -- mu vs mu\n",
        "            x_mu, y_mu = [], []\n",
        "            for obj in objs:\n",
        "                mu_snpy, z = float(objs[obj]['mu']), float(objs[obj]['z'])\n",
        "                mu_cosmo = COSMO_MODEL.distmod(z).value\n",
        "                plt.scatter(mu_snpy, mu_cosmo, marker='o')\n",
        "                x_mu.append(mu_snpy)\n",
        "                y_mu.append(mu_cosmo)\n",
        "                if labels:\n",
        "                    axs[0].text(mu_snpy, mu_cosmo, obj, size='x-small', va='top')\n",
        "\n",
        "            # Plot trendline\n",
        "            z = np.polyfit(x_mu, y_mu, 1)\n",
        "            p = np.poly1d(z)\n",
        "            plt.plot(x_mu, p(x_mu), alpha=0.4, linewidth=5, label='Trendline: '+\"y=%.6fx+(%.6f)\"%(z[0],z[1]))\n",
        "\n",
        "            # Formating\n",
        "            plt.xlabel('SNooPy Distance Modulus'); plt.ylabel('Cosmological Distance Modulus')\n",
        "            plt.legend()\n",
        "\n",
        "            plt.show()\n",
        "        except KeyError:\n",
        "            print(\"[KeyError] Please run 'snpy_fit()' before attempting to plot.\")\n",
        "\n",
        "    if ('burns_residualsvz' in choice) or ('altas_residualsvz' in choice):\n",
        "        sigma = 3\n",
        "\n",
        "        try:\n",
        "            fig, axs = plt.subplots(1, 2, figsize=plot_size, gridspec_kw={'width_ratios': plot_ratio})\n",
        "            if 'burns_residualsvz' in choice:\n",
        "                fig.suptitle('Hubble Residuals vs. Redshift of CSP 91bg-like SNe Ia\\n '+\n",
        "                             'Dist. Sigma: '+str(sigma)) # Figure Title\n",
        "                objs = dict_unpacker(BURNS_SAVE_TXT)\n",
        "            elif 'altas_residualsvz' in choice:\n",
        "                fig.suptitle('Hubble Residuals vs. Redshift of ATLAS 91bg-like SNe Ia\\n'+\n",
        "                             'Dist. Sigma: '+str(sigma)) # Figure Title\n",
        "                objs = dict_unpacker(ATLAS_SAVE_TXT)\n",
        "\n",
        "            # Compute mu_cosmo\n",
        "            mu_cosmo, mu_snpy, mu_err, z, objnames = np.array([]), np.array([]), np.array([]), np.array([]), np.array([])\n",
        "            for obj in objs:\n",
        "                objnames = np.append(objnames, obj)\n",
        "                z = np.append(z, float(objs[obj]['z']))\n",
        "                mu_err = np.append(mu_err, float(objs[obj]['mu_err']))\n",
        "                mu_snpy = np.append(mu_snpy, float(objs[obj]['mu']))\n",
        "                mu_cosmo = np.append(mu_cosmo, COSMO_MODEL.distmod(float(objs[obj]['z'])).value)\n",
        "            mu_res = (mu_snpy - mu_cosmo) - np.average(mu_snpy - mu_cosmo)\n",
        "\n",
        "            # Plot -- mu vs z\n",
        "            mu_hist = []\n",
        "            for n in range(len(objnames)):\n",
        "                if not raw and z[n] < 0.01:\n",
        "                    continue\n",
        "                axs[0].errorbar(z[n], mu_res[n], yerr=mu_err[n]*sigma, label=objnames[n], fmt=\"o\")\n",
        "                mu_hist.append(mu_res[n])\n",
        "                if labels:\n",
        "                    axs[0].text(z[n], mu_res[n], objnames[n], size='x-small', va='top')\n",
        "            axs[1].hist(mu_hist, bins=hist_bins[2], orientation=\"horizontal\")\n",
        "\n",
        "            # Formatting\n",
        "            axs[0].set(xlabel='Redshift', ylabel='Hubble Residuals') # Sub-plot Labels\n",
        "            axs[1].get_yaxis().set_visible(False)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # Limits\n",
        "            ylimiter = (np.max(np.abs(mu_hist)) + np.max(mu_err*sigma)) + 0.01\n",
        "            ylimiter = 2\n",
        "            axs[0].set_ylim(-ylimiter, ylimiter); axs[1].set_ylim(-ylimiter, ylimiter)\n",
        "\n",
        "            plt.show()\n",
        "        except KeyError:\n",
        "            print(\"[KeyError] Please run 'snpy_fit()' before attempting to plot.\")\n",
        "\n",
        "    if ('burns_residualsvmass' in choice) or ('altas_residualsvmass' in choice):\n",
        "        sigmas = [3, 3]\n",
        "        objsRemove = ['2022skw', '2023cvq']\n",
        "\n",
        "        try:\n",
        "            fig, axs = plt.subplots(1, 2, figsize=plot_size, gridspec_kw={'width_ratios': plot_ratio})\n",
        "\n",
        "            if 'burns_residualsvmass' in choice:\n",
        "                fig.suptitle('Hubble Residuals vs. Host Mass of CSP 91bg-like SNe Ia\\n '+\n",
        "                             'Dist. Sigma: '+str(sigmas[0])+' | Mass Sigma: '+str(sigmas[1])) # Figure Title\n",
        "                objs = dict_unpacker(BURNS_SAVE_TXT)\n",
        "            elif 'altas_residualsvmass' in choice:\n",
        "                fig.suptitle('Hubble Residuals vs. Host Mass of ATLAS 91bg-like SNe Ia\\n '+\n",
        "                             'Dist. Sigma: '+str(sigmas[0])+' | Mass Sigma: '+str(sigmas[1])) # Figure Title\n",
        "                objs = dict_unpacker(ATLAS_SAVE_TXT)\n",
        "\n",
        "            # Compute mu_cosmo\n",
        "            mu_cosmo, mu_snpy, mu_err, mass, mass_err, objnames = np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([])\n",
        "            for obj in objs:\n",
        "                if obj in objsRemove:\n",
        "                    continue\n",
        "                objnames = np.append(objnames, obj)\n",
        "                mass = np.append(mass, float(objs[obj]['logstellarmass']))\n",
        "                mass_err = np.append(mass_err, float(objs[obj]['logstellarmasserr']))\n",
        "                mu_err = np.append(mu_err, float(objs[obj]['mu_err']))\n",
        "                mu_snpy = np.append(mu_snpy, float(objs[obj]['mu']))\n",
        "                mu_cosmo = np.append(mu_cosmo, COSMO_MODEL.distmod(float(objs[obj]['z'])).value)\n",
        "            mu_res = (mu_snpy - mu_cosmo) - np.average(mu_snpy - mu_cosmo)\n",
        "\n",
        "            # Plot -- mu vs z\n",
        "            mu_hist = []\n",
        "            for n in range(len(objnames)):\n",
        "                if not raw and mass[n] <= 0:\n",
        "                    continue\n",
        "                axs[0].errorbar(mass[n], mu_res[n], xerr=mass_err[n]*sigmas[1], yerr=mu_err[n]*sigmas[0], fmt='o')\n",
        "                mu_hist.append(mu_res[n])\n",
        "                if labels:\n",
        "                    axs[0].text(mass[n], mu_res[n], objnames[n], size='x-small', va='top')\n",
        "            axs[1].hist(mu_hist, bins=hist_bins[3], orientation=\"horizontal\")\n",
        "\n",
        "            # Formatting\n",
        "            axs[0].set(xlabel='Host Mass', ylabel='Hubble Residuals') # Sub-plot Labels\n",
        "            axs[1].get_yaxis().set_visible(False)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # Limits\n",
        "            ylimiter = (np.max(np.abs(mu_hist)) + np.max(mu_err*sigmas[0])) + 0.01\n",
        "            axs[0].set_ylim(-ylimiter, ylimiter); axs[1].set_ylim(-ylimiter, ylimiter)\n",
        "            # axs[0].set_xlim(9.75, 11.5); axs[1].set_xlim(9.75, 11.5)\n",
        "\n",
        "            plt.show()\n",
        "        except KeyError:\n",
        "            print(\"[KeyError] Please run 'snpy_fit()' before attempting to plot.\")\n",
        "\n",
        "    if ('burns_res_zcorr' in choice) or ('altas_res_zcorr' in choice):\n",
        "        sigma = 0\n",
        "        objsRemove = ['2022skw', '2023cvq']\n",
        "\n",
        "        try:\n",
        "            fig, axs = plt.subplots(1, 2, figsize=plot_size, gridspec_kw={'width_ratios': plot_ratio})\n",
        "            if 'burns_res_zcorr' in choice:\n",
        "                fig.suptitle('Hubble Residuals vs. Redshift of CSP 91bg-like SNe Ia\\n '+\n",
        "                             'Dist. Sigma: '+str(sigma)) # Figure Title\n",
        "                objs = dict_unpacker(BURNS_SAVE_TXT)\n",
        "            elif 'altas_res_zcorr' in choice:\n",
        "                fig.suptitle('Hubble Residuals vs. Redshift of ATLAS 91bg-like SNe Ia\\n'+\n",
        "                             'Dist. Sigma: '+str(sigma)) # Figure Title\n",
        "                objs = dict_unpacker(ATLAS_SAVE_TXT)\n",
        "\n",
        "            # Compute mu_cosmo\n",
        "            mu_cosmo, mu_snpy, mu_err, z, objnames = np.array([]), np.array([]), np.array([]), np.array([]), np.array([])\n",
        "            for obj in objs:\n",
        "                if not raw and float(objs[obj]['z']) < 0.01:\n",
        "                    continue\n",
        "                elif obj in objsRemove:\n",
        "                    continue\n",
        "                objnames = np.append(objnames, obj)\n",
        "                z = np.append(z, float(objs[obj]['z']))\n",
        "                mu_err = np.append(mu_err, float(objs[obj]['mu_err']))\n",
        "                mu_snpy = np.append(mu_snpy, float(objs[obj]['mu']))\n",
        "                mu_cosmo = np.append(mu_cosmo, COSMO_MODEL.distmod(float(objs[obj]['z'])).value)\n",
        "            mu_res = (mu_snpy - mu_cosmo) - np.average(mu_snpy - mu_cosmo)\n",
        "\n",
        "            # Plot -- mu vs z\n",
        "            mu_hist = []\n",
        "            for n in range(len(objnames)):\n",
        "\n",
        "                axs[0].errorbar(z[n], mu_res[n], yerr=mu_err[n]*sigma, label=objnames[n], fmt=\"o\")\n",
        "                mu_hist.append(mu_res[n])\n",
        "                if labels:\n",
        "                    axs[0].text(z[n], mu_res[n], objnames[n], size='x-small', va='top')\n",
        "            axs[1].hist(mu_hist, bins=hist_bins[2], orientation=\"horizontal\")\n",
        "\n",
        "            # Formatting\n",
        "            axs[0].set(xlabel='Redshift', ylabel='Hubble Residuals') # Sub-plot Labels\n",
        "            axs[1].get_yaxis().set_visible(False)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # Limits\n",
        "            ylimiter = (np.max(np.abs(mu_hist)) + np.max(mu_err*sigma)) + 0.1\n",
        "            axs[0].set_ylim(-ylimiter, ylimiter); axs[1].set_ylim(-ylimiter, ylimiter)\n",
        "\n",
        "            # Redshift correction\n",
        "            # chi2 = malmquist_bias_corr(mu_res, z, mu_err, m, b)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            plt.close()\n",
        "            # plt.show()\n",
        "        except KeyError:\n",
        "            print(\"[KeyError] Please run 'snpy_fit()' before attempting to plot.\")\n",
        "\n",
        "\n",
        "    return\n"
      ],
      "metadata": {
        "id": "v-FkXLx96Tx0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" MAIN \"\"\"\n",
        "if __name__ == '__main__':\n",
        "    start = systime.time() # Runtime tracker\n",
        "\n",
        "    recover_dir() # Recovering vital directories\n",
        "\n",
        "    # burns_cspvdr3(skip_problems=False, use_saved=False, snpy_plots=False)\n",
        "    # ghost_host_galaxy(BURNS_SAVE_TXT, save_loc=TEST_ROOT, keep_data=False, update_saved=True)\n",
        "\n",
        "    # atlas_collection(quiet=False, check_data=True)\n",
        "    # atlas_objs = atlas_processing(err_max=1000, n_iter=0, sleep_t=5, use_TNS=True)\n",
        "    # write_ASCII(atlas_objs, SNPY_ATLAS_ASCII, quiet=True)\n",
        "    # atlas_snpy_fitting(n_iter=0, skip_problems=False, use_saved=False, snpy_plots=True, save_plots=True)\n",
        "    # ghost_host_galaxy(ATLAS_SAVE_TXT, save_loc=TEST_ROOT, keep_data=True, update_saved=True)\n",
        "\n",
        "    # ztf_collection(submit=True)\n",
        "    # ztf_alt_collection()\n",
        "\n",
        "    # burns_plotting([]) # Options: ['reg_hist', 'res_hist', 'zvmu']\n",
        "\n",
        "    # atlas_plotting([])\n",
        "\n",
        "    ghost_plot_args = {'plot_size': (18, 6), 'plot_ratio': [10, 1], 'hist_bins': [40, 40, 35, 35], 'labels': False, 'raw': False}\n",
        "    ghost_plotting(['atlas_all'], **ghost_plot_args)\n",
        "\n",
        "    # snpy_fit_indv('2023cvq')\n",
        "\n",
        "    print('|---------------------------|\\n Run-time: ', round(systime.time()-start, 4), 'seconds\\n|---------------------------|')"
      ],
      "metadata": {
        "id": "yO9qvltNuI9Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}