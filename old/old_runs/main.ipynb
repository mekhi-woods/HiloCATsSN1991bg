{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyMUSfGrMcOAE9HoGFHedyuT",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mekhi-woods/HiloCATsSN1991bg/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# \"\"\" DEPRICATED FUNCTIONS \"\"\"\n",
    "# Open\n",
    "    # def plot_SNooPy_mu_vs_z(save_plot=True, saveLoc=SNPY_DATA_ATLAS_PATH):\n",
    "    #     data = np.genfromtxt(ROOT_SAVE+'ATLAS_variables.txt', delimiter=', ', dtype=str, skip_header=1)\n",
    "    #     name, mu, z = data[:, 0], data[:, 7].astype(float), data[:, 4].astype(float)\n",
    "\n",
    "    #     print(mu)\n",
    "    #     print(z)\n",
    "\n",
    "\n",
    "    #     for n in range(len(name)):\n",
    "    #         plt.loglog(z[n], mu[n], 'o')\n",
    "    #         if z[n] < 0.0125:\n",
    "    #             plt.text(z[n], mu[n], name[n], fontsize='xx-small')\n",
    "    #     plt.xlabel('Redshift [z]'); plt.ylabel('Distance Modulus [mu]')\n",
    "    #     plt.title('ATLAS SNe -- Fitted with SNooPy \\nDistance Modulus v. Redshift')\n",
    "    #     if save_plot:\n",
    "    #         plt.savefig(saveLoc+'SNooPy_mu_vs_z.png')\n",
    "    #     plt.show()\n",
    "    #     return\n",
    "\n",
    "    # def plot_DvD(snpyDistances, burnsDistances, size=(8, 5), save=False):\n",
    "    #     print(\"Ploting differences in distance calculations...\")\n",
    "    #     plt.figure(figsize=size)\n",
    "    #     for x in snpyDistances:\n",
    "    #         try:\n",
    "    #             plt.scatter(burnsDistances[x], snpyDistances[x], marker='o')\n",
    "    #             plt.text(burnsDistances[x]+0.05, snpyDistances[x]-0.05, x, fontsize='xx-small')\n",
    "    #             print('Burns Distance:', burnsDistances[x], '| SNooPy Distance:', snpyDistances[x])\n",
    "    #         except KeyError:\n",
    "    #             print(x, 'not found.')\n",
    "    #             pass\n",
    "    #     plt.title(\"Burns v. SNooPy Distance\")\n",
    "    #     plt.xlabel('Burns Distance'); plt.ylabel('SNooPy Distance')\n",
    "    #     plt.xlim(min(burnsDistances.values()), max(burnsDistances.values()))\n",
    "    #     plt.ylim(min(burnsDistances.values()), max(burnsDistances.values()))\n",
    "\n",
    "    #     if save:\n",
    "    #         plt.savefig('burns_v_snpy_dist.png')\n",
    "\n",
    "    #     plt.show()\n",
    "    #     return\n",
    "\n",
    "    # def plot_residuals(snpyDistances, burnsDistances, snpyRedshifts, size=(8,5), save=False):\n",
    "    #     print(\"Ploting residuals...\")\n",
    "    #     plt.figure(figsize=size)\n",
    "    #     for x in snpyDistances:\n",
    "    #         try:\n",
    "    #             plt.scatter(snpyRedshifts[x], abs(burnsDistances[x]-snpyDistances[x]), marker='o')\n",
    "    #             plt.text(snpyRedshifts[x], abs(burnsDistances[x]-snpyDistances[x]), x, fontsize='xx-small')\n",
    "    #             print('Redshift:', snpyRedshifts[x], '| Burns-SNooPy Distance:', burnsDistances[x]-snpyDistances[x])\n",
    "    #         except KeyError:\n",
    "    #             print(x, 'not found.')\n",
    "    #             pass\n",
    "    #     plt.title(\"Burns-SNooPy Residuals\"); plt.xlabel('Redshift'); plt.ylabel('Burns-SNooPy')\n",
    "    #     if save:\n",
    "    #         plt.savefig('burns-snpy_res.png')\n",
    "    #     plt.show()\n",
    "    #     return\n",
    "\n",
    "    # def plot_91bglike_SN1a(FILTER_WHEEL = ['u', 'g', 'r', 'i', 'B', 'V0']):\n",
    "        # KrisciunasPath = \"/content/HiloCATsSN1991bg/targetLists/91bglike_justnames.txt\"\n",
    "        # KrisciunasNames = np.genfromtxt(KrisciunasPath, dtype=str, delimiter=', ')\n",
    "\n",
    "        # allCPSPhot = \"/content/HiloCATsSN1991bg/data/CSPdata/SN_photo.dat\"\n",
    "        # allCPSPhotData = np.genfromtxt(allCPSPhot, dtype='str')\n",
    "\n",
    "        # names = allCPSPhotData[:,0]\n",
    "        # filters = allCPSPhotData[:,1]\n",
    "        # time = allCPSPhotData[:,2]\n",
    "        # light = allCPSPhotData[:,3]\n",
    "        # err = allCPSPhotData[:,4]\n",
    "\n",
    "        # plt.figure(figsize=(10,6))\n",
    "        # sigma = 1\n",
    "        # for tar in KrisciunasNames:\n",
    "        #     for n in range(len(FILTER_WHEEL)):\n",
    "        #         # output_names = names[(names == tar) & (filters == FILTER_WHEEL[n])]\n",
    "        #         output_light = light[(names == tar) & (filters == FILTER_WHEEL[n])].astype('float64')\n",
    "        #         output_time = time[(names == tar) & (filters == FILTER_WHEEL[n])].astype('float64') + 53000\n",
    "        #         output_err = err[(names == tar) & (filters == FILTER_WHEEL[n])].astype('float64')\n",
    "        #         plt.errorbar(output_time, output_light, yerr=output_err*sigma, fmt='o', label=FILTER_WHEEL[n])\n",
    "\n",
    "        #     plt.title(tar); plt.xlabel('Time [MJD]'); plt.ylabel('Intensity [mag]')\n",
    "        #     plt.gca().invert_yaxis()\n",
    "        #     plt.legend()\n",
    "        #     # plt.savefig('save\\\\'+str(tar)+'.png')\n",
    "        #     plt.show()\n",
    "        #     break\n",
    "        # return\n",
    "\n",
    "    # def plot_DR3_tmax_st_EBVhost():\n",
    "        # data = np.genfromtxt('/content/HiloCATsSN1991bg/DR3_fits.dat', dtype=str, skip_header=1)\n",
    "        # DR3_st = np.stack((data[:, 1].astype(float), data[:, 2].astype(float)), axis=1)\n",
    "        # DR3_Tmax = np.stack((data[:, 5].astype(float), data[:, 6].astype(float)), axis=1)\n",
    "        # DR3_EBVhost = np.stack((data[:, 25].astype(float), data[:, 26].astype(float)), axis=1)\n",
    "\n",
    "        # fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,5))\n",
    "        # fig.suptitle(\"DR3's Tmax vs. st vs EBVhost\")\n",
    "        # sigmas = [[1, 1], [1, 1], [1, 1]]\n",
    "\n",
    "        # # Tmax vs. st\n",
    "        # ax1.errorbar(DR3_Tmax[:, 0], DR3_st[:, 0],\n",
    "        #              xerr=DR3_Tmax[:, 1]*sigmas[0][0], yerr=DR3_st[:, 1]*sigmas[0][1],\n",
    "        #              fmt='yo')\n",
    "        # ax1.set_xlabel('Tmax'); ax1.set_ylabel('st')\n",
    "        # ax1.set_title('Tmax vs. st, sigma(x='+str(sigmas[0][0])+', y='+str(sigmas[0][1])+')')\n",
    "\n",
    "        # # st vs. EBVhost\n",
    "        # ax2.errorbar(DR3_st[:, 0], DR3_EBVhost[:, 0],\n",
    "        #              xerr=DR3_st[:, 1]*sigmas[1][0], yerr=DR3_EBVhost[:, 1]*sigmas[1][1],\n",
    "        #              fmt='bo')\n",
    "        # ax2.set_xlabel('st'); ax2.set_ylabel('EBVhost')\n",
    "        # ax2.set_title('st vs. EBVhost, sigma(x='+str(sigmas[1][0])+', y='+str(sigmas[1][1])+')')\n",
    "\n",
    "        # # Tmax vs. EBVhost\n",
    "        # ax3.errorbar(DR3_Tmax[:, 0], DR3_EBVhost[:, 0],\n",
    "        #              xerr=DR3_Tmax[:, 1]*sigmas[2][0], yerr=DR3_EBVhost[:, 1]*sigmas[2][1],\n",
    "        #              fmt='ro')\n",
    "        # ax3.set_xlabel('Tmax'); ax3.set_ylabel('EBVhost')\n",
    "        # ax3.set_title('Tmax vs. EBVhost, sigma(x='+str(sigmas[2][0])+', y='+str(sigmas[2][1])+')')\n",
    "\n",
    "        # plt.show()\n",
    "        # return\n",
    "\n",
    "    # def snpy_fit(filePath, model='max_model', shapeParam='dm15', BandsToFit = ['B','g','r','i'], summarize=True, saveplots=False, saveLoc=SNPY_DATA_ATLAS_PATH, show_plots=True):\n",
    "        # s = snpy.get_sn(filePath)\n",
    "\n",
    "        # # Set model parameters\n",
    "        # s.choose_model(model, stype=shapeParam)\n",
    "        # s.set_restbands() # Auto pick appropriate rest-bands\n",
    "\n",
    "        # # Fit data -- using David configurations\n",
    "        # fitargs = {'mangle':1,'calibration':0, 'quiet':False} # I don't remember what calibration is\n",
    "        # s.fit(BandsToFit,\n",
    "        #       dokcorr=True,\n",
    "        #       k_stretch=False,\n",
    "        #       reset_kcorrs=True,\n",
    "        #       **fitargs)\n",
    "\n",
    "        # # Show results\n",
    "        # if summarize:\n",
    "        #     s.summary()\n",
    "        #     # for param in s.parameters:\n",
    "        #     #     print(\"{} = {} +/- {}\".format(param, s.parameters[param], s.errors[param]))\n",
    "        # if saveplots:\n",
    "        #     print('Plot saved to', SNPY_DATA_ATLAS_PATH+filePath[-17:-9]+'_snpyplots.png')\n",
    "        #     s.plot(outfile=SNPY_DATA_ATLAS_PATH+filePath[-17:-9]+'_snpyplots.png')\n",
    "        #     if show_plots:\n",
    "        #         plt.show()\n",
    "        #     else:\n",
    "        #         plt.close()\n",
    "\n",
    "        #     with ZipFile(SNPY_DATA_ATLAS_PATH+'snpyplots.zip', 'a') as zip_object:\n",
    "        #         zip_object.write(SNPY_DATA_ATLAS_PATH+filePath[-17:-9]+'_snpyplots.png')\n",
    "\n",
    "        # return s\n",
    "\n",
    "    # def SNooPy2_fitting(dataPath, tarNames, model='EBV_model2', shape='st', bands=['B','g','r','i'], output=False, snpyPlots=False, show_plots=True, use_saved=True):\n",
    "        # PROBLEM_CHILDREN = []\n",
    "\n",
    "        # if len(bands) == 0:\n",
    "        #     bands = None\n",
    "\n",
    "        # tarPaths = []\n",
    "        # for tar in tarNames:\n",
    "        #     tarPaths.append(dataPath+str(tar))\n",
    "\n",
    "        # SNe_mu = {}\n",
    "        # SNe_z = {}\n",
    "        # SNe_params = {}\n",
    "\n",
    "        # for i in range(len(tarPaths)):\n",
    "        #     tarName = tarNames[i][:-9]\n",
    "        #     tarSave = SNPY_ROOT+tarName+'_'+model+'.snpy'\n",
    "        #     print('[ '+str(i+1)+' / '+str(len(tarPaths))+'] Fiting data for '+tarName+'...')\n",
    "\n",
    "        #     # Create/Retrieve Fit\n",
    "        #     valid = True\n",
    "\n",
    "        #     if os.path.exists(tarSave) and use_saved:\n",
    "        #         print(tarName, 'found in files! Pulling data...')\n",
    "        #         s_n = snpy.get_sn(tarSave)\n",
    "        #     elif os.path.exists(tarPaths[i]):\n",
    "        #         try:\n",
    "        #             s_n = snpy_fit(tarPaths[i],\n",
    "        #                             model=model,\n",
    "        #                             shapeParam=shape,\n",
    "        #                             BandsToFit=None,\n",
    "        #                             summarize=output,\n",
    "        #                             saveplots=snpyPlots,\n",
    "        #                             saveLoc=SNPY_DATA_ATLAS_PATH,\n",
    "        #                             show_plots=show_plots) # Enter snpy fit function\n",
    "        #         except ValueError:\n",
    "        #             PROBLEM_CHILDREN.append(tarName)\n",
    "        #             print('[!!!] ValueError: No data near maximum light... skipping\\n')\n",
    "        #             valid = False\n",
    "        #         except RuntimeError:\n",
    "        #             PROBLEM_CHILDREN.append(tarName)\n",
    "        #             print('[!!!] RuntimeError: Model has trailed off fitting filter... skipping\\n')\n",
    "        #             valid = False\n",
    "        #         except TypeError:\n",
    "        #             PROBLEM_CHILDREN.append(tarName)\n",
    "        #             print('[!!!] TypeError: m > k must hold (I have no clue what this means)... skipping\\n')\n",
    "        #             valid = False\n",
    "        #         except:\n",
    "        #             PROBLEM_CHILDREN.append(tarName)\n",
    "        #             print('[!!!] Unknown Error... skipping\\n')\n",
    "        #             valid = False\n",
    "        #     else:\n",
    "        #         print(tarName, 'does not exsist in CSP data... skipping')\n",
    "        #         valid = False\n",
    "\n",
    "        #     if valid:\n",
    "        #         # Save model\n",
    "        #         s_n.save(tarSave)\n",
    "\n",
    "        #         # Pull SNooPY distance\n",
    "        #         snpy_mu = s_n.get_distmod() # Nab paramaters from SNe objects)\n",
    "\n",
    "        #         # Update dictionary/list\n",
    "        #         SNe_mu.update({tarName: snpy_mu})\n",
    "        #         SNe_z.update({tarName: s_n.z})\n",
    "        #         SNe_params.update({tarName: [s_n.st, s_n.Tmax, s_n.EBVhost, s_n.DM]})\n",
    "\n",
    "        #         # Print info\n",
    "        #         print('Redshift:\\t z = '+str(s_n.z))\n",
    "        #         print('Distance: \\t mu = '+str(round(snpy_mu, 4))+'\\n')\n",
    "\n",
    "        # print('Problem children:\\n', '[', len(PROBLEM_CHILDREN), ']', PROBLEM_CHILDREN)\n",
    "        # plt.close()\n",
    "        # return SNe_mu, SNe_z, SNe_params\n",
    "\n",
    "    # def ztf_query(targets, jds, jde):\n",
    "        # print(\"Number of (ra, dec) pairs =\", len(targets))\n",
    "\n",
    "        # ralist = []\n",
    "        # declist = []\n",
    "        # i = 0\n",
    "        # for tar in targets:\n",
    "        #     raval = float('%.7f'%(float(tar[0])))\n",
    "        #     decval = float('%.7f'%(float(tar[1])))\n",
    "        #     ralist.append(raval)\n",
    "        #     declist.append(decval)\n",
    "        #     i = i + 1\n",
    "        #     rem = i % 1500 # Limit submission to 1500 sky positions.\n",
    "        #     if rem == 0:\n",
    "        #         ztf_submit_post(ralist, declist, jds, jde)\n",
    "        #         ralist = []\n",
    "        #         declist = []\n",
    "        # if len(ralist) > 0:\n",
    "        #     ztf_submit_post(ralist, declist, jds, jde)\n",
    "        # return\n",
    "\n",
    "    # def ATLAS_snpy_fitting(SNe, ATLASnames, show_plot=True, use_saved=True):\n",
    "        # SNe_mu, SNe_z, SNe_params = SNooPy2_fitting(SNPY_DATA_ATLAS_PATH,\n",
    "        #                                             ATLASnames,\n",
    "        #                                             model='EBV_model2', shape='st', bands=['ATri', 'ATgr'],\n",
    "        #                                             output=True, snpyPlots=True, show_plots=show_plot, use_saved=use_saved)\n",
    "        # SNe_new = []\n",
    "        # for SN in SNe:\n",
    "        #     try:\n",
    "        #         SN.mu = SNe_mu[SN.objname]\n",
    "        #         SN.z = SNe_z[SN.objname]\n",
    "        #         SN.st = SNe_params[SN.objname][0]\n",
    "        #         SN.Tmax = SNe_params[SN.objname][1]\n",
    "        #         SN.EBVhost = SNe_params[SN.objname][2]\n",
    "        #         SN.DM = SNe_params[SN.objname][3]\n",
    "        #         SNe_new.append(SN)\n",
    "        #     except KeyError:\n",
    "        #         print(SN.objname, 'is a problem child, removing...')\n",
    "\n",
    "        # # Save distance mod\n",
    "        # params = np.genfromtxt(ROOT_SAVE+'ATLAS_variables.txt', delimiter=', ', dtype=str, skip_header=1)\n",
    "        # with open(ROOT_SAVE+'ATLAS_variables_mu.txt', 'w') as f:\n",
    "        #     f.write('objname, ATLASname, RA, DEC, z, tmin, tmax, mu\\n')\n",
    "        #     for n in range(len(SNe_new)):\n",
    "        #         f.write(str(params[n, 0])+', '+str(params[n, 1])+', '+str(params[n, 2])+', '+str(params[n, 3])+', '+\n",
    "        #                 str(params[n, 4])+', '+str(params[n, 5])+', '+str(params[n, 6])+', '+str(SNe_new[n].mu)+'\\n')\n",
    "\n",
    "        # return SNe_new\n",
    "\n",
    "    # def ATLAS_main_processing(err_max=100, yaxis='flux', t_lim = 0.1, n_iter = 0, plot_mode = 'SOLO', show_plot=True, use_saved=True):\n",
    "        # # [2.1] Aquire Data\n",
    "        # print('[2.1] Retrieving data from...', DATA_ATLAS_PATH)\n",
    "        # files = glob.glob(DATA_ATLAS_PATH+'/*')\n",
    "        # PROBLEM_CHILDREN = ['1032212120425304400']   # Running list of problematic SNe\n",
    "        #                                             # '1032212120425304400' - David believes it might be a shock breakout but ATLAS reports it as SN1a\n",
    "        #                                             #\n",
    "        # # [2.2] Validate Data\n",
    "        # print('[2.2] Sorting data...')\n",
    "        # SNe = []\n",
    "        # for n in range(len(files)):\n",
    "        #     print('[', n+1, '/', len(files), '] Validating data for...', files[n][48:-4])\n",
    "        #     result = slice_data(path=files[n], err_max=err_max)\n",
    "        #     if result != None:\n",
    "        #         SNe.append(result)\n",
    "        #     else:\n",
    "        #         PROBLEM_CHILDREN.append(files[n][48:-4])\n",
    "        #     if n_iter != 0 and n+1 >= n_iter:\n",
    "        #         break\n",
    "\n",
    "        # # [2.3] Remove problem children\n",
    "        # print('[2.3] Problem Children: ', PROBLEM_CHILDREN)\n",
    "        # for SN in SNe:\n",
    "        #     for probname in PROBLEM_CHILDREN:\n",
    "        #         if SN.ATLASname == probname:\n",
    "        #             print('Removing...', SN.ATLASname)\n",
    "\n",
    "        # # [2.4] Save RA, DEC, Redshift, and Object Name\n",
    "        # print('[2.4] Saving parameters to file...')\n",
    "        # print(t_lim, 'second pause between entries...')\n",
    "        # TNS_obj_detection(SNe, t_lim=t_lim, use_saved=use_saved)\n",
    "\n",
    "        # # [2.5] Plot data\n",
    "        # if plot_mode == 'SOLO':\n",
    "        #     print(\"[2.5] Plotting data [indivisual]...\")\n",
    "        #     with ZipFile(PLOTS_ATLAS_PATH+'/ATLASplots.zip', 'w') as zip_object:\n",
    "        #         for SN in SNe:\n",
    "        #             solo_plotting(name=SN.ATLASname, coords=[SN.RA, SN.DEC], err_max=err_max,\n",
    "        #                           t_o=SN.t_o, flux_o=SN.flux_o, flux_err_o=SN.dflux_o,\n",
    "        #                           t_c=SN.t_c, flux_c=SN.flux_c, flux_err_c=SN.dflux_c,\n",
    "        #                           save=True, saveLoc=PLOTS_ATLAS_PATH, show_plot=show_plot)\n",
    "        #             zip_object.write(PLOTS_ATLAS_PATH+SN.ATLASname+'_ATLASplot.png')\n",
    "        #             print('Plot saved to', PLOTS_ATLAS_PATH+SN.ATLASname+'_ATLASplot.png')\n",
    "        # elif plot_mode == 'COMBINED':\n",
    "        #     print(\"[2.5] Plotting data [combined]...\")\n",
    "        #     fig, axs = plt.subplots(len(SNe), figsize=(12, len(SNe)*3.2))\n",
    "        #     fig.tight_layout(pad=5.0)\n",
    "        #     for n in range(len(SNe)):\n",
    "        #         combined_plotting(ax=axs[n], name=SN.ATLASname, coords=[SN.RA, SN.DEC],\n",
    "        #                           t_o=SNe[n].t_o, flux_o=SNe[n].flux_o, flux_err_o=SNe[n].dflux_o,\n",
    "        #                           t_c=SN.t_c, flux_c=SN.flux_c, flux_err_c=SN.dflux_c)\n",
    "        #     plt.savefig(PLOTS_ATLAS_PATH+'CombinedATLASplots.png')\n",
    "        #     print('Plot saved to', PLOTS_ATLAS_PATH+'CombinedATLASplots.png')\n",
    "        #     if show_plot:\n",
    "        #         plt.show()\n",
    "        #     else:\n",
    "        #         plt.close()\n",
    "\n",
    "        # return SNe\n",
    "\n",
    "    # def snpy_ASCII_formatting(SNe):\n",
    "        # knownVariables = {}\n",
    "        # skip_header = True\n",
    "        # with open(ROOT_SAVE+'ATLAS_variables.txt', 'r') as f:\n",
    "        #     for line in f.readlines():\n",
    "        #         if skip_header:\n",
    "        #             skip_header = False\n",
    "        #             pass\n",
    "        #         else:\n",
    "        #             line = line[:-1].split(', ')\n",
    "        #             name = line[1]\n",
    "        #             line.remove(name)\n",
    "        #             knownVariables.update({name : line})\n",
    "\n",
    "        # ATLASnames = []\n",
    "        # for SN in SNe:\n",
    "        #     ATLASnames.append(str(SN.objname)+'_snpy.txt')\n",
    "        #     with open(SNPY_DATA_ATLAS_PATH+str(SN.objname)+'_snpy.txt', 'w') as f:\n",
    "        #         # Line 1\n",
    "        #         # Ex. SN1981D 0.005871 50.65992 -37.23272\n",
    "        #         #     Name    Helio Z  RA        Dec\n",
    "        #         try:\n",
    "        #             SN.objname = knownVariables[SN.ATLASname][0]\n",
    "        #         except KeyError:\n",
    "        #             print('No saved data for...', SN.ATLASname)\n",
    "        #         f.write(str(SN.objname)+' '+str(SN.z)+' '+str(SN.RA)+' '+str(SN.DEC)+'\\n')\n",
    "        #         print(str(SN.objname)+' '+str(SN.z)+' '+str(SN.RA)+' '+str(SN.DEC))\n",
    "\n",
    "        #         # 'ATri'-filter photometry block\n",
    "        #         # Ex. filter O\n",
    "        #         #     674.8593      12.94   0.11\n",
    "        #         #     Date (JD/MJD) mag     err\n",
    "        #         f.write('filter ATri\\n')\n",
    "        #         for i in range(len(SN.t_o)):\n",
    "        #             f.write(str(SN.t_o[i])+'\\t'+str(SN.mag_o[i])+'\\t'+str(SN.dmag_o[i])+'\\n')\n",
    "\n",
    "        #         # # 'ATgr'-filter photometry block\n",
    "        #         f.write('filter ATgr\\n')\n",
    "        #         for i in range(len(SN.t_c)):\n",
    "        #             f.write(str(SN.t_c[i])+'\\t'+str(SN.mag_c[i])+'\\t'+str(SN.dmag_c[i])+'\\n')\n",
    "        # return ATLASnames\n",
    "\n",
    "    # def data_collection(path=DATA_ATLAS_PATH, quiet=False):\n",
    "            # if os.path.exists(ROOT_SAVE+'tmp.npz'):\n",
    "            #     pickle = np.load(ROOT_SAVE+'tmp.npz', allow_pickle=True)\n",
    "            #     data = pickle['data']\n",
    "\n",
    "            # data = requests.post(\n",
    "            #     'https://star.pst.qub.ac.uk/sne/atlas4/api/objectlist/',\n",
    "            #     headers={'Authorization': f'Token {API_TOKEN}'},\n",
    "            #     data={'objectlistid':2}\n",
    "            # ).json()\n",
    "\n",
    "            # np.savez(ROOT_SAVE+'tmp.npz', data=data)\n",
    "\n",
    "            # count = 0\n",
    "            # for d in data:\n",
    "            #     if d['observation_status'] is not None and d['observation_status'].startswith('SN Ia') and '91bg' in d['observation_status']:\n",
    "            #         count += 1\n",
    "            #         if not quiet:\n",
    "            #             print(d['atlas_designation'],d['observation_status'].replace(' ',''),d['ra'],d['dec'])\n",
    "\n",
    "\n",
    "            #         ids = d['id']\n",
    "            #         base_url = 'https://star.pst.qub.ac.uk/sne/atlas4/lightcurveforced/1161048951013729300/'\n",
    "            #         new_url = base_url.replace('1161048951013729300/',str(ids))\n",
    "            #         if not quiet:\n",
    "            #             print(new_url)\n",
    "\n",
    "            #         idfile = path+'/' + str(ids)+'.txt'\n",
    "            #         if os.path.exists(idfile):\n",
    "            #             continue\n",
    "            #         urllib.request.urlretrieve(str(new_url), str(idfile))\n",
    "            #         if not quiet:\n",
    "            #             print(idfile)\n",
    "\n",
    "            #     if count > 300:\n",
    "            #         break\n",
    "\n",
    "    # def slice_data(path, err_max=100):\n",
    "        # name = path[48:-4]\n",
    "        # data = np.genfromtxt(path, dtype=str, delimiter=',')\n",
    "\n",
    "        # if len(data) == 0:\n",
    "        #     print('[!!!] File '+name+' empty...skipping')\n",
    "        #     return None\n",
    "\n",
    "        # filters = data[:, 6]\n",
    "        # t = data[:, 8].astype(float)\n",
    "        # flux = data[:, 24]\n",
    "        # dflux = data[:, 25]\n",
    "        # mag = np.char.replace(data[:, 3], '>', '') # Removes greater than symbols\n",
    "        # dmag = data[:, 4]\n",
    "\n",
    "        # # Finds the empty spots of flux and mag and records the element\n",
    "        # mod_empty = np.unique(np.hstack((np.hstack((np.where(flux == 'None')[0], np.where(dflux == 'None')[0])),\n",
    "        #                                  np.hstack((np.where(mag == 'None')[0], np.where(dmag == 'None')[0])))))\n",
    "        # filters = np.delete(filters, mod_empty)\n",
    "        # t = np.delete(t, mod_empty).astype(float)\n",
    "        # flux = np.delete(flux, mod_empty).astype(float)\n",
    "        # dflux = np.delete(dflux, mod_empty).astype(float)\n",
    "        # mag = np.delete(mag, mod_empty).astype(float)\n",
    "        # dmag = np.delete(dmag, mod_empty).astype(float)\n",
    "\n",
    "        # # Finds negative fluxes\n",
    "        # mod_positive = np.unique(np.hstack((np.hstack((np.where(flux <= 0)[0], np.where(dflux <= 0)[0])),\n",
    "        #                             np.hstack((np.where(mag <= 0)[0], np.where(dmag <= 0)[0])))))\n",
    "        # filters = np.delete(filters, mod_positive)\n",
    "        # t = np.delete(t, mod_positive)\n",
    "        # flux = np.delete(flux, mod_positive)\n",
    "        # dflux = np.delete(dflux, mod_positive)\n",
    "        # mag = np.delete(mag, mod_positive)\n",
    "        # dmag = np.delete(dmag, mod_positive)\n",
    "\n",
    "        # # Find outliers beyond error limit\n",
    "        # mod_err = np.unique(np.hstack(((np.where(abs(dflux) > err_max)[0]), np.where(abs(dmag) > err_max)[0]))) # Negatives fluxes & Error Limit\n",
    "        # filters = np.delete(filters, mod_err)\n",
    "        # t = np.delete(t, mod_err)\n",
    "        # flux = np.delete(flux, mod_err)\n",
    "        # dflux = np.delete(dflux, mod_err)\n",
    "        # mag = np.delete(mag, mod_err)\n",
    "        # dmag = np.delete(dmag, mod_err)\n",
    "\n",
    "        # tempSN = ATLAS_SN(ATLASname=name, RA=np.average(data[:, 1].astype(float)), DEC=np.average(data[:, 2].astype(float)),\n",
    "        #                     t_o=t[np.where(filters=='o')[0]], flux_o=flux[np.where(filters=='o')[0]], dflux_o=dflux[np.where(filters=='o')[0]], mag_o=mag[np.where(filters=='o')[0]], dmag_o=dmag[np.where(filters=='o')[0]],\n",
    "        #                     t_c=t[np.where(filters=='c')[0]], flux_c=flux[np.where(filters=='c')[0]], dflux_c=dflux[np.where(filters=='c')[0]], mag_c=mag[np.where(filters=='c')[0]], dmag_c=dmag[np.where(filters=='c')[0]])\n",
    "\n",
    "        # return tempSN\n",
    "\n",
    "    # def TNS_obj_detection(SNe, t_lim=0.1, saveLoc=ROOT_SAVE+'ATLAS_variables.txt', use_saved=True):\n",
    "        # # Check for presaved data\n",
    "        # savedData = {}\n",
    "        # if os.path.exists(saveLoc) and use_saved:\n",
    "        #     data = np.genfromtxt(saveLoc, delimiter=', ', dtype=str, skip_header=1)\n",
    "        #     if len(data) > 0:\n",
    "        #         for n in range(len(data[:, 0])):\n",
    "        #             savedData.update({data[n][1]: [data[n][0], data[n][4]]})\n",
    "\n",
    "        # with open(saveLoc, 'w') as f:\n",
    "        #     f.write('objname, ATLASname, RA, DEC, z, tmin, tmax\\n') # Header\n",
    "        #     for n in range(len(SNe)):\n",
    "        #         if SNe[n].ATLASname in savedData:\n",
    "        #             obj = {'objname' : savedData[SNe[n].ATLASname][0], 'redshift' : savedData[SNe[n].ATLASname][1]}\n",
    "        #             SNe[n].objname = obj['objname']\n",
    "        #             SNe[n].z = obj['redshift']\n",
    "        #             print(\"Saved object data found for \"+SNe[n].ATLASname+\", retrieving...\")\n",
    "        #         else:\n",
    "        #             print(\"No saved data, sleeping for\", t_lim, 'seconds...')\n",
    "        #             time.sleep(t_lim)\n",
    "        #             obj = TNS_details(ra=SNe[n].RA, dec=SNe[n].DEC)\n",
    "        #             SNe[n].objname = 'SN'+obj['objname']\n",
    "        #             SNe[n].z = obj['redshift']\n",
    "\n",
    "        #         if len(SNe[n].t_o) > 0 and len(SNe[n].t_c) > 0:\n",
    "        #             t_max = max([np.max(SNe[n].t_o), np.max(SNe[n].t_c)])\n",
    "        #             t_min = min([np.min(SNe[n].t_o), np.min(SNe[n].t_c)])\n",
    "        #         elif len(SNe[n].t_o) == 0:\n",
    "        #             t_max = np.max(SNe[n].t_c)\n",
    "        #             t_min = np.min(SNe[n].t_c)\n",
    "        #         elif len(SNe[n].t_c) == 0:\n",
    "        #             t_max = np.max(SNe[n].t_o)\n",
    "        #             t_min = np.min(SNe[n].t_o)\n",
    "\n",
    "        #         print('[ '+str(n+1)+' / '+str(len(SNe))+' ]', SNe[n].ATLASname+':', SNe[n].objname,\n",
    "        #               '| z =', SNe[n].z, '| Tmin:', t_min, 'Tmax:', t_max, '\\n')\n",
    "        #         f.write(str(SNe[n].objname)+', '+str(SNe[n].ATLASname)+', '+str(SNe[n].RA)+', '+str(SNe[n].DEC)+\n",
    "        #                 ', '+str(SNe[n].z)+', '+str(t_min)+', '+str(t_max)+'\\n')\n",
    "\n",
    "        # return\n",
    "\n",
    "    # def solo_plotting(t_o, t_c, flux_o, flux_c, flux_err_o, flux_err_c, err_max, name='Empty', coords=[0, 0], size=(12, 4), save=False, saveLoc=PLOTS_ATLAS_PATH, show_plot=True):\n",
    "        # plt.figure(figsize=size)\n",
    "\n",
    "        # plt.errorbar(t_o, flux_o, yerr=flux_err_o, fmt='o', color='orange')\n",
    "        # plt.errorbar(t_c, flux_c, yerr=flux_err_c, fmt='o', color='cyan')\n",
    "\n",
    "        # plt.title('Light Curve: '+str(name)+'\\n'+str(coords[0])+', '+str(coords[1])+'\\nMax Error = '+str(err_max))\n",
    "        # plt.xlabel('Time [MJD]')\n",
    "        # plt.ylabel('Flux [uJy]')\n",
    "        # plt.ylim(0)\n",
    "        # plt.savefig(saveLoc+name+'_ATLASplot.png')\n",
    "        # if show_plot:\n",
    "        #     plt.show()\n",
    "        # else:\n",
    "        #     plt.close()\n",
    "        # return\n",
    "\n",
    "    # def combined_plotting(ax, t_o, t_c, flux_o, flux_c, flux_err_o, flux_err_c, name='Empty', coords=[0, 0]):\n",
    "        # ax.errorbar(t_o, flux_o, yerr=flux_err_o, fmt='o', color='orange')\n",
    "        # ax.errorbar(t_c, flux_c, yerr=flux_err_c, fmt='o', color='cyan')\n",
    "\n",
    "        # ax.set_title('Light Curve: '+str(name)+'\\n'+str(coords[0])+', '+str(coords[1]))\n",
    "        # ax.set_xlabel('Time [MJD]')\n",
    "        # ax.set_ylabel('Flux [uJy]')\n",
    "        # ax.set_ylim(0)\n",
    "        # return\n",
    "\n",
    "    # def plot_ATLAS(xyo, xyc, ax=plt, name='Empty', coords=[0, 0], save=False, saveloc=PLOTS_ATLAS_PATH):\n",
    "        # ax.errorbar(xyo[0], xyo[1], yerr=xyo[2], fmt='o', color='orange')\n",
    "        # ax.errorbar(xyc[0], xyc[1], yerr=xyc[2], fmt='o', color='cyan')\n",
    "\n",
    "        # ax.set_title('Light Curve: '+str(name)+'\\n'+str(coords[0])+', '+str(coords[1]))\n",
    "        # ax.set_xlabel('Time [MJD]'); ax.set_ylabel('Flux [uJy]')\n",
    "        # if save:\n",
    "        #     plt.savefig(saveloc+name+'_ATLASplot.png')\n",
    "        # return\n",
    "\n",
    "    # def ATLAS_process():\n",
    "    # # [1] Collecting ATLAS data\n",
    "    # print('[1] Collecting ATLAS data...')\n",
    "    # data_collection(quiet=False)\n",
    "\n",
    "    # # [2] Slice data, remove outliers, & plot\n",
    "    # print('[2] Processing ATLAS data...')\n",
    "    # SNe = ATLAS_main_processing(err_max=100, t_lim = 10, n_iter = 0, plot_mode = 'SOLO', show_plot=False, use_saved=True)\n",
    "    # print('[2!] ATLAS data processed...', len(SNe), 'SN found and validated.')\n",
    "\n",
    "    # # [3] Write ATLAS data to SNooPy ASCII file\n",
    "    # print('[3] Writing ATLAS data to ASCII file for SNooPy...')\n",
    "    # ATLASnames = snpy_ASCII_formatting(SNe)\n",
    "\n",
    "    # # [4] SNooPy fitting\n",
    "    # print('[4] Fitting ATLAS data with SNooPy...')\n",
    "    # fit_args = {'model': 'EBV_model2', 'shape': 'st', 'bands': ['ATgr', 'ATri'], 'output': True, 'show_plots': True, 'use_saved': False}\n",
    "    # paths = glob.glob('/content/HiloCATsSN1991bg/saved_data/data/atlas_snpy/*')\n",
    "    # params = snpy_fit(paths[:5], plot_save=PLOTS_ROOT, model_save=SNPY_ROOT, **fit_args)\n",
    "\n",
    "    # SNe_new = [] # mu, z, st, Tmax, EBVhost, DM\n",
    "    # for SN in SNe:\n",
    "    #     try:\n",
    "    #         SN.mu = params[SN.objname][0]\n",
    "    #         SN.z = params[SN.objname][1]\n",
    "    #         SN.st = params[SN.objname][2]\n",
    "    #         SN.Tmax = params[SN.objname][3]\n",
    "    #         SN.EBVhost = params[SN.objname][4]\n",
    "    #         SN.DM = params[SN.objname][5]\n",
    "    #         SNe_new.append(SN)\n",
    "    #     except KeyError:\n",
    "    #         print(SN.objname, 'is a problem child, removing...')\n",
    "    # SNe = SNe_new # Replace list of SNe with new list\n",
    "\n",
    "    # # Save distance mod\n",
    "    # saved_params = np.genfromtxt(ROOT_SAVE+'ATLAS_variables.txt', delimiter=', ', dtype=str, skip_header=1)\n",
    "    # with open(ROOT_SAVE+'ATLAS_variables_mu.txt', 'w') as f:\n",
    "    #     f.write('objname, ATLASname, RA, DEC, z, tmin, tmax, mu\\n')\n",
    "    #     for n in range(len(SNe_new)):\n",
    "    #         f.write(str(saved_params[n, 0])+', '+str(saved_params[n, 1])+', '+str(saved_params[n, 2])+', '+str(saved_params[n, 3])+', '+\n",
    "    #                 str(saved_params[n, 4])+', '+str(saved_params[n, 5])+', '+str(saved_params[n, 6])+', '+str(SNe_new[n].mu)+'\\n')\n",
    "\n",
    "    # # # [5] SNooPy fit mu v. Redshift\n",
    "    # # plot_SNooPy_mu_vs_z()\n",
    "\n",
    "    # # # [6] Histogram of fit parameters\n",
    "    # # plot_SNooPy_hist(binNum=10)\n",
    "    # return\n"
   ],
   "metadata": {
    "id": "ctmVmhAwsg7d"
   },
   "execution_count": 1660,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# \"\"\" START UP \"\"\"\n",
    "# import os\n",
    "# import shutil\n",
    "# if os.path.exists('/content/HiloCATsSN1991bg') == True:\n",
    "#     shutil.rmtree('/content/HiloCATsSN1991bg')\n",
    "#     !git clone https://github.com/mekhi-woods/HiloCATsSN1991bg.git\n",
    "# else:\n",
    "#     !git clone https://github.com/mekhi-woods/HiloCATsSN1991bg.git\n",
    "\n",
    "# !pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple snpy\n",
    "# !pip install requests\n",
    "# !pip install sncosmo\n",
    "# !pip install iminuit"
   ],
   "metadata": {
    "id": "gTAo57hVjmTa"
   },
   "execution_count": 1661,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\" IMPORTS \"\"\"\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import json\n",
    "import snpy\n",
    "import shutil\n",
    "import sncosmo\n",
    "import requests\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "from zipfile import ZipFile\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from HiloCATsSN1991bg.scripts import tns_redshifts\n",
    "from astropy.table import QTable, Table, Column\n",
    "from astropy import units as u"
   ],
   "metadata": {
    "id": "bg3Q3CWYsvzj"
   },
   "execution_count": 1662,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\" GLOBALS \"\"\"\n",
    "# TNS CREDINTIALS\n",
    "tns_bot_id = '73181'\n",
    "tns_bot_name = 'YSE_Bot1'\n",
    "tns_bot_api_key = '0d771345fa6b876a5bb99cd5042ab8b5ae91fc67'\n",
    "\n",
    "# EXSISTING DATA\n",
    "RAW_ZTF = '/content/HiloCATsSN1991bg/data/ZTF/'\n",
    "\n",
    "# PATHS\n",
    "ROOT_SAVE = '/content/HiloCATsSN1991bg/saved_data/'\n",
    "\n",
    "## Raw Data\n",
    "DATA_ROOT = ROOT_SAVE+'data/'\n",
    "DATA_ATLAS_PATH = DATA_ROOT+'atlas/'\n",
    "DATA_ZTF_PATH = DATA_ROOT+'ztf/'\n",
    "\n",
    "## SNooPy\n",
    "SNPY_ROOT = ROOT_SAVE+'snpy/'\n",
    "SNPY_DATA_BURNS_PATH = SNPY_ROOT+'burns/'\n",
    "SNPY_MODELS_BURNS_PATH = SNPY_ROOT+'burns_models/'\n",
    "SNPY_DATA_ATLAS_PATH = SNPY_ROOT+'atlas/'\n",
    "SNPY_MODELS_ATLAS_PATH = SNPY_ROOT+'atlas_models/'\n",
    "SNPY_DATA_ZTF_PATH = SNPY_ROOT+'ztf/'\n",
    "SNPY_MODELS_ZTF_PATH = SNPY_ROOT+'ztf_models/'\n",
    "\n",
    "## Param Files\n",
    "PARAM_ROOT = '/content/HiloCATsSN1991bg/saved_data/param/'\n",
    "PARAM_BURNS_PATH = PARAM_ROOT + 'burns/'\n",
    "PARAM_ATLAS_PATH = PARAM_ROOT + 'atlas/'\n",
    "PARAM_ZTF_PATH = PARAM_ROOT + 'ztf/'\n",
    "\n",
    "## Plotting\n",
    "PLOTS_ROOT = ROOT_SAVE+'plots/'\n",
    "PLOTS_BURNS_PATH = PLOTS_ROOT+'burns/'\n",
    "PLOTS_ATLAS_PATH = PLOTS_ROOT+'atlas/'\n",
    "PLOTS_ZTF_PATH = PLOTS_ROOT+'ztf/'\n",
    "\n",
    "PROBLEM_CHILDREN_PATH = ROOT_SAVE+'problem_children.txt'\n",
    "PROBLEM_CHILDREN = ['1032212120425304400']  # Running list of problematic SNe\n",
    "                                            # '1032212120425304400' - David believes it might be a shock breakout but ATLAS reports it as SN1a\n",
    "                                            #\n"
   ],
   "metadata": {
    "id": "WbQz8fC_uhH6"
   },
   "execution_count": 1663,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\" CLASSES \"\"\"\n",
    "class ATLAS_SN():\n",
    "    def __init__(self, ATLASname='EmptySN', objname='SN####abc', RA=0.00000000000, DEC=0.00000000000, z=0.00000000000,\n",
    "                 DM=0.00, st=0.00, EBVhost=0.00, Tmax=0.00, mu=0.00,\n",
    "                 t_o=np.array([0]), flux_o=np.array([0]), dflux_o=np.array([0]), mag_o=np.array([0]), dmag_o=np.array([0]),\n",
    "                 t_c=np.array([0]), flux_c=np.array([0]), dflux_c=np.array([0]), mag_c=np.array([0]), dmag_c=np.array([0])):\n",
    "        self.ATLASname=ATLASname\n",
    "        self.objname=objname\n",
    "        self.RA=RA\n",
    "        self.DEC=DEC\n",
    "        self.z=z\n",
    "\n",
    "        self.t_o=t_o\n",
    "        self.flux_o=flux_o\n",
    "        self.dflux_o=dflux_o\n",
    "        self.mag_o=mag_o\n",
    "        self.dmag_o=dmag_o\n",
    "\n",
    "        self.t_c=t_c\n",
    "        self.flux_c=flux_c\n",
    "        self.dflux_c=dflux_c\n",
    "        self.mag_c=mag_c\n",
    "        self.dmag_c=dmag_c\n",
    "\n",
    "        self.mu = mu\n",
    "        self.DM = DM\n",
    "        self.st = st\n",
    "        self.EBVhost = EBVhost\n",
    "        self.Tmax = Tmax\n",
    "        return\n",
    "\n",
    "    def __str__(self):\n",
    "        return (self.objname+' : '+self.ATLASname+' @ ('+str(self.RA)+', '+str(self.DEC)+')\\n'+\n",
    "                'O-Filter:'+\n",
    "                '\\t t [MJD]: '+str(np.min(self.t_o))+'...'+str(np.max(self.t_o))+'\\n'+\n",
    "                '\\t\\t flux [uJy]: '+str(np.min(self.flux_o))+'...'+str(np.max(self.flux_o))+'\\n'+\n",
    "                '\\t\\t dflux [duJy]: '+str(np.min(self.dflux_o))+'...'+str(np.max(self.dflux_o))+'\\n'+\n",
    "                '\\t\\t mag: '+str(np.min(self.mag_o))+'...'+str(np.max(self.mag_o))+'\\n'+\n",
    "                '\\t\\t dmag: '+str(np.min(self.dmag_o))+'...'+str(np.max(self.dmag_o))+'\\n'+\n",
    "                'C-Filter:'+\n",
    "                '\\t t [MJD]: '+str(np.min(self.t_c))+'...'+str(np.max(self.t_c))+'\\n'+\n",
    "                '\\t\\t flux [uJy]: '+str(np.min(self.flux_c))+'...'+str(np.max(self.flux_c))+'\\n'+\n",
    "                '\\t\\t dflux [duJy]: '+str(np.min(self.dflux_c))+'...'+str(np.max(self.dflux_c))+'\\n'\n",
    "                '\\t\\t mag: '+str(np.min(self.mag_c))+'...'+str(np.max(self.mag_c))+'\\n'+\n",
    "                '\\t\\t dmag: '+str(np.min(self.dmag_c))+'...'+str(np.max(self.dmag_c))+'\\n'+\n",
    "                'Params:'+\n",
    "                '\\t Distance Mod [mu]: '+str(self.mu)+'\\n'+\n",
    "                '\\t\\t DM: '+str(self.DM)+'\\n'+\n",
    "                '\\t\\t Shape [st]: '+str(self.st)+'\\n'\n",
    "                '\\t\\t EBVhost: '+str(self.EBVhost)+'\\n'+\n",
    "                '\\t\\t Peak Time [Tmax]: '+str(self.Tmax)+'\\n')\n",
    "\n",
    "    def coords(self):\n",
    "        return('('+str(self.RA)+', '+str(self.DEC)+')')\n",
    "\n",
    "    def flux_to_mag(self):\n",
    "        return [[-2.5*np.log10(self.flux_o) + 23.9, 1.0857*self.dflux_o/self.flux_o],\n",
    "                [-2.5*np.log10(self.flux_c) + 23.9, 1.0857*self.dflux_c/self.flux_c]]\n"
   ],
   "metadata": {
    "id": "mxQPN393v8Qi"
   },
   "execution_count": 1664,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\" GENERAL \"\"\"\n",
    "def recover_dir():\n",
    "    directories = [ROOT_SAVE, RAW_ZTF,\n",
    "                   DATA_ROOT, DATA_ATLAS_PATH, DATA_ZTF_PATH,\n",
    "                   SNPY_ROOT, SNPY_DATA_BURNS_PATH, SNPY_MODELS_BURNS_PATH,\n",
    "                   SNPY_DATA_ATLAS_PATH, SNPY_MODELS_ATLAS_PATH,\n",
    "                   SNPY_DATA_ZTF_PATH, SNPY_MODELS_ZTF_PATH,\n",
    "                   PLOTS_ROOT, PLOTS_BURNS_PATH, PLOTS_ATLAS_PATH, PLOTS_ZTF_PATH,\n",
    "                   PARAM_ROOT, PARAM_BURNS_PATH, PARAM_ATLAS_PATH, PARAM_ZTF_PATH]\n",
    "    for dir in directories:\n",
    "        if os.path.exists(dir) == False:\n",
    "            os.mkdir(dir)\n",
    "    if os.path.exists(SNPY_DATA_ATLAS_PATH+'/snpyplots.zip'):\n",
    "        os.remove(SNPY_DATA_ATLAS_PATH+'/snpyplots.zip')\n",
    "    return\n",
    "\n",
    "def TNS_details(ra, dec):\n",
    "    # Code from David\n",
    "    headers = tns_redshifts.build_tns_header(tns_bot_id, tns_bot_name)\n",
    "    tns_api_url = f\"https://www.wis-tns.org/api/get\"\n",
    "\n",
    "    # get the API URLs\n",
    "    search_tns_url = tns_redshifts.build_tns_url(tns_api_url, mode=\"search\")\n",
    "    get_tns_url = tns_redshifts.build_tns_url(tns_api_url, mode=\"get\")\n",
    "\n",
    "    search_data = tns_redshifts.build_tns_search_query_data(tns_bot_api_key, ra, dec)\n",
    "    transients = tns_redshifts.rate_limit_query_tns(search_data, headers, search_tns_url)\n",
    "\n",
    "    get_data = tns_redshifts.build_tns_get_query_data(tns_bot_api_key, transients[0])\n",
    "    transient_detail = tns_redshifts.rate_limit_query_tns(get_data, headers, get_tns_url)\n",
    "\n",
    "    return transient_detail\n",
    "\n",
    "def snpy_fit(paths, plot_save=PLOTS_ROOT, model_save=SNPY_ROOT,\n",
    "             model='EBV_model2', shape='st', bands=None, output=False, show_plots=False, use_saved=True):\n",
    "    params = {} # mu, z, st, Tmax, EBVhost, DM\n",
    "    n_targets = len(paths)\n",
    "    for n in range(n_targets):\n",
    "        # Set up iterable variables\n",
    "        n_name = paths[n][:-9].split('/')[-1] # Splits along backslash and removes '.txt'\n",
    "        n_save = model_save + n_name + '_' + model + '.snpy'\n",
    "        n_path = paths[n]\n",
    "        print('[ '+str(n+1)+' / '+str(n_targets)+'] Fiting data for '+n_name+'...')\n",
    "\n",
    "        # Attempt to retrieve previous fits\n",
    "        if os.path.exists(n_save) and use_saved:\n",
    "            print(n_name, 'found in files! Pulling data...')\n",
    "            n_s = snpy.get_sn(n_save)\n",
    "\n",
    "        # If no saved data / used_save=False, run fit\n",
    "        else:\n",
    "            try:\n",
    "                # Fit data -- using David configurations\n",
    "                print(n_path)\n",
    "                n_s = snpy.get_sn(n_path)\n",
    "                n_s.choose_model(model, stype=shape)\n",
    "                n_s.set_restbands() # Auto pick appropriate rest-bands\n",
    "                fitargs = {'mangle':1,'calibration':0} # I don't remember what calibration is\n",
    "                n_s.fit(bands=bands, dokcorr=True, k_stretch=False, reset_kcorrs=True, **fitargs)\n",
    "            except:\n",
    "                # If error, return None\n",
    "                n_s = None\n",
    "                PROBLEM_CHILDREN.append(n_name)\n",
    "                print('[!!!] Unknown Error... skipping\\n')\n",
    "\n",
    "        # If fit was successful, save\n",
    "        if n_s is not None:\n",
    "            n_mu = n_s.get_distmod()\n",
    "\n",
    "            # Save Model\n",
    "            n_s.save(n_save)\n",
    "\n",
    "            # Save paramaters - mu, z, st, Tmax, EBVhost, DM\n",
    "            params.update({n_name : [n_mu, n_s.z, n_s.st, n_s.Tmax, n_s.EBVhost, n_s.DM]})\n",
    "\n",
    "            # Print output\n",
    "            if output:\n",
    "                # Print fit summary\n",
    "                n_s.summary()\n",
    "\n",
    "                # Print paramaters\n",
    "                print('Redshift:\\t z = '+str(n_s.z))\n",
    "                print('Distance: \\t mu = '+str(round(n_mu, 4))+'\\n')\n",
    "\n",
    "            # Plotting\n",
    "            n_s.plot(outfile=plot_save+n_name+'_snpyplots.png')\n",
    "            if show_plots:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.close()\n",
    "\n",
    "    print('Problem children:\\n', '[', len(PROBLEM_CHILDREN), ']', PROBLEM_CHILDREN)\n",
    "    plt.clf()\n",
    "    return params\n",
    "\n",
    "def read_DR3(loc='/content/HiloCATsSN1991bg/DR3_fits.dat'):\n",
    "    data = np.genfromtxt(loc, dtype=str, skip_header=1)\n",
    "    dr3 = {}\n",
    "    for n in range(len(data[:, 0])):\n",
    "        dr3.update({data[:, 0][n]: {'st': float(data[:, 1][n]), 'e_st': float(data[:, 2][n]), 'z': float(data[:, 3][n]),\n",
    "                           'Tmax': float(data[:, 5][n]), 'e_Tmax': float(data[:, 6][n]),\n",
    "                           'EBVHost': float(data[:, 25][n]), 'e_EBVHost': float(data[:, 26][n])}})\n",
    "    return dr3\n",
    "\n",
    "def plot_param_hist(st, Tmax, EBVHost, bins=30, title='Empty', save_loc=ROOT_SAVE, save_plot=False, show_plot=True):\n",
    "    paramsNames = ['st', title+' \\n Tmax', 'EBVhost']\n",
    "    paramsData = [st, Tmax, EBVHost]\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    for n in range(len(paramsNames)):\n",
    "        axes[n].hist(paramsData[n], bins=bins)\n",
    "        axes[n].set_title(paramsNames[n])\n",
    "    if save_plot:\n",
    "        plt.savefig(save_loc+'param_hist.png')\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "    return\n",
    "\n",
    "def dict_unpacker(path, delimiter=', '):\n",
    "    with open(path, 'r') as f:\n",
    "        hdr = f.readline()[:-1].split(delimiter)\n",
    "\n",
    "    data = np.genfromtxt(path, delimiter=delimiter, dtype=str, skip_header=1)\n",
    "    temp_objs = {}\n",
    "    for i in range(len(data[:, 0])):\n",
    "        obj = data[:, 0][i]\n",
    "        temp_objs.update({obj: {}})\n",
    "        for j in range(len(hdr)):\n",
    "            temp_objs[obj].update({hdr[j]: data[i, j]})\n",
    "    return temp_objs\n",
    "\n",
    "def dict_packer(data_dict, save_loc, delimiter=', '):\n",
    "    with open(save_loc, 'w') as f:\n",
    "        for category in list(data_dict.keys()):\n",
    "            f.write(category+delimiter)\n",
    "        f.write('\\n')\n",
    "        for name in data_dict:\n",
    "            f.write(name+delimiter)\n",
    "            for category in list(data_dict.keys()):\n",
    "                f.write(str(data_dict[name][category])+delimiter)\n",
    "            f.write('\\n')\n",
    "    return\n",
    "\n",
    "\n",
    ""
   ],
   "metadata": {
    "id": "C7KXlnwCM_f0"
   },
   "execution_count": 1665,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\" SALT3/SNCOSMO \"\"\"\n",
    "def example_fit():\n",
    "    data = sncosmo.load_example_data()\n",
    "    print(data)\n",
    "\n",
    "    # create a model\n",
    "    model = sncosmo.Model(source='salt3')\n",
    "\n",
    "    # run the fit\n",
    "    result, fitted_model = sncosmo.fit_lc(data, model, ['z', 't0', 'x0', 'x1', 'c'], bounds = {'z':(0.3, 0.7)})\n",
    "\n",
    "    print(\"Number of chi^2 function calls:\", result.ncall)\n",
    "    print(\"Number of degrees of freedom in fit:\", result.ndof)\n",
    "    print(\"chi^2 value at minimum:\", result.chisq)\n",
    "    print(\"model parameters:\", result.param_names)\n",
    "    print(\"best-fit values:\", result.parameters)\n",
    "    print(\"The result contains the following attributes:\\n\", result.keys())\n",
    "\n",
    "    sncosmo.plot_lc(data, model=fitted_model, errors=result.errors)\n",
    "    return\n",
    "\n",
    "def SALT2_ATLAS():\n",
    "    data = np.genfromtxt('/content/HiloCATsSN1991bg/saved_data/data/atlas/1000438990080559900.txt', delimiter=',', dtype=str, skip_header=1)\n",
    "    time = data[:,8]\n",
    "    band = np.full(len(data[:, 7]), 'f105w')\n",
    "    flux = data[:, 16]\n",
    "    fluxerr = data[:, 17]\n",
    "    zp = data[:, 7]\n",
    "    zpsys = np.full(len(data[:, 7]), 'ab')\n",
    "\n",
    "    #  time      band       flux         fluxerr      zp  zpsys\n",
    "    # data = sncosmo.load_example_data()\n",
    "    # print(data)\n",
    "\n",
    "    data_t = Table([time, band, flux, fluxerr, zp, zpsys], names=('time', 'band', 'flux', 'fluxerr', 'zp', 'zpsys'))\n",
    "    print(data_t)\n",
    "\n",
    "    # create a model\n",
    "    model = sncosmo.Model(source='salt3')\n",
    "\n",
    "    # run the fit\n",
    "    result, fitted_model = sncosmo.fit_lc(data_t, model, ['z', 't0', 'x0', 'x1', 'c'], bounds = {'z':(0.3, 0.7)})\n",
    "\n",
    "    print(\"Number of chi^2 function calls:\", result.ncall)\n",
    "    print(\"Number of degrees of freedom in fit:\", result.ndof)\n",
    "    print(\"chi^2 value at minimum:\", result.chisq)\n",
    "    print(\"model parameters:\", result.param_names)\n",
    "    print(\"best-fit values:\", result.parameters)\n",
    "    print(\"The result contains the following attributes:\\n\", result.keys())\n",
    "\n",
    "    sncosmo.plot_lc(data_t, model=fitted_model, errors=result.errors)\n",
    "\n",
    "\n",
    "    return\n",
    "\n"
   ],
   "metadata": {
    "id": "cyr8DJ1CKPnZ"
   },
   "execution_count": 1666,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\" ZTF \"\"\"\n",
    "# [1] - Pull\n",
    "def ztf_collection(ra, dec, jds, jde, submit=False, limit=1000):\n",
    "    print(\"Number of targets =\", len(ra))\n",
    "    ralist, declist = [], []\n",
    "    for n in range(len(ra)):\n",
    "        ralist.append(ra[n])\n",
    "        declist.append(dec[n])\n",
    "        if len(ralist) % limit == 0:\n",
    "            ralist = []\n",
    "            declist = []\n",
    "            if submit:\n",
    "                print('Submiting request to ZTF...')\n",
    "                ztf_submit_post(ralist, declist, jds, jde)\n",
    "    if submit and len(ralist) > 0:\n",
    "        print('Submiting request to ZTF...')\n",
    "        ztf_submit_post(ralist, declist, jds, jde)\n",
    "    return\n",
    "\n",
    "def ztf_submit_post(ra_list, dec_list, jds, jde):\n",
    "    email = 'mekhidw@hawaii.edu' # email you subscribed with.\n",
    "    userpass = 'wxdk286' # password that was issued to you.\n",
    "\n",
    "    ra, dec = json.dumps(ra_list), json.dumps(dec_list)\n",
    "    jdend = json.dumps(jde)\n",
    "    jdstart = json.dumps(jds)\n",
    "    payload = {'ra': ra, 'dec': dec, 'jdstart': jdstart, 'jdend': jdend, 'email': email, 'userpass': userpass}\n",
    "\n",
    "    # fixed IP address/URL where requests are submitted:\n",
    "    url = 'https://ztfweb.ipac.caltech.edu/cgi-bin/batchfp.py/submit'\n",
    "    r = requests.post(url, auth=('ztffps', 'dontgocrazy!'), data=payload)\n",
    "\n",
    "    print(ra)\n",
    "    print(dec)\n",
    "    print(jdstart)\n",
    "    print(jdend)\n",
    "    print(\"Status_code=\",r.status_code)\n",
    "    return\n",
    "\n",
    "# [2] - Process\n",
    "def ztf_processing(err_max= 100):\n",
    "    paths = glob.glob(RAW_ZTF+'*')\n",
    "    params = {}\n",
    "    for path in paths:\n",
    "        ztfname = path.split('_')[1][3:]\n",
    "        data = np.genfromtxt(path, delimiter=' ', skip_header=54, dtype=str)\n",
    "\n",
    "        flux = data[:, 24].astype(float)\n",
    "        fluxerr = data[:, 25].astype(float)\n",
    "        time = data[:, 22].astype(float)\n",
    "        filter = data[:, 4]\n",
    "\n",
    "        # Get ra & dec from file\n",
    "        with open(path, 'r') as f:\n",
    "            for i in range(3):\n",
    "                f.readline()\n",
    "            ra = float(f.readline().split(' ')[5])\n",
    "            dec = float(f.readline().split(' ')[5])\n",
    "            try:\n",
    "                details = TNS_details(ra, dec)\n",
    "                ztfname = details['objname']\n",
    "                z = details['redshift']\n",
    "            except:\n",
    "                print('['+ztfname+'] TNS could not resolve location...')\n",
    "                z = 0\n",
    "\n",
    "        # Correct for outliers\n",
    "        invalid_values = np.array([])\n",
    "        invalid_values = np.append(invalid_values, np.where(fluxerr < 0)[0]) # Negative errors\n",
    "        invalid_values = np.append(invalid_values, np.where(fluxerr >= err_max)[0]) # Large errors\n",
    "        invalid_values = np.append(invalid_values, np.where(flux < 0)[0]) # Negative fluxes\n",
    "\n",
    "        # Commit fixes\n",
    "        invalid_values = np.unique(invalid_values.astype(int))\n",
    "        flux = np.delete(flux, invalid_values)\n",
    "        fluxerr = np.delete(fluxerr, invalid_values)\n",
    "        time = np.delete(time, invalid_values)\n",
    "        filter = np.delete(filter, invalid_values)\n",
    "\n",
    "        # Save to dictionary\n",
    "        if z != 0:\n",
    "            params.update({ztfname: {'ra': ra, 'dec': dec, 'z': z, 'time': time, 'flux': flux, 'fluxerr': fluxerr, 'filter': filter}})\n",
    "\n",
    "    return params\n",
    "\n",
    "# [3] - Saving\n",
    "def ztf_write_to_ASCII(data_dict):\n",
    "    for obj in data_dict:\n",
    "        f_index = [np.where(data_dict[obj]['filter']=='ZTF_g')[0],\n",
    "                   np.where(data_dict[obj]['filter']=='ZTF_r')[0],\n",
    "                   np.where(data_dict[obj]['filter']=='ZTF_i')[0]]\n",
    "        f_label = ['g', 'r', 'i']\n",
    "\n",
    "        with open(SNPY_DATA_ZTF_PATH+obj+'_snpy.txt', 'w') as f:\n",
    "            f.write(str(obj)+' '+str(data_dict[obj]['z'])+' '+str(data_dict[obj]['ra'])+' '+str(data_dict[obj]['dec'])+'\\n')\n",
    "\n",
    "            for j in range(len(f_label)):\n",
    "                if len(f_index[j]) != 0:\n",
    "                    f.write('filter '+str(f_label[j])+'\\n')\n",
    "                    for i in f_index[j]:\n",
    "                        f.write(str(data_dict[obj]['time'][i])+'\\t'+\n",
    "                                str(data_dict[obj]['flux'][i])+'\\t'+\n",
    "                                str(data_dict[obj]['fluxerr'][i])+'\\n')\n",
    "\n",
    "# [4] - Fitting\n",
    "def ztf_fitting(output=False, show_plots=False, use_saved=False):\n",
    "    fit_args = {'model': 'EBV_model2', 'shape': 'st', 'bands': ['g', 'r', 'i'], 'output': output, 'show_plots': show_plots, 'use_saved': use_saved}\n",
    "    paths = glob.glob(SNPY_DATA_ZTF_PATH+'*')\n",
    "    params = snpy_fit(paths, plot_save=PLOTS_ROOT, model_save=SNPY_MODELS_ZTF_PATH, **fit_args)\n",
    "\n",
    "    return\n",
    "\n",
    "# [5] - Plot\n",
    "def ztf_plotting(data_dict, zoom=300, sigma=1, show_plot=True, save_plot=False):\n",
    "    f_label = ['g', 'r', 'i']\n",
    "    f_color = ['green', 'red', 'blue']\n",
    "\n",
    "    for obj in data_dict:\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        peak = np.where(data_dict[obj]['time'] == np.max(data_dict[obj]['time']))[0][0]\n",
    "\n",
    "        f_index = [np.where(data_dict[obj]['filter']=='ZTF_g')[0],\n",
    "                   np.where(data_dict[obj]['filter']=='ZTF_r')[0],\n",
    "                   np.where(data_dict[obj]['filter']=='ZTF_i')[0]]\n",
    "\n",
    "        for n in range(len(f_index)):\n",
    "            plt.errorbar(data_dict[obj]['time'][f_index[n]],\n",
    "                         data_dict[obj]['flux'][f_index[n]],\n",
    "                         yerr=data_dict[obj]['fluxerr'][f_index[n]]*sigma,\n",
    "                         markersize=3, fmt='o', color=f_color[n], label=f_label[n])\n",
    "\n",
    "        plt.xlabel('Time [JD]'); plt.ylabel('Flux [counts]')\n",
    "        plt.title(obj+'\\nSigma = '+str(sigma))\n",
    "        if zoom != 0:\n",
    "            plt.xlim(data_dict[obj]['time'][peak]-zoom, data_dict[obj]['time'][peak]+zoom)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        # break\n",
    "\n",
    "    # for obj in data_dict:\n",
    "        # plt.figure(figsize=(12, 4))\n",
    "\n",
    "        # f_index = [np.where(data_dict[obj]['filter']=='ZTF_g')[0],\n",
    "        #            np.where(data_dict[obj]['filter']=='ZTF_r')[0],\n",
    "        #            np.where(data_dict[obj]['filter']=='ZTF_i')[0]]\n",
    "\n",
    "        # for n in range(len(f_index)):\n",
    "        #     plt.errorbar(data_dict[obj]['time'][f_index[n]],\n",
    "        #                  data_dict[obj]['flux'][f_index[n]],\n",
    "        #                  yerr=data_dict[obj]['fluxerr'][f_index[n]]*sigma,\n",
    "        #                  markersize=3, fmt='o', color=f_color[n], label=f_label[n])\n",
    "\n",
    "        # plt.xlabel('Time [JD]'); plt.ylabel('Flux [counts]')\n",
    "        # plt.title(obj+'\\nSigma = '+str(sigma))\n",
    "        # plt.legend()\n",
    "        # plt.show()\n",
    "        # break\n",
    "\n",
    "    return\n",
    "\n",
    "def ztf_histogram(data_dict):\n",
    "\n",
    "\n",
    "    return\n",
    "\n",
    "def ztf_residuals(t, flux, fluxerr, filter, objname):\n",
    "    dr3_data = read_DR3()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return\n"
   ],
   "metadata": {
    "id": "i51T5V4eNOCI"
   },
   "execution_count": 1667,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\" ATLAS \"\"\"\n",
    "# [1] - Collect\n",
    "def atlas_collection(path=DATA_ATLAS_PATH, quiet=False, check_data=True):\n",
    "    api_token = '7f4e1dee8f52cf0c8cdaf55bf29d04bef4810fb4'\n",
    "\n",
    "    if check_data and len(glob.glob(DATA_ATLAS_PATH+'*')) > 1:\n",
    "        print('ATLAS data already collected, passing step...')\n",
    "        return\n",
    "    else:\n",
    "        print('No data detected, collecting ATLAS data...')\n",
    "        if os.path.exists(ROOT_SAVE+'tmp.npz'):\n",
    "            pickle = np.load(ROOT_SAVE+'tmp.npz', allow_pickle=True)\n",
    "            data = pickle['data']\n",
    "\n",
    "        data = requests.post(\n",
    "            'https://star.pst.qub.ac.uk/sne/atlas4/api/objectlist/',\n",
    "            headers={'Authorization': f'Token {api_token}'},\n",
    "            data={'objectlistid':2}\n",
    "        ).json()\n",
    "\n",
    "        np.savez(ROOT_SAVE+'tmp.npz', data=data)\n",
    "\n",
    "        count = 0\n",
    "        for d in data:\n",
    "            if d['observation_status'] is not None and d['observation_status'].startswith('SN Ia') and '91bg' in d['observation_status']:\n",
    "                count += 1\n",
    "                if not quiet:\n",
    "                    print(d['atlas_designation'],d['observation_status'].replace(' ',''),d['ra'],d['dec'])\n",
    "\n",
    "\n",
    "                ids = d['id']\n",
    "                base_url = 'https://star.pst.qub.ac.uk/sne/atlas4/lightcurveforced/1161048951013729300/'\n",
    "                new_url = base_url.replace('1161048951013729300/',str(ids))\n",
    "                if not quiet:\n",
    "                    print(new_url)\n",
    "\n",
    "                idfile = path+'/' + str(ids)+'.txt'\n",
    "                if os.path.exists(idfile):\n",
    "                    continue\n",
    "                urllib.request.urlretrieve(str(new_url), str(idfile))\n",
    "                if not quiet:\n",
    "                    print(idfile)\n",
    "\n",
    "            if count > 300:\n",
    "                break\n",
    "    return\n",
    "\n",
    "# [2] - Process\n",
    "def atlas_processing(err_max=100, n_iter = 0, use_saved=True):\n",
    "    # [2.1] Aquire Data\n",
    "    print('[2.1] Retrieving data from...', DATA_ATLAS_PATH)\n",
    "    files = glob.glob(DATA_ATLAS_PATH+'/*')\n",
    "    # [2.2] Validate Data\n",
    "    print('[2.2] Sorting data...')\n",
    "    SNe = []\n",
    "    tar_num = len(files)\n",
    "    for n in range(tar_num):\n",
    "        n_name = files[n][48:-4]\n",
    "        print('[', n+1, '/', len(files), '] Validating data for...', n_name)\n",
    "        result = atlas_slice_data(path=files[n], err_max=err_max)\n",
    "        if result != None:\n",
    "            SNe.append(result)\n",
    "        else:\n",
    "            PROBLEM_CHILDREN.append(n_name)\n",
    "        if n_iter != 0 and n+1 >= n_iter:\n",
    "            break\n",
    "\n",
    "    # [2.3] Remove problem children\n",
    "    print('[2.3] Problem Children: ', PROBLEM_CHILDREN)\n",
    "    for SN in SNe:\n",
    "        for probname in PROBLEM_CHILDREN:\n",
    "            if SN.ATLASname == probname:\n",
    "                print('Removing...', SN.ATLASname)\n",
    "                SNe.remove(SN)\n",
    "    return SNe\n",
    "\n",
    "def atlas_slice_data(path, err_max=100):\n",
    "    name = path[48:-4]\n",
    "    data = np.genfromtxt(path, dtype=str, delimiter=',')\n",
    "\n",
    "    if len(data) == 0:\n",
    "        print('[!!!] File '+name+' empty...skipping')\n",
    "        return None\n",
    "\n",
    "    filters = data[:, 6]\n",
    "    t = data[:, 8].astype(float)\n",
    "    flux = data[:, 24]\n",
    "    dflux = data[:, 25]\n",
    "    mag = np.char.replace(data[:, 3], '>', '') # Removes greater than symbols\n",
    "    dmag = data[:, 4]\n",
    "\n",
    "    # Finds the empty spots of flux and mag and records the element\n",
    "    mod_empty = np.unique(np.hstack((np.hstack((np.where(flux == 'None')[0], np.where(dflux == 'None')[0])),\n",
    "                                     np.hstack((np.where(mag == 'None')[0], np.where(dmag == 'None')[0])))))\n",
    "    filters = np.delete(filters, mod_empty)\n",
    "    t = np.delete(t, mod_empty).astype(float)\n",
    "    flux = np.delete(flux, mod_empty).astype(float)\n",
    "    dflux = np.delete(dflux, mod_empty).astype(float)\n",
    "    mag = np.delete(mag, mod_empty).astype(float)\n",
    "    dmag = np.delete(dmag, mod_empty).astype(float)\n",
    "\n",
    "    # Finds negative fluxes\n",
    "    mod_positive = np.unique(np.hstack((np.hstack((np.where(flux <= 0)[0], np.where(dflux <= 0)[0])),\n",
    "                                np.hstack((np.where(mag <= 0)[0], np.where(dmag <= 0)[0])))))\n",
    "    filters = np.delete(filters, mod_positive)\n",
    "    t = np.delete(t, mod_positive)\n",
    "    flux = np.delete(flux, mod_positive)\n",
    "    dflux = np.delete(dflux, mod_positive)\n",
    "    mag = np.delete(mag, mod_positive)\n",
    "    dmag = np.delete(dmag, mod_positive)\n",
    "\n",
    "    # Find outliers beyond error limit\n",
    "    mod_err = np.unique(np.hstack(((np.where(abs(dflux) > err_max)[0]), np.where(abs(dmag) > err_max)[0]))) # Negatives fluxes & Error Limit\n",
    "    filters = np.delete(filters, mod_err)\n",
    "    t = np.delete(t, mod_err)\n",
    "    flux = np.delete(flux, mod_err)\n",
    "    dflux = np.delete(dflux, mod_err)\n",
    "    mag = np.delete(mag, mod_err)\n",
    "    dmag = np.delete(dmag, mod_err)\n",
    "\n",
    "    tempSN = ATLAS_SN(ATLASname=name, RA=np.average(data[:, 1].astype(float)), DEC=np.average(data[:, 2].astype(float)),\n",
    "                        t_o=t[np.where(filters=='o')[0]], flux_o=flux[np.where(filters=='o')[0]], dflux_o=dflux[np.where(filters=='o')[0]], mag_o=mag[np.where(filters=='o')[0]], dmag_o=dmag[np.where(filters=='o')[0]],\n",
    "                        t_c=t[np.where(filters=='c')[0]], flux_c=flux[np.where(filters=='c')[0]], dflux_c=dflux[np.where(filters=='c')[0]], mag_c=mag[np.where(filters=='c')[0]], dmag_c=dmag[np.where(filters=='c')[0]])\n",
    "\n",
    "    return tempSN\n",
    "\n",
    "# [3] - Save\n",
    "def atlas_write_to_file(SNe, t_lim=0.1, save_loc=ROOT_SAVE+'ATLAS_variables.txt', quiet=False, use_saved=True):\n",
    "    # Check for presaved data\n",
    "    savedData = {}\n",
    "    if use_saved and os.path.exists(save_loc):\n",
    "        data = np.genfromtxt(save_loc, delimiter=', ', dtype=str, skip_header=1)\n",
    "        if len(data) > 0:\n",
    "            for n in range(len(data[:, 0])):\n",
    "                savedData.update({data[n][1]: [data[n][0], data[n][4]]}) # atlasname: objname, z\n",
    "\n",
    "    with open(save_loc, 'w') as f:\n",
    "        f.write('objname, ATLASname, RA, DEC, z, tmin, tmax\\n') # Header\n",
    "        for n in range(len(SNe)):\n",
    "            if SNe[n].ATLASname in savedData:\n",
    "                obj = {'objname' : savedData[SNe[n].ATLASname][0], 'redshift' : savedData[SNe[n].ATLASname][1]}\n",
    "                SNe[n].objname = obj['objname']\n",
    "                SNe[n].z = obj['redshift']\n",
    "                print(\"Saved object data found for \"+SNe[n].ATLASname+\", retrieving...\")\n",
    "            else:\n",
    "                print(\"No saved data, sleeping for\", t_lim, 'seconds...')\n",
    "                time.sleep(t_lim)\n",
    "                obj = TNS_details(ra=SNe[n].RA, dec=SNe[n].DEC)\n",
    "                SNe[n].objname = 'SN'+obj['objname']\n",
    "                SNe[n].z = obj['redshift']\n",
    "\n",
    "            if len(SNe[n].t_o) > 0 and len(SNe[n].t_c) > 0:\n",
    "                t_max = max([np.max(SNe[n].t_o), np.max(SNe[n].t_c)])\n",
    "                t_min = min([np.min(SNe[n].t_o), np.min(SNe[n].t_c)])\n",
    "            elif len(SNe[n].t_o) == 0:\n",
    "                t_max = np.max(SNe[n].t_c)\n",
    "                t_min = np.min(SNe[n].t_c)\n",
    "            elif len(SNe[n].t_c) == 0:\n",
    "                t_max = np.max(SNe[n].t_o)\n",
    "                t_min = np.min(SNe[n].t_o)\n",
    "\n",
    "            if not quiet:\n",
    "                print('[ '+str(n+1)+' / '+str(len(SNe))+' ]', SNe[n].ATLASname+':', SNe[n].objname,\n",
    "                      '| z =', SNe[n].z, '| Tmin:', t_min, 'Tmax:', t_max, '\\n')\n",
    "            f.write(str(SNe[n].objname)+', '+str(SNe[n].ATLASname)+', '+str(SNe[n].RA)+', '+str(SNe[n].DEC)+', '+\n",
    "                    str(SNe[n].z)+', '+str(t_min)+', '+str(t_max)+'\\n')\n",
    "    return SNe\n",
    "\n",
    "def atlas_write_ASCII(SNe, quiet=True, use_saved=True):\n",
    "    knownVariables = {}\n",
    "    skip_header = True\n",
    "    variables_path = ROOT_SAVE+'ATLAS_variables.txt'\n",
    "    if use_saved and os.path.exists(variables_path):\n",
    "        with open(variables_path, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                if skip_header:\n",
    "                    skip_header = False\n",
    "                    pass\n",
    "                else:\n",
    "                    line = line[:-1].split(', ')\n",
    "                    name = line[1]\n",
    "                    line.remove(name)\n",
    "                    knownVariables.update({name : line})\n",
    "\n",
    "    ATLASnames = []\n",
    "    for SN in SNe:\n",
    "        ATLASnames.append(str(SN.objname)+'_snpy.txt')\n",
    "        with open(SNPY_DATA_ATLAS_PATH+str(SN.objname)+'_snpy.txt', 'w') as f:\n",
    "            if not quiet:\n",
    "                print(str(SN.objname)+' | z = '+str(SN.z)+', RA = '+str(SN.RA)+', DEC = '+str(SN.DEC))\n",
    "\n",
    "            # Line 1 -- Objname, Helio-Z, RA, Dec (Ex. SN1981D 0.005871 50.65992 -37.23272)\n",
    "            if SN.ATLASname in knownVariables.keys():\n",
    "                SN.objname = knownVariables[SN.ATLASname][0]\n",
    "            else:\n",
    "                print('No saved data for: '+str(SN.ATLASname)+', querying TNS...')\n",
    "                SN.objname = TNS_details(ra=SN.RA, dec=SN.DEC)['objname']\n",
    "            f.write(str(SN.objname)+' '+str(SN.z)+' '+str(SN.RA)+' '+str(SN.DEC)+'\\n')\n",
    "\n",
    "            # 'o'/'ATri'-filter photometry block -- Date (JD/MJD), mag, err (674.8593 12.94 0.11)\n",
    "            f.write('filter ATri\\n')\n",
    "            for i in range(len(SN.t_o)):\n",
    "                f.write(str(SN.t_o[i])+'\\t'+str(SN.mag_o[i])+'\\t'+str(SN.dmag_o[i])+'\\n')\n",
    "\n",
    "            # # 'c'/'ATgr'-filter photometry block\n",
    "            f.write('filter ATgr\\n')\n",
    "            for i in range(len(SN.t_c)):\n",
    "                f.write(str(SN.t_c[i])+'\\t'+str(SN.mag_c[i])+'\\t'+str(SN.dmag_c[i])+'\\n')\n",
    "    return ATLASnames\n",
    "\n",
    "# [4] - Fitting\n",
    "def atlas_fitting(SNe, save=True, output=True, show_plots=True, use_saved=True):\n",
    "    fit_args = {'model': 'EBV_model2', 'shape': 'st', 'bands': ['ATgr', 'ATri'], 'output': output, 'show_plots': show_plots, 'use_saved': use_saved}\n",
    "    paths = glob.glob(SNPY_DATA_ATLAS_PATH+'*')\n",
    "    params = snpy_fit(paths, plot_save=PLOTS_ATLAS_PATH, model_save=SNPY_MODELS_ATLAS_PATH, **fit_args)\n",
    "\n",
    "    SNe_new = [] # mu, z, st, Tmax, EBVhost, DM\n",
    "    for SN in SNe:\n",
    "        if SN.objname in params:\n",
    "            SN.mu = params[SN.objname][0]\n",
    "            SN.z = params[SN.objname][1]\n",
    "            SN.st = params[SN.objname][2]\n",
    "            SN.Tmax = params[SN.objname][3]\n",
    "            SN.EBVhost = params[SN.objname][4]\n",
    "            SN.DM = params[SN.objname][5]\n",
    "            SNe_new.append(SN)\n",
    "        else:\n",
    "            print(SN.objname, 'is a problem child, removing...')\n",
    "\n",
    "    # Save distance mod\n",
    "    if save:\n",
    "        saved_params = np.genfromtxt(ROOT_SAVE+'ATLAS_variables.txt', delimiter=', ', dtype=str, skip_header=1)\n",
    "        with open(ROOT_SAVE+'ATLAS_variables_fit.txt', 'w') as f:\n",
    "            f.write('objname, ATLASname, RA, DEC, z, tmin, tmax, mu, st, Tmax, EBVhost, DM\\n')\n",
    "            for n in range(len(SNe_new)):\n",
    "                f.write(str(saved_params[n, 0])+', '+str(saved_params[n, 1])+', '+str(saved_params[n, 2])+', '+str(saved_params[n, 3])+', '+\n",
    "                        str(saved_params[n, 4])+', '+str(saved_params[n, 5])+', '+str(saved_params[n, 6])+', '+str(SNe_new[n].mu)+', '+\n",
    "                        str(SNe_new[n].st)+', '+str(SNe_new[n].Tmax)+', '+str(SNe_new[n].EBVhost)+', '+str(SNe_new[n].DM)+'\\n')\n",
    "    return SNe_new\n",
    "\n",
    "# [5] - Plot\n",
    "def atlas_plot_selctor(SNe, plot_type='SOLO', saveLoc=PLOTS_ATLAS_PATH, save_plot=True, show_plot=True):\n",
    "    if plot_type == 'SOLO':\n",
    "        print(\"[5] Plotting data [solo]...\")\n",
    "        with ZipFile(saveLoc+'/ATLASplots.zip', 'w') as zip_object:\n",
    "            for n in range(len(SNe)):\n",
    "                n_name = SNe[n].objname\n",
    "                atlas_solo_plot([SNe[n].t_o, SNe[n].flux_o, SNe[n].dflux_o], [SNe[n].t_c, SNe[n].flux_c, SNe[n].dflux_c],\n",
    "                                title=str(n_name)+', ['+str(round(SNe[n].RA, 4))+', '+str(round(SNe[n].DEC, 4))+']',\n",
    "                                saveLoc=saveLoc+n_name+'_ATLASplot.png', save_plot=save_plot, show_plot=show_plot)\n",
    "                zip_object.write(PLOTS_ATLAS_PATH+n_name+'_ATLASplot.png')\n",
    "                print('Plot saved to', PLOTS_ATLAS_PATH+n_name+'_ATLASplot.png')\n",
    "    elif plot_type == 'COMBINED':\n",
    "        print(\"[5] Plotting data [combined]...\")\n",
    "        fig, axs = plt.subplots(len(SNe), figsize=(12, len(SNe)*3.2))\n",
    "        fig.tight_layout(pad=5.0)\n",
    "        for n in range(len(SNe)):\n",
    "            n_name = SNe[n].objname\n",
    "            atlas_combined_plot(axs[n], [SNe[n].t_o, SNe[n].flux_o, SNe[n].dflux_o], [SNe[n].t_c, SNe[n].flux_c, SNe[n].dflux_c],\n",
    "                                title=str(n_name)+', ['+str(round(SNe[n].RA, 4))+', '+str(round(SNe[n].DEC, 4))+']')\n",
    "        if save_plot:\n",
    "            plt.savefig(saveLoc+'CombinedATLASplots.png')\n",
    "            print('Plot saved to', saveLoc+'CombinedATLASplots.png')\n",
    "        if show_plot:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "    else:\n",
    "        print('Invalid plot type selected.')\n",
    "    return\n",
    "\n",
    "def atlas_solo_plot(data_o, data_c, title='Empty', saveLoc=PLOTS_ATLAS_PATH+'untitled.png', save_plot=True, show_plot=True):\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.errorbar(data_o[0], data_o[1], yerr=data_o[2], fmt='o', color='orange')\n",
    "    plt.errorbar(data_c[0], data_c[1], yerr=data_c[2], fmt='o', color='cyan')\n",
    "    plt.xlabel('Time [MJD]'); plt.ylabel('Flux [uJy]')\n",
    "    plt.title(title)\n",
    "    plt.ylim(0)\n",
    "    if save_plot:\n",
    "        plt.savefig(saveLoc)\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "    return\n",
    "\n",
    "def atlas_combined_plot(ax, data_o, data_c, title='Empty'):\n",
    "    ax.errorbar(data_o[0], data_o[1], yerr=data_o[2], fmt='o', color='orange')\n",
    "    ax.errorbar(data_c[0], data_c[1], yerr=data_c[2], fmt='o', color='cyan')\n",
    "    ax.set_xlabel('Time [MJD]'); ax.set_ylabel('Flux [uJy]')\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylim(0)\n",
    "    return\n",
    "\n",
    "def atlas_mu_z_plot():\n",
    "    data = np.genfromtxt(ROOT_SAVE+'ATLAS_variables_mu.txt', delimiter=', ', dtype=str, skip_header=1)\n",
    "    atlas_objs = {}\n",
    "    for n in range(len(data[:, 0])):\n",
    "        atlas_objs.update({data[:, 0][n]: {'z': data[n, 4],\n",
    "                                           'mu': data[n, 7]}})\n",
    "    for obj in atlas_objs:\n",
    "        plt.loglog(atlas_objs[obj]['z'], atlas_objs[obj]['mu'], 'x')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return\n",
    "\n",
    "def atlas_histograms(bins=30, save_loc=ROOT_SAVE, save_plot=True, show_plot=True):\n",
    "    data = np.genfromtxt(ROOT_SAVE+'ATLAS_variables_mu.txt', delimiter=', ', dtype=str, skip_header=1)\n",
    "    plot_param_hist(st=data[:, 8].astype(float), Tmax=data[:, 9].astype(float), EBVHost=data[:, 10].astype(float),\n",
    "                    bins=30, title='ATLAS SNooPy Fitting Parameters', save_plot=True, show_plot=True)\n",
    "    return\n",
    "\n",
    "def atlas_residuals(save_plot=True, show_plot=True):\n",
    "    dr3_dict = read_DR3()\n",
    "    ATLAS_data = np.genfromtxt('/content/HiloCATsSN1991bg/saved_data/ATLAS_variables_mu.txt', dtype=str, delimiter=', ', skip_header=1)\n",
    "    ATLAS_dict = {}\n",
    "    for n in range(len(ATLAS_data[:, 0])):\n",
    "        ATLAS_dict.update({ATLAS_data[:, 0][n]: {'st': float(ATLAS_data[:, 8][n]),\n",
    "                                                 'Tmax': float(ATLAS_data[:, 9][n]),\n",
    "                                                 'EBVHost': float(ATLAS_data[:, 10][n])}})\n",
    "\n",
    "    return\n",
    "\n"
   ],
   "metadata": {
    "id": "HYVS3t2oNN83"
   },
   "execution_count": 1668,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1669,
   "metadata": {
    "id": "3ExsdUj9XTCi"
   },
   "outputs": [],
   "source": [
    "\"\"\" BURNS \"\"\"\n",
    "# [1] - Initialize\n",
    "def burns_init(burnsData):\n",
    "    names_file ='/content/HiloCATsSN1991bg/targetLists/91bglike_justnames.txt'\n",
    "    names = np.genfromtxt(names_file, dtype=str, delimiter=', ')\n",
    "\n",
    "    data_file ='/content/HiloCATsSN1991bg/targetLists/burns+25table2ext.txt'\n",
    "    data = np.genfromtxt(data_file, dtype=str)\n",
    "\n",
    "    for name in names:\n",
    "        try:\n",
    "            burnsData.update({'SN'+name: {'burns_mu': float(data[np.where(data[:, 0] == name)[0], 14])}})\n",
    "        except:\n",
    "            print(name, 'not found...')\n",
    "            continue\n",
    "\n",
    "    return burnsData\n",
    "\n",
    "# [2] - Fitting\n",
    "def burns_fitting(burnsData, output=False, show_plots=False, use_saved=False):\n",
    "    paths = []\n",
    "    for name in burnsData:\n",
    "        n_path = '/content/HiloCATsSN1991bg/data/CSPdata/'+name+'_snpy.txt'\n",
    "        if os.path.exists(n_path):\n",
    "            paths.append(n_path)\n",
    "        else:\n",
    "            print('No file found for '+name+'...')\n",
    "\n",
    "    fit_args = {'model': 'EBV_model2', 'shape': 'st', 'bands': None, 'output': output, 'show_plots': show_plots, 'use_saved': use_saved}\n",
    "    params = snpy_fit(paths, plot_save=PLOTS_BURNS_PATH, model_save=SNPY_MODELS_BURNS_PATH, **fit_args)\n",
    "\n",
    "    temp_objs = {}\n",
    "    for obj in params:\n",
    "        temp_objs.update({obj: {'mu': float(params[obj][0]), 'z': float(params[obj][1]), 'st': float(params[obj][2]),\n",
    "                                'Tmax': float(params[obj][3]), 'EBVHost': float(params[obj][4]), 'DM': float(params[obj][5])}})\n",
    "    # print(temp_objs)\n",
    "    return temp_objs\n",
    "\n",
    "# [3] - Saving\n",
    "def burns_write_to_file(data):\n",
    "    with open(PARAM_BURNS_PATH+'burns_params.txt', 'w') as f:\n",
    "        f.write('objname, mu, st, Tmax, EBVHost, DM\\n')\n",
    "        for name in data:\n",
    "            f.write(name+', '+str(data[name]['mu'])+', '+str(data[name]['st'])+', '+\n",
    "                    str(data[name]['Tmax'])+', '+str(data[name]['EBVHost'])+', '+str(data[name]['DM'])+'\\n')\n",
    "    return\n",
    "\n",
    "# [4] - Plot\n",
    "def burns_histogram(show_plots=True, save_plot=False):\n",
    "    path = '/content/HiloCATsSN1991bg/saved_data/param/burns/burns_params.txt'\n",
    "    data = np.genfromtxt(path, delimiter=', ', skip_header=1, dtype=str)\n",
    "    print(data[:, 0])\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\" WORKFLOWS \"\"\"\n",
    "def Burns_process():\n",
    "    burnsData = {}\n",
    "\n",
    "    # [1] Initialize Data\n",
    "    print('[1] Initializing data...')\n",
    "    burnsData = burns_init(burnsData)\n",
    "\n",
    "    print('[2] Fitting Burns SNe...')\n",
    "    burnsData = burns_fitting(burnsData, output=False, show_plots=False, use_saved=True)\n",
    "\n",
    "    print('[3] Save fitting parameters...')\n",
    "    # dict_packer(burnsData, ROOT_SAVE+'burns_variables_fit.txt', delimiter=', ')\n",
    "    burns_write_to_file(burnsData)\n",
    "\n",
    "    print('[4] Plot data...')\n",
    "    burns_histogram()\n",
    "\n",
    "    return\n",
    "\n",
    "def ATLAS_process():\n",
    "    # [1] Collecting ATLAS data\n",
    "    print('[1] Collecting ATLAS data...')\n",
    "    atlas_collection(quiet=False, check_data=True)\n",
    "\n",
    "    # [2] Slice data & remove outliers\n",
    "    print('[2] Processing ATLAS data...')\n",
    "    SNe = atlas_processing(err_max=100, n_iter = 0, use_saved=True)\n",
    "    print('[2!] ATLAS data processed...', len(SNe), 'SN found and validated.')\n",
    "\n",
    "    # [3] Write ATLAS data to file\n",
    "    print('[3.1] Writing ATLAS data to file...')\n",
    "    SNe = atlas_write_to_file(SNe, t_lim=8, quiet=False, use_saved=True)\n",
    "    print('[3.2] Writing ATLAS ASCII files...')\n",
    "    ATLASnames = atlas_write_ASCII(SNe, quiet=False, use_saved=True)\n",
    "\n",
    "    # [4] SNooPy fitting\n",
    "    print('[4] Fitting ATLAS data with SNooPy...')\n",
    "    atlas_fitting(SNe, save=True, output=False, show_plots=False, use_saved=True)\n",
    "\n",
    "    # [5] Plotting\n",
    "    print('[5.1] Normal plotting...')\n",
    "    atlas_plot_selctor(SNe, plot_type='COMBINED', save_plot=True, show_plot=True)\n",
    "\n",
    "    # print('[5.2] Histogram plotting...')\n",
    "    # atlas_histograms(bins=30, save_plot=True, show_plot=True)\n",
    "\n",
    "    # print('[5.3] Residual plotting...')\n",
    "    # atlas_residuals(save_plot=True, show_plot=True)\n",
    "\n",
    "    # print('[5.4]')\n",
    "    # atlas_mu_z_plot()\n",
    "\n",
    "\n",
    "    return\n",
    "\n",
    "def ZTF_process():\n",
    "    # # [1] Pull ZTF data\n",
    "    # print('[1] Pulling ZTF data...')\n",
    "    # data = np.genfromtxt(ROOT_SAVE+'ATLAS_variables_mu.txt', delimiter=', ', skip_header=1, dtype=str)\n",
    "    # data_dict = {'ra': data[:, 2].astype(float), 'dec': data[:, 3].astype(float), 'jds': min(data[:, 6]), 'jde': max(data[:, 7])}\n",
    "    # ztf_collection(submit=False, **data_dict)\n",
    "\n",
    "    # [2] Processing ZTF data\n",
    "    print('[2] Processing ZTF data...')\n",
    "    ztfdata = ztf_processing(err_max=100)\n",
    "\n",
    "    # [4] Write to SNooPy ASCII\n",
    "    print('[3] Writing to ASCII for SNooPy fitting...')\n",
    "    ztf_write_to_ASCII(ztfdata)\n",
    "\n",
    "    # # [4] Fitting\n",
    "    # print('[4] Fitting with SNooPy...')\n",
    "    # ztf_fitting()\n",
    "\n",
    "    # # [5] Plotting\n",
    "    # print('[5.1] Normal plotting...')\n",
    "    # ztf_plotting(ztfdata, zoom=0, sigma=1, show_plot=False, save_plot=False)\n",
    "\n",
    "    # print('[5.2] Histogram plotting...')\n",
    "    # ztf_histogram(ztfdata)\n",
    "\n",
    "    # print('[5.3] Residuals plotting')\n",
    "    # ztf_residuals(t, flux, fluxerr, filter, objDetails['objname'])\n",
    "\n",
    "    return\n",
    "\n",
    "def test_realm():\n",
    "    csp_sne = glob.glob('/content/HiloCATsSN1991bg/data/CSPdata/*')\n",
    "    for n in range(len(csp_sne)):\n",
    "        csp_sne[n] = csp_sne[n][39:-9]\n",
    "\n",
    "\n",
    "\n",
    "    # atlas_dict = dict_unpacker(ROOT_SAVE+'ATLAS_variables_fit.txt', delimiter=', ').keys()\n",
    "    # burns_dict = dict_unpacker('/content/HiloCATsSN1991bg/saved_data/param/burns/burns_params.txt', delimiter=', ').keys()\n",
    "\n",
    "    # for name in burns_dict:\n",
    "    #     if name in atlas_dict:\n",
    "    #         print(name)\n",
    "\n",
    "    return\n",
    "\n",
    "def SALT3_process():\n",
    "    SALT2_ATLAS()\n",
    "\n",
    "    return\n",
    "\n",
    "def BurnsVDR3():\n",
    "    # Get Chris Burns Data\n",
    "    objnames = np.genfromtxt('/content/HiloCATsSN1991bg/targetLists/91bglike_justnames.txt', dtype=str, delimiter=', ')\n",
    "\n",
    "    # Get CSP paths of Chris Burns Data\n",
    "    objpaths = []\n",
    "    for name in objnames:\n",
    "        if os.path.exists('/content/HiloCATsSN1991bg/data/CSPdata/SN'+name+'_snpy.txt'):\n",
    "            objpaths.append('/content/HiloCATsSN1991bg/data/CSPdata/SN'+name+'_snpy.txt')\n",
    "        else:\n",
    "            print(name, 'not found...')\n",
    "\n",
    "    # Fitting with SNooPy\n",
    "    objs = {}\n",
    "    for n_path in objpaths:\n",
    "        objname = n_path[39:-9]\n",
    "        try:\n",
    "            n_s = snpy.get_sn(n_path)\n",
    "            n_s.choose_model('EBV_model2', stype='st')\n",
    "            n_s.set_restbands() # Auto pick appropriate rest-bands\n",
    "            fitargs = {'mangle':1,'calibration':0} # I don't remember what calibration is\n",
    "            n_s.fit(bands=None, dokcorr=True, k_stretch=False, reset_kcorrs=True, **fitargs)\n",
    "        except:\n",
    "            print(objname+'\\t| SNooPy failed to fit...')\n",
    "            continue\n",
    "        print(objname, '\\t| mu:', n_s.get_distmod(), 'z=', n_s.z, 'st=', n_s.st, 'Tmax=', n_s.Tmax, 'EBVHost=', n_s.EBVhost)\n",
    "        objs.update({objname: {'mu': n_s.get_distmod(), 'z': n_s.z, 'st': n_s.st, 'Tmax': n_s.Tmax, 'EBVHost': n_s.EBVhost}})\n",
    "\n",
    "    # Residuals (SNooPy - DR3)\n",
    "    st_res, Tmax_res, EBVHost_res = [], [], []\n",
    "    dr3 = read_DR3()\n",
    "    for obj in objs:\n",
    "        if obj in dr3:\n",
    "            st_res.append(objs[obj]['st'] - dr3[obj]['st'])\n",
    "            Tmax_res.append(objs[obj]['Tmax'] - dr3[obj]['Tmax'])\n",
    "            EBVHost_res.append(objs[obj]['EBVHost'] - dr3[obj]['EBVHost'])\n",
    "    res_params = [st_res, Tmax_res, EBVHost_res]\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    titles = ['st', 'Residuals of SNooPy - Chris Burns Parameters \\nTmax', 'EBVhost']\n",
    "    for i in range(len(titles)):\n",
    "        ax[i].hist(res_params[i], bins=30)\n",
    "        ax[i].set_title(titles[i])\n",
    "        ax[i].set_xlim(-np.max(np.abs(res_params[i])), np.max(np.abs(res_params[i])))\n",
    "    plt.show()\n",
    "\n",
    "    return\n"
   ],
   "metadata": {
    "id": "58PC6v_ax3c4"
   },
   "execution_count": 1670,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\" MAIN \"\"\"\n",
    "if __name__ == '__main__':\n",
    "    # NOTES\n",
    "        # Full start-up is ~15 minutes\n",
    "\n",
    "    # Runtime tracker\n",
    "    start = time.time()\n",
    "\n",
    "    # Recovering vital directories\n",
    "    recover_dir()\n",
    "\n",
    "    # Workflow select\n",
    "    # Burns_process()\n",
    "    # ATLAS_process()\n",
    "    # ZTF_process()\n",
    "    # SALT3_process()\n",
    "    # test_realm()\n",
    "\n",
    "    BurnsVDR3()\n",
    "\n",
    "\n",
    "    print('|---------------------------|\\n Run-time: ', round(time.time()-start, 4), 'seconds\\n|---------------------------|')"
   ],
   "metadata": {
    "id": "rI6R5V4-tUsZ"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
