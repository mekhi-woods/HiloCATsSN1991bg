{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXuZOpj5SIIBqvnqkxlvW9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mekhi-woods/HiloCATsSN1991bg/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \"\"\" DEPRICATED FUNCTIONS \"\"\"\n",
        "# Open\n",
        "    # def plot_91bglike_SN1a(FILTER_WHEEL = ['u', 'g', 'r', 'i', 'B', 'V0']):\n",
        "        # KrisciunasPath = \"/content/HiloCATsSN1991bg/targetLists/91bglike_justnames.txt\"\n",
        "        # KrisciunasNames = np.genfromtxt(KrisciunasPath, dtype=str, delimiter=', ')\n",
        "\n",
        "        # allCPSPhot = \"/content/HiloCATsSN1991bg/data/CSPdata/SN_photo.dat\"\n",
        "        # allCPSPhotData = np.genfromtxt(allCPSPhot, dtype='str')\n",
        "\n",
        "        # names = allCPSPhotData[:,0]\n",
        "        # filters = allCPSPhotData[:,1]\n",
        "        # time = allCPSPhotData[:,2]\n",
        "        # light = allCPSPhotData[:,3]\n",
        "        # err = allCPSPhotData[:,4]\n",
        "\n",
        "        # plt.figure(figsize=(10,6))\n",
        "        # sigma = 1\n",
        "        # for tar in KrisciunasNames:\n",
        "        #     for n in range(len(FILTER_WHEEL)):\n",
        "        #         # output_names = names[(names == tar) & (filters == FILTER_WHEEL[n])]\n",
        "        #         output_light = light[(names == tar) & (filters == FILTER_WHEEL[n])].astype('float64')\n",
        "        #         output_time = time[(names == tar) & (filters == FILTER_WHEEL[n])].astype('float64') + 53000\n",
        "        #         output_err = err[(names == tar) & (filters == FILTER_WHEEL[n])].astype('float64')\n",
        "        #         plt.errorbar(output_time, output_light, yerr=output_err*sigma, fmt='o', label=FILTER_WHEEL[n])\n",
        "\n",
        "        #     plt.title(tar); plt.xlabel('Time [MJD]'); plt.ylabel('Intensity [mag]')\n",
        "        #     plt.gca().invert_yaxis()\n",
        "        #     plt.legend()\n",
        "        #     # plt.savefig('save\\\\'+str(tar)+'.png')\n",
        "        #     plt.show()\n",
        "        #     break\n",
        "        # return\n",
        "\n",
        "    # def plot_DR3_tmax_st_EBVhost():\n",
        "        # data = np.genfromtxt('/content/HiloCATsSN1991bg/DR3_fits.dat', dtype=str, skip_header=1)\n",
        "        # DR3_st = np.stack((data[:, 1].astype(float), data[:, 2].astype(float)), axis=1)\n",
        "        # DR3_Tmax = np.stack((data[:, 5].astype(float), data[:, 6].astype(float)), axis=1)\n",
        "        # DR3_EBVhost = np.stack((data[:, 25].astype(float), data[:, 26].astype(float)), axis=1)\n",
        "\n",
        "        # fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,5))\n",
        "        # fig.suptitle(\"DR3's Tmax vs. st vs EBVhost\")\n",
        "        # sigmas = [[1, 1], [1, 1], [1, 1]]\n",
        "\n",
        "        # # Tmax vs. st\n",
        "        # ax1.errorbar(DR3_Tmax[:, 0], DR3_st[:, 0],\n",
        "        #              xerr=DR3_Tmax[:, 1]*sigmas[0][0], yerr=DR3_st[:, 1]*sigmas[0][1],\n",
        "        #              fmt='yo')\n",
        "        # ax1.set_xlabel('Tmax'); ax1.set_ylabel('st')\n",
        "        # ax1.set_title('Tmax vs. st, sigma(x='+str(sigmas[0][0])+', y='+str(sigmas[0][1])+')')\n",
        "\n",
        "        # # st vs. EBVhost\n",
        "        # ax2.errorbar(DR3_st[:, 0], DR3_EBVhost[:, 0],\n",
        "        #              xerr=DR3_st[:, 1]*sigmas[1][0], yerr=DR3_EBVhost[:, 1]*sigmas[1][1],\n",
        "        #              fmt='bo')\n",
        "        # ax2.set_xlabel('st'); ax2.set_ylabel('EBVhost')\n",
        "        # ax2.set_title('st vs. EBVhost, sigma(x='+str(sigmas[1][0])+', y='+str(sigmas[1][1])+')')\n",
        "\n",
        "        # # Tmax vs. EBVhost\n",
        "        # ax3.errorbar(DR3_Tmax[:, 0], DR3_EBVhost[:, 0],\n",
        "        #              xerr=DR3_Tmax[:, 1]*sigmas[2][0], yerr=DR3_EBVhost[:, 1]*sigmas[2][1],\n",
        "        #              fmt='ro')\n",
        "        # ax3.set_xlabel('Tmax'); ax3.set_ylabel('EBVhost')\n",
        "        # ax3.set_title('Tmax vs. EBVhost, sigma(x='+str(sigmas[2][0])+', y='+str(sigmas[2][1])+')')\n",
        "\n",
        "        # plt.show()\n",
        "        # return\n",
        "\n",
        "    # def snpy_fit(filePath, model='max_model', shapeParam='dm15', BandsToFit = ['B','g','r','i'], summarize=True, saveplots=False, saveLoc=SNPY_DATA_ATLAS_PATH, show_plots=True):\n",
        "        # s = snpy.get_sn(filePath)\n",
        "\n",
        "        # # Set model parameters\n",
        "        # s.choose_model(model, stype=shapeParam)\n",
        "        # s.set_restbands() # Auto pick appropriate rest-bands\n",
        "\n",
        "        # # Fit data -- using David configurations\n",
        "        # fitargs = {'mangle':1,'calibration':0, 'quiet':False} # I don't remember what calibration is\n",
        "        # s.fit(BandsToFit,\n",
        "        #       dokcorr=True,\n",
        "        #       k_stretch=False,\n",
        "        #       reset_kcorrs=True,\n",
        "        #       **fitargs)\n",
        "\n",
        "        # # Show results\n",
        "        # if summarize:\n",
        "        #     s.summary()\n",
        "        #     # for param in s.parameters:\n",
        "        #     #     print(\"{} = {} +/- {}\".format(param, s.parameters[param], s.errors[param]))\n",
        "        # if saveplots:\n",
        "        #     print('Plot saved to', SNPY_DATA_ATLAS_PATH+filePath[-17:-9]+'_snpyplots.png')\n",
        "        #     s.plot(outfile=SNPY_DATA_ATLAS_PATH+filePath[-17:-9]+'_snpyplots.png')\n",
        "        #     if show_plots:\n",
        "        #         plt.show()\n",
        "        #     else:\n",
        "        #         plt.close()\n",
        "\n",
        "        #     with ZipFile(SNPY_DATA_ATLAS_PATH+'snpyplots.zip', 'a') as zip_object:\n",
        "        #         zip_object.write(SNPY_DATA_ATLAS_PATH+filePath[-17:-9]+'_snpyplots.png')\n",
        "\n",
        "        # return s\n",
        "\n",
        "    # def SNooPy2_fitting(dataPath, tarNames, model='EBV_model2', shape='st', bands=['B','g','r','i'], output=False, snpyPlots=False, show_plots=True, use_saved=True):\n",
        "        # PROBLEM_CHILDREN = []\n",
        "\n",
        "        # if len(bands) == 0:\n",
        "        #     bands = None\n",
        "\n",
        "        # tarPaths = []\n",
        "        # for tar in tarNames:\n",
        "        #     tarPaths.append(dataPath+str(tar))\n",
        "\n",
        "        # SNe_mu = {}\n",
        "        # SNe_z = {}\n",
        "        # SNe_params = {}\n",
        "\n",
        "        # for i in range(len(tarPaths)):\n",
        "        #     tarName = tarNames[i][:-9]\n",
        "        #     tarSave = SNPY_ROOT+tarName+'_'+model+'.snpy'\n",
        "        #     print('[ '+str(i+1)+' / '+str(len(tarPaths))+'] Fiting data for '+tarName+'...')\n",
        "\n",
        "        #     # Create/Retrieve Fit\n",
        "        #     valid = True\n",
        "\n",
        "        #     if os.path.exists(tarSave) and use_saved:\n",
        "        #         print(tarName, 'found in files! Pulling data...')\n",
        "        #         s_n = snpy.get_sn(tarSave)\n",
        "        #     elif os.path.exists(tarPaths[i]):\n",
        "        #         try:\n",
        "        #             s_n = snpy_fit(tarPaths[i],\n",
        "        #                             model=model,\n",
        "        #                             shapeParam=shape,\n",
        "        #                             BandsToFit=None,\n",
        "        #                             summarize=output,\n",
        "        #                             saveplots=snpyPlots,\n",
        "        #                             saveLoc=SNPY_DATA_ATLAS_PATH,\n",
        "        #                             show_plots=show_plots) # Enter snpy fit function\n",
        "        #         except ValueError:\n",
        "        #             PROBLEM_CHILDREN.append(tarName)\n",
        "        #             print('[!!!] ValueError: No data near maximum light... skipping\\n')\n",
        "        #             valid = False\n",
        "        #         except RuntimeError:\n",
        "        #             PROBLEM_CHILDREN.append(tarName)\n",
        "        #             print('[!!!] RuntimeError: Model has trailed off fitting filter... skipping\\n')\n",
        "        #             valid = False\n",
        "        #         except TypeError:\n",
        "        #             PROBLEM_CHILDREN.append(tarName)\n",
        "        #             print('[!!!] TypeError: m > k must hold (I have no clue what this means)... skipping\\n')\n",
        "        #             valid = False\n",
        "        #         except:\n",
        "        #             PROBLEM_CHILDREN.append(tarName)\n",
        "        #             print('[!!!] Unknown Error... skipping\\n')\n",
        "        #             valid = False\n",
        "        #     else:\n",
        "        #         print(tarName, 'does not exsist in CSP data... skipping')\n",
        "        #         valid = False\n",
        "\n",
        "        #     if valid:\n",
        "        #         # Save model\n",
        "        #         s_n.save(tarSave)\n",
        "\n",
        "        #         # Pull SNooPY distance\n",
        "        #         snpy_mu = s_n.get_distmod() # Nab paramaters from SNe objects)\n",
        "\n",
        "        #         # Update dictionary/list\n",
        "        #         SNe_mu.update({tarName: snpy_mu})\n",
        "        #         SNe_z.update({tarName: s_n.z})\n",
        "        #         SNe_params.update({tarName: [s_n.st, s_n.Tmax, s_n.EBVhost, s_n.DM]})\n",
        "\n",
        "        #         # Print info\n",
        "        #         print('Redshift:\\t z = '+str(s_n.z))\n",
        "        #         print('Distance: \\t mu = '+str(round(snpy_mu, 4))+'\\n')\n",
        "\n",
        "        # print('Problem children:\\n', '[', len(PROBLEM_CHILDREN), ']', PROBLEM_CHILDREN)\n",
        "        # plt.close()\n",
        "        # return SNe_mu, SNe_z, SNe_params\n",
        "\n",
        "    # def ztf_query(targets, jds, jde):\n",
        "        # print(\"Number of (ra, dec) pairs =\", len(targets))\n",
        "\n",
        "        # ralist = []\n",
        "        # declist = []\n",
        "        # i = 0\n",
        "        # for tar in targets:\n",
        "        #     raval = float('%.7f'%(float(tar[0])))\n",
        "        #     decval = float('%.7f'%(float(tar[1])))\n",
        "        #     ralist.append(raval)\n",
        "        #     declist.append(decval)\n",
        "        #     i = i + 1\n",
        "        #     rem = i % 1500 # Limit submission to 1500 sky positions.\n",
        "        #     if rem == 0:\n",
        "        #         ztf_submit_post(ralist, declist, jds, jde)\n",
        "        #         ralist = []\n",
        "        #         declist = []\n",
        "        # if len(ralist) > 0:\n",
        "        #     ztf_submit_post(ralist, declist, jds, jde)\n",
        "        # return\n",
        "\n",
        "    # def ATLAS_snpy_fitting(SNe, ATLASnames, show_plot=True, use_saved=True):\n",
        "        # SNe_mu, SNe_z, SNe_params = SNooPy2_fitting(SNPY_DATA_ATLAS_PATH,\n",
        "        #                                             ATLASnames,\n",
        "        #                                             model='EBV_model2', shape='st', bands=['ATri', 'ATgr'],\n",
        "        #                                             output=True, snpyPlots=True, show_plots=show_plot, use_saved=use_saved)\n",
        "        # SNe_new = []\n",
        "        # for SN in SNe:\n",
        "        #     try:\n",
        "        #         SN.mu = SNe_mu[SN.objname]\n",
        "        #         SN.z = SNe_z[SN.objname]\n",
        "        #         SN.st = SNe_params[SN.objname][0]\n",
        "        #         SN.Tmax = SNe_params[SN.objname][1]\n",
        "        #         SN.EBVhost = SNe_params[SN.objname][2]\n",
        "        #         SN.DM = SNe_params[SN.objname][3]\n",
        "        #         SNe_new.append(SN)\n",
        "        #     except KeyError:\n",
        "        #         print(SN.objname, 'is a problem child, removing...')\n",
        "\n",
        "        # # Save distance mod\n",
        "        # params = np.genfromtxt(ROOT_SAVE+'ATLAS_variables.txt', delimiter=', ', dtype=str, skip_header=1)\n",
        "        # with open(ROOT_SAVE+'ATLAS_variables_mu.txt', 'w') as f:\n",
        "        #     f.write('objname, ATLASname, RA, DEC, z, tmin, tmax, mu\\n')\n",
        "        #     for n in range(len(SNe_new)):\n",
        "        #         f.write(str(params[n, 0])+', '+str(params[n, 1])+', '+str(params[n, 2])+', '+str(params[n, 3])+', '+\n",
        "        #                 str(params[n, 4])+', '+str(params[n, 5])+', '+str(params[n, 6])+', '+str(SNe_new[n].mu)+'\\n')\n",
        "\n",
        "        # return SNe_new\n",
        "\n",
        "    # def ATLAS_main_processing(err_max=100, yaxis='flux', t_lim = 0.1, n_iter = 0, plot_mode = 'SOLO', show_plot=True, use_saved=True):\n",
        "        # # [2.1] Aquire Data\n",
        "        # print('[2.1] Retrieving data from...', DATA_ATLAS_PATH)\n",
        "        # files = glob.glob(DATA_ATLAS_PATH+'/*')\n",
        "        # PROBLEM_CHILDREN = ['1032212120425304400']   # Running list of problematic SNe\n",
        "        #                                             # '1032212120425304400' - David believes it might be a shock breakout but ATLAS reports it as SN1a\n",
        "        #                                             #\n",
        "        # # [2.2] Validate Data\n",
        "        # print('[2.2] Sorting data...')\n",
        "        # SNe = []\n",
        "        # for n in range(len(files)):\n",
        "        #     print('[', n+1, '/', len(files), '] Validating data for...', files[n][48:-4])\n",
        "        #     result = slice_data(path=files[n], err_max=err_max)\n",
        "        #     if result != None:\n",
        "        #         SNe.append(result)\n",
        "        #     else:\n",
        "        #         PROBLEM_CHILDREN.append(files[n][48:-4])\n",
        "        #     if n_iter != 0 and n+1 >= n_iter:\n",
        "        #         break\n",
        "\n",
        "        # # [2.3] Remove problem children\n",
        "        # print('[2.3] Problem Children: ', PROBLEM_CHILDREN)\n",
        "        # for SN in SNe:\n",
        "        #     for probname in PROBLEM_CHILDREN:\n",
        "        #         if SN.ATLASname == probname:\n",
        "        #             print('Removing...', SN.ATLASname)\n",
        "\n",
        "        # # [2.4] Save RA, DEC, Redshift, and Object Name\n",
        "        # print('[2.4] Saving parameters to file...')\n",
        "        # print(t_lim, 'second pause between entries...')\n",
        "        # TNS_obj_detection(SNe, t_lim=t_lim, use_saved=use_saved)\n",
        "\n",
        "        # # [2.5] Plot data\n",
        "        # if plot_mode == 'SOLO':\n",
        "        #     print(\"[2.5] Plotting data [indivisual]...\")\n",
        "        #     with ZipFile(PLOTS_ATLAS_PATH+'/ATLASplots.zip', 'w') as zip_object:\n",
        "        #         for SN in SNe:\n",
        "        #             solo_plotting(name=SN.ATLASname, coords=[SN.RA, SN.DEC], err_max=err_max,\n",
        "        #                           t_o=SN.t_o, flux_o=SN.flux_o, flux_err_o=SN.dflux_o,\n",
        "        #                           t_c=SN.t_c, flux_c=SN.flux_c, flux_err_c=SN.dflux_c,\n",
        "        #                           save=True, saveLoc=PLOTS_ATLAS_PATH, show_plot=show_plot)\n",
        "        #             zip_object.write(PLOTS_ATLAS_PATH+SN.ATLASname+'_ATLASplot.png')\n",
        "        #             print('Plot saved to', PLOTS_ATLAS_PATH+SN.ATLASname+'_ATLASplot.png')\n",
        "        # elif plot_mode == 'COMBINED':\n",
        "        #     print(\"[2.5] Plotting data [combined]...\")\n",
        "        #     fig, axs = plt.subplots(len(SNe), figsize=(12, len(SNe)*3.2))\n",
        "        #     fig.tight_layout(pad=5.0)\n",
        "        #     for n in range(len(SNe)):\n",
        "        #         combined_plotting(ax=axs[n], name=SN.ATLASname, coords=[SN.RA, SN.DEC],\n",
        "        #                           t_o=SNe[n].t_o, flux_o=SNe[n].flux_o, flux_err_o=SNe[n].dflux_o,\n",
        "        #                           t_c=SN.t_c, flux_c=SN.flux_c, flux_err_c=SN.dflux_c)\n",
        "        #     plt.savefig(PLOTS_ATLAS_PATH+'CombinedATLASplots.png')\n",
        "        #     print('Plot saved to', PLOTS_ATLAS_PATH+'CombinedATLASplots.png')\n",
        "        #     if show_plot:\n",
        "        #         plt.show()\n",
        "        #     else:\n",
        "        #         plt.close()\n",
        "\n",
        "        # return SNe\n",
        "\n",
        "    # def snpy_ASCII_formatting(SNe):\n",
        "        # knownVariables = {}\n",
        "        # skip_header = True\n",
        "        # with open(ROOT_SAVE+'ATLAS_variables.txt', 'r') as f:\n",
        "        #     for line in f.readlines():\n",
        "        #         if skip_header:\n",
        "        #             skip_header = False\n",
        "        #             pass\n",
        "        #         else:\n",
        "        #             line = line[:-1].split(', ')\n",
        "        #             name = line[1]\n",
        "        #             line.remove(name)\n",
        "        #             knownVariables.update({name : line})\n",
        "\n",
        "        # ATLASnames = []\n",
        "        # for SN in SNe:\n",
        "        #     ATLASnames.append(str(SN.objname)+'_snpy.txt')\n",
        "        #     with open(SNPY_DATA_ATLAS_PATH+str(SN.objname)+'_snpy.txt', 'w') as f:\n",
        "        #         # Line 1\n",
        "        #         # Ex. SN1981D 0.005871 50.65992 -37.23272\n",
        "        #         #     Name    Helio Z  RA        Dec\n",
        "        #         try:\n",
        "        #             SN.objname = knownVariables[SN.ATLASname][0]\n",
        "        #         except KeyError:\n",
        "        #             print('No saved data for...', SN.ATLASname)\n",
        "        #         f.write(str(SN.objname)+' '+str(SN.z)+' '+str(SN.RA)+' '+str(SN.DEC)+'\\n')\n",
        "        #         print(str(SN.objname)+' '+str(SN.z)+' '+str(SN.RA)+' '+str(SN.DEC))\n",
        "\n",
        "        #         # 'ATri'-filter photometry block\n",
        "        #         # Ex. filter O\n",
        "        #         #     674.8593      12.94   0.11\n",
        "        #         #     Date (JD/MJD) mag     err\n",
        "        #         f.write('filter ATri\\n')\n",
        "        #         for i in range(len(SN.t_o)):\n",
        "        #             f.write(str(SN.t_o[i])+'\\t'+str(SN.mag_o[i])+'\\t'+str(SN.dmag_o[i])+'\\n')\n",
        "\n",
        "        #         # # 'ATgr'-filter photometry block\n",
        "        #         f.write('filter ATgr\\n')\n",
        "        #         for i in range(len(SN.t_c)):\n",
        "        #             f.write(str(SN.t_c[i])+'\\t'+str(SN.mag_c[i])+'\\t'+str(SN.dmag_c[i])+'\\n')\n",
        "        # return ATLASnames\n",
        "\n",
        "    # def data_collection(path=DATA_ATLAS_PATH, quiet=False):\n",
        "            # if os.path.exists(ROOT_SAVE+'tmp.npz'):\n",
        "            #     pickle = np.load(ROOT_SAVE+'tmp.npz', allow_pickle=True)\n",
        "            #     data = pickle['data']\n",
        "\n",
        "            # data = requests.post(\n",
        "            #     'https://star.pst.qub.ac.uk/sne/atlas4/api/objectlist/',\n",
        "            #     headers={'Authorization': f'Token {API_TOKEN}'},\n",
        "            #     data={'objectlistid':2}\n",
        "            # ).json()\n",
        "\n",
        "            # np.savez(ROOT_SAVE+'tmp.npz', data=data)\n",
        "\n",
        "            # count = 0\n",
        "            # for d in data:\n",
        "            #     if d['observation_status'] is not None and d['observation_status'].startswith('SN Ia') and '91bg' in d['observation_status']:\n",
        "            #         count += 1\n",
        "            #         if not quiet:\n",
        "            #             print(d['atlas_designation'],d['observation_status'].replace(' ',''),d['ra'],d['dec'])\n",
        "\n",
        "\n",
        "            #         ids = d['id']\n",
        "            #         base_url = 'https://star.pst.qub.ac.uk/sne/atlas4/lightcurveforced/1161048951013729300/'\n",
        "            #         new_url = base_url.replace('1161048951013729300/',str(ids))\n",
        "            #         if not quiet:\n",
        "            #             print(new_url)\n",
        "\n",
        "            #         idfile = path+'/' + str(ids)+'.txt'\n",
        "            #         if os.path.exists(idfile):\n",
        "            #             continue\n",
        "            #         urllib.request.urlretrieve(str(new_url), str(idfile))\n",
        "            #         if not quiet:\n",
        "            #             print(idfile)\n",
        "\n",
        "            #     if count > 300:\n",
        "            #         break\n",
        "\n",
        "    # def slice_data(path, err_max=100):\n",
        "        # name = path[48:-4]\n",
        "        # data = np.genfromtxt(path, dtype=str, delimiter=',')\n",
        "\n",
        "        # if len(data) == 0:\n",
        "        #     print('[!!!] File '+name+' empty...skipping')\n",
        "        #     return None\n",
        "\n",
        "        # filters = data[:, 6]\n",
        "        # t = data[:, 8].astype(float)\n",
        "        # flux = data[:, 24]\n",
        "        # dflux = data[:, 25]\n",
        "        # mag = np.char.replace(data[:, 3], '>', '') # Removes greater than symbols\n",
        "        # dmag = data[:, 4]\n",
        "\n",
        "        # # Finds the empty spots of flux and mag and records the element\n",
        "        # mod_empty = np.unique(np.hstack((np.hstack((np.where(flux == 'None')[0], np.where(dflux == 'None')[0])),\n",
        "        #                                  np.hstack((np.where(mag == 'None')[0], np.where(dmag == 'None')[0])))))\n",
        "        # filters = np.delete(filters, mod_empty)\n",
        "        # t = np.delete(t, mod_empty).astype(float)\n",
        "        # flux = np.delete(flux, mod_empty).astype(float)\n",
        "        # dflux = np.delete(dflux, mod_empty).astype(float)\n",
        "        # mag = np.delete(mag, mod_empty).astype(float)\n",
        "        # dmag = np.delete(dmag, mod_empty).astype(float)\n",
        "\n",
        "        # # Finds negative fluxes\n",
        "        # mod_positive = np.unique(np.hstack((np.hstack((np.where(flux <= 0)[0], np.where(dflux <= 0)[0])),\n",
        "        #                             np.hstack((np.where(mag <= 0)[0], np.where(dmag <= 0)[0])))))\n",
        "        # filters = np.delete(filters, mod_positive)\n",
        "        # t = np.delete(t, mod_positive)\n",
        "        # flux = np.delete(flux, mod_positive)\n",
        "        # dflux = np.delete(dflux, mod_positive)\n",
        "        # mag = np.delete(mag, mod_positive)\n",
        "        # dmag = np.delete(dmag, mod_positive)\n",
        "\n",
        "        # # Find outliers beyond error limit\n",
        "        # mod_err = np.unique(np.hstack(((np.where(abs(dflux) > err_max)[0]), np.where(abs(dmag) > err_max)[0]))) # Negatives fluxes & Error Limit\n",
        "        # filters = np.delete(filters, mod_err)\n",
        "        # t = np.delete(t, mod_err)\n",
        "        # flux = np.delete(flux, mod_err)\n",
        "        # dflux = np.delete(dflux, mod_err)\n",
        "        # mag = np.delete(mag, mod_err)\n",
        "        # dmag = np.delete(dmag, mod_err)\n",
        "\n",
        "        # tempSN = ATLAS_SN(ATLASname=name, RA=np.average(data[:, 1].astype(float)), DEC=np.average(data[:, 2].astype(float)),\n",
        "        #                     t_o=t[np.where(filters=='o')[0]], flux_o=flux[np.where(filters=='o')[0]], dflux_o=dflux[np.where(filters=='o')[0]], mag_o=mag[np.where(filters=='o')[0]], dmag_o=dmag[np.where(filters=='o')[0]],\n",
        "        #                     t_c=t[np.where(filters=='c')[0]], flux_c=flux[np.where(filters=='c')[0]], dflux_c=dflux[np.where(filters=='c')[0]], mag_c=mag[np.where(filters=='c')[0]], dmag_c=dmag[np.where(filters=='c')[0]])\n",
        "\n",
        "        # return tempSN\n",
        "\n",
        "    # def TNS_obj_detection(SNe, t_lim=0.1, saveLoc=ROOT_SAVE+'ATLAS_variables.txt', use_saved=True):\n",
        "        # # Check for presaved data\n",
        "        # savedData = {}\n",
        "        # if os.path.exists(saveLoc) and use_saved:\n",
        "        #     data = np.genfromtxt(saveLoc, delimiter=', ', dtype=str, skip_header=1)\n",
        "        #     if len(data) > 0:\n",
        "        #         for n in range(len(data[:, 0])):\n",
        "        #             savedData.update({data[n][1]: [data[n][0], data[n][4]]})\n",
        "\n",
        "        # with open(saveLoc, 'w') as f:\n",
        "        #     f.write('objname, ATLASname, RA, DEC, z, tmin, tmax\\n') # Header\n",
        "        #     for n in range(len(SNe)):\n",
        "        #         if SNe[n].ATLASname in savedData:\n",
        "        #             obj = {'objname' : savedData[SNe[n].ATLASname][0], 'redshift' : savedData[SNe[n].ATLASname][1]}\n",
        "        #             SNe[n].objname = obj['objname']\n",
        "        #             SNe[n].z = obj['redshift']\n",
        "        #             print(\"Saved object data found for \"+SNe[n].ATLASname+\", retrieving...\")\n",
        "        #         else:\n",
        "        #             print(\"No saved data, sleeping for\", t_lim, 'seconds...')\n",
        "        #             time.sleep(t_lim)\n",
        "        #             obj = TNS_details(ra=SNe[n].RA, dec=SNe[n].DEC)\n",
        "        #             SNe[n].objname = 'SN'+obj['objname']\n",
        "        #             SNe[n].z = obj['redshift']\n",
        "\n",
        "        #         if len(SNe[n].t_o) > 0 and len(SNe[n].t_c) > 0:\n",
        "        #             t_max = max([np.max(SNe[n].t_o), np.max(SNe[n].t_c)])\n",
        "        #             t_min = min([np.min(SNe[n].t_o), np.min(SNe[n].t_c)])\n",
        "        #         elif len(SNe[n].t_o) == 0:\n",
        "        #             t_max = np.max(SNe[n].t_c)\n",
        "        #             t_min = np.min(SNe[n].t_c)\n",
        "        #         elif len(SNe[n].t_c) == 0:\n",
        "        #             t_max = np.max(SNe[n].t_o)\n",
        "        #             t_min = np.min(SNe[n].t_o)\n",
        "\n",
        "        #         print('[ '+str(n+1)+' / '+str(len(SNe))+' ]', SNe[n].ATLASname+':', SNe[n].objname,\n",
        "        #               '| z =', SNe[n].z, '| Tmin:', t_min, 'Tmax:', t_max, '\\n')\n",
        "        #         f.write(str(SNe[n].objname)+', '+str(SNe[n].ATLASname)+', '+str(SNe[n].RA)+', '+str(SNe[n].DEC)+\n",
        "        #                 ', '+str(SNe[n].z)+', '+str(t_min)+', '+str(t_max)+'\\n')\n",
        "\n",
        "        # return\n",
        "\n",
        "    # def solo_plotting(t_o, t_c, flux_o, flux_c, flux_err_o, flux_err_c, err_max, name='Empty', coords=[0, 0], size=(12, 4), save=False, saveLoc=PLOTS_ATLAS_PATH, show_plot=True):\n",
        "        # plt.figure(figsize=size)\n",
        "\n",
        "        # plt.errorbar(t_o, flux_o, yerr=flux_err_o, fmt='o', color='orange')\n",
        "        # plt.errorbar(t_c, flux_c, yerr=flux_err_c, fmt='o', color='cyan')\n",
        "\n",
        "        # plt.title('Light Curve: '+str(name)+'\\n'+str(coords[0])+', '+str(coords[1])+'\\nMax Error = '+str(err_max))\n",
        "        # plt.xlabel('Time [MJD]')\n",
        "        # plt.ylabel('Flux [uJy]')\n",
        "        # plt.ylim(0)\n",
        "        # plt.savefig(saveLoc+name+'_ATLASplot.png')\n",
        "        # if show_plot:\n",
        "        #     plt.show()\n",
        "        # else:\n",
        "        #     plt.close()\n",
        "        # return\n",
        "\n",
        "    # def combined_plotting(ax, t_o, t_c, flux_o, flux_c, flux_err_o, flux_err_c, name='Empty', coords=[0, 0]):\n",
        "        # ax.errorbar(t_o, flux_o, yerr=flux_err_o, fmt='o', color='orange')\n",
        "        # ax.errorbar(t_c, flux_c, yerr=flux_err_c, fmt='o', color='cyan')\n",
        "\n",
        "        # ax.set_title('Light Curve: '+str(name)+'\\n'+str(coords[0])+', '+str(coords[1]))\n",
        "        # ax.set_xlabel('Time [MJD]')\n",
        "        # ax.set_ylabel('Flux [uJy]')\n",
        "        # ax.set_ylim(0)\n",
        "        # return\n",
        "\n",
        "    # def plot_ATLAS(xyo, xyc, ax=plt, name='Empty', coords=[0, 0], save=False, saveloc=PLOTS_ATLAS_PATH):\n",
        "        # ax.errorbar(xyo[0], xyo[1], yerr=xyo[2], fmt='o', color='orange')\n",
        "        # ax.errorbar(xyc[0], xyc[1], yerr=xyc[2], fmt='o', color='cyan')\n",
        "\n",
        "        # ax.set_title('Light Curve: '+str(name)+'\\n'+str(coords[0])+', '+str(coords[1]))\n",
        "        # ax.set_xlabel('Time [MJD]'); ax.set_ylabel('Flux [uJy]')\n",
        "        # if save:\n",
        "        #     plt.savefig(saveloc+name+'_ATLASplot.png')\n",
        "        # return\n",
        "\n",
        "    # def ATLAS_process():\n",
        "    # # [1] Collecting ATLAS data\n",
        "    # print('[1] Collecting ATLAS data...')\n",
        "    # data_collection(quiet=False)\n",
        "\n",
        "    # # [2] Slice data, remove outliers, & plot\n",
        "    # print('[2] Processing ATLAS data...')\n",
        "    # SNe = ATLAS_main_processing(err_max=100, t_lim = 10, n_iter = 0, plot_mode = 'SOLO', show_plot=False, use_saved=True)\n",
        "    # print('[2!] ATLAS data processed...', len(SNe), 'SN found and validated.')\n",
        "\n",
        "    # # [3] Write ATLAS data to SNooPy ASCII file\n",
        "    # print('[3] Writing ATLAS data to ASCII file for SNooPy...')\n",
        "    # ATLASnames = snpy_ASCII_formatting(SNe)\n",
        "\n",
        "    # # [4] SNooPy fitting\n",
        "    # print('[4] Fitting ATLAS data with SNooPy...')\n",
        "    # fit_args = {'model': 'EBV_model2', 'shape': 'st', 'bands': ['ATgr', 'ATri'], 'output': True, 'show_plots': True, 'use_saved': False}\n",
        "    # paths = glob.glob('/content/HiloCATsSN1991bg/saved_data/data/atlas_snpy/*')\n",
        "    # params = snpy_fit(paths[:5], plot_save=PLOTS_ROOT, model_save=SNPY_ROOT, **fit_args)\n",
        "\n",
        "    # SNe_new = [] # mu, z, st, Tmax, EBVhost, DM\n",
        "    # for SN in SNe:\n",
        "    #     try:\n",
        "    #         SN.mu = params[SN.objname][0]\n",
        "    #         SN.z = params[SN.objname][1]\n",
        "    #         SN.st = params[SN.objname][2]\n",
        "    #         SN.Tmax = params[SN.objname][3]\n",
        "    #         SN.EBVhost = params[SN.objname][4]\n",
        "    #         SN.DM = params[SN.objname][5]\n",
        "    #         SNe_new.append(SN)\n",
        "    #     except KeyError:\n",
        "    #         print(SN.objname, 'is a problem child, removing...')\n",
        "    # SNe = SNe_new # Replace list of SNe with new list\n",
        "\n",
        "    # # Save distance mod\n",
        "    # saved_params = np.genfromtxt(ROOT_SAVE+'ATLAS_variables.txt', delimiter=', ', dtype=str, skip_header=1)\n",
        "    # with open(ROOT_SAVE+'ATLAS_variables_mu.txt', 'w') as f:\n",
        "    #     f.write('objname, ATLASname, RA, DEC, z, tmin, tmax, mu\\n')\n",
        "    #     for n in range(len(SNe_new)):\n",
        "    #         f.write(str(saved_params[n, 0])+', '+str(saved_params[n, 1])+', '+str(saved_params[n, 2])+', '+str(saved_params[n, 3])+', '+\n",
        "    #                 str(saved_params[n, 4])+', '+str(saved_params[n, 5])+', '+str(saved_params[n, 6])+', '+str(SNe_new[n].mu)+'\\n')\n",
        "\n",
        "    # # # [5] SNooPy fit mu v. Redshift\n",
        "    # # plot_SNooPy_mu_vs_z()\n",
        "\n",
        "    # # # [6] Histogram of fit parameters\n",
        "    # # plot_SNooPy_hist(binNum=10)\n",
        "    # return\n"
      ],
      "metadata": {
        "id": "ctmVmhAwsg7d"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \"\"\" START UP \"\"\"\n",
        "# import os\n",
        "# import shutil\n",
        "# if os.path.exists('/content/HiloCATsSN1991bg') == True:\n",
        "#     shutil.rmtree('/content/HiloCATsSN1991bg')\n",
        "#     !git clone https://github.com/mekhi-woods/HiloCATsSN1991bg.git\n",
        "# else:\n",
        "#     !git clone https://github.com/mekhi-woods/HiloCATsSN1991bg.git\n",
        "\n",
        "# !pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple snpy\n",
        "# !pip install requests\n"
      ],
      "metadata": {
        "id": "gTAo57hVjmTa"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" IMPORTS \"\"\"\n",
        "import os\n",
        "import time\n",
        "import glob\n",
        "import json\n",
        "import snpy\n",
        "import shutil\n",
        "import requests\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import matplotlib.pyplot as plt\n",
        "from zipfile import ZipFile\n",
        "from requests.auth import HTTPBasicAuth\n",
        "from HiloCATsSN1991bg.scripts import tns_redshifts"
      ],
      "metadata": {
        "id": "bg3Q3CWYsvzj"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" GLOBALS \"\"\"\n",
        "# TNS CREDINTIALS\n",
        "tns_bot_id = '73181'\n",
        "tns_bot_name = 'YSE_Bot1'\n",
        "tns_bot_api_key = '0d771345fa6b876a5bb99cd5042ab8b5ae91fc67'\n",
        "\n",
        "# PATHS\n",
        "ROOT_SAVE = '/content/HiloCATsSN1991bg/saved_data/'\n",
        "\n",
        "## Raw Data\n",
        "DATA_ROOT = ROOT_SAVE+'data/'\n",
        "DATA_ATLAS_PATH = DATA_ROOT+'atlas/'\n",
        "DATA_ZTF_PATH = DATA_ROOT+'ztf/'\n",
        "\n",
        "## SNooPy\n",
        "SNPY_ROOT = ROOT_SAVE+'snpy/'\n",
        "SNPY_DATA_BURNS_PATH = SNPY_ROOT+'burns/'\n",
        "SNPY_MODELS_BURNS_PATH = SNPY_ROOT+'burns_models/'\n",
        "SNPY_DATA_ATLAS_PATH = SNPY_ROOT+'atlas/'\n",
        "SNPY_MODELS_ATLAS_PATH = SNPY_ROOT+'atlas_models/'\n",
        "SNPY_DATA_ZTF_PATH = SNPY_ROOT+'ztf/'\n",
        "SNPY_MODELS_ZTF_PATH = SNPY_ROOT+'ztf_models/'\n",
        "\n",
        "## Plotting\n",
        "PLOTS_ROOT = ROOT_SAVE+'plots/'\n",
        "PLOTS_BURNS_PATH = PLOTS_ROOT+'burns/'\n",
        "PLOTS_ATLAS_PATH = PLOTS_ROOT+'atlas/'\n",
        "PLOTS_ZTF_PATH = PLOTS_ROOT+'ztf/'\n",
        "\n",
        "PROBLEM_CHILDREN = ['1032212120425304400']  # Running list of problematic SNe\n",
        "                                            # '1032212120425304400' - David believes it might be a shock breakout but ATLAS reports it as SN1a\n",
        "                                            #\n"
      ],
      "metadata": {
        "id": "WbQz8fC_uhH6"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" CLASSES \"\"\"\n",
        "class ATLAS_SN():\n",
        "    def __init__(self, ATLASname='EmptySN', objname='SN####abc', RA=0.00000000000, DEC=0.00000000000, z=0.00000000000,\n",
        "                 DM=0.00, st=0.00, EBVhost=0.00, Tmax=0.00, mu=0.00,\n",
        "                 t_o=np.array([0]), flux_o=np.array([0]), dflux_o=np.array([0]), mag_o=np.array([0]), dmag_o=np.array([0]),\n",
        "                 t_c=np.array([0]), flux_c=np.array([0]), dflux_c=np.array([0]), mag_c=np.array([0]), dmag_c=np.array([0])):\n",
        "        self.ATLASname=ATLASname\n",
        "        self.objname=objname\n",
        "        self.RA=RA\n",
        "        self.DEC=DEC\n",
        "        self.z=z\n",
        "\n",
        "        self.t_o=t_o\n",
        "        self.flux_o=flux_o\n",
        "        self.dflux_o=dflux_o\n",
        "        self.mag_o=mag_o\n",
        "        self.dmag_o=dmag_o\n",
        "\n",
        "        self.t_c=t_c\n",
        "        self.flux_c=flux_c\n",
        "        self.dflux_c=dflux_c\n",
        "        self.mag_c=mag_c\n",
        "        self.dmag_c=dmag_c\n",
        "\n",
        "        self.mu = mu\n",
        "        self.DM = DM\n",
        "        self.st = st\n",
        "        self.EBVhost = EBVhost\n",
        "        self.Tmax = Tmax\n",
        "        return\n",
        "\n",
        "    def __str__(self):\n",
        "        return (self.objname+' : '+self.ATLASname+' @ ('+str(self.RA)+', '+str(self.DEC)+')\\n'+\n",
        "                'O-Filter:'+\n",
        "                '\\t t [MJD]: '+str(np.min(self.t_o))+'...'+str(np.max(self.t_o))+'\\n'+\n",
        "                '\\t\\t flux [uJy]: '+str(np.min(self.flux_o))+'...'+str(np.max(self.flux_o))+'\\n'+\n",
        "                '\\t\\t dflux [duJy]: '+str(np.min(self.dflux_o))+'...'+str(np.max(self.dflux_o))+'\\n'+\n",
        "                '\\t\\t mag: '+str(np.min(self.mag_o))+'...'+str(np.max(self.mag_o))+'\\n'+\n",
        "                '\\t\\t dmag: '+str(np.min(self.dmag_o))+'...'+str(np.max(self.dmag_o))+'\\n'+\n",
        "                'C-Filter:'+\n",
        "                '\\t t [MJD]: '+str(np.min(self.t_c))+'...'+str(np.max(self.t_c))+'\\n'+\n",
        "                '\\t\\t flux [uJy]: '+str(np.min(self.flux_c))+'...'+str(np.max(self.flux_c))+'\\n'+\n",
        "                '\\t\\t dflux [duJy]: '+str(np.min(self.dflux_c))+'...'+str(np.max(self.dflux_c))+'\\n'\n",
        "                '\\t\\t mag: '+str(np.min(self.mag_c))+'...'+str(np.max(self.mag_c))+'\\n'+\n",
        "                '\\t\\t dmag: '+str(np.min(self.dmag_c))+'...'+str(np.max(self.dmag_c))+'\\n'+\n",
        "                'Params:'+\n",
        "                '\\t Distance Mod [mu]: '+str(self.mu)+'\\n'+\n",
        "                '\\t\\t DM: '+str(self.DM)+'\\n'+\n",
        "                '\\t\\t Shape [st]: '+str(self.st)+'\\n'\n",
        "                '\\t\\t EBVhost: '+str(self.EBVhost)+'\\n'+\n",
        "                '\\t\\t Peak Time [Tmax]: '+str(self.Tmax)+'\\n')\n",
        "\n",
        "    def coords(self):\n",
        "        return('('+str(self.RA)+', '+str(self.DEC)+')')\n",
        "\n",
        "    def flux_to_mag(self):\n",
        "        return [[-2.5*np.log10(self.flux_o) + 23.9, 1.0857*self.dflux_o/self.flux_o],\n",
        "                [-2.5*np.log10(self.flux_c) + 23.9, 1.0857*self.dflux_c/self.flux_c]]\n"
      ],
      "metadata": {
        "id": "mxQPN393v8Qi"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "3ExsdUj9XTCi"
      },
      "outputs": [],
      "source": [
        "\"\"\" FUNCTIONS \"\"\"\n",
        "## GENERAL -----------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "def recover_dir():\n",
        "    directories = [ROOT_SAVE,\n",
        "                   DATA_ROOT, DATA_ATLAS_PATH, DATA_ZTF_PATH,\n",
        "                   SNPY_ROOT, SNPY_DATA_BURNS_PATH, SNPY_MODELS_BURNS_PATH,\n",
        "                   SNPY_DATA_ATLAS_PATH, SNPY_MODELS_ATLAS_PATH,\n",
        "                   SNPY_DATA_ZTF_PATH, SNPY_MODELS_ZTF_PATH,\n",
        "                   PLOTS_ROOT, PLOTS_BURNS_PATH, PLOTS_ATLAS_PATH, PLOTS_ZTF_PATH ]\n",
        "    for dir in directories:\n",
        "        if os.path.exists(dir) == False:\n",
        "            os.mkdir(dir)\n",
        "    if os.path.exists(SNPY_DATA_ATLAS_PATH+'/snpyplots.zip'):\n",
        "        os.remove(SNPY_DATA_ATLAS_PATH+'/snpyplots.zip')\n",
        "    # if os.path.exists(ROOT_SAVE) == False:\n",
        "    #     os.mkdir(ROOT_SAVE)\n",
        "    # if os.path.exists(SNPY_ROOT) == False:\n",
        "    #     os.mkdir(SNPY_ROOT)\n",
        "    # if os.path.exists(PLOTS_ROOT) == False:\n",
        "    #     os.mkdir(PLOTS_ROOT)\n",
        "    # if os.path.exists(DATA_ROOT) == False:\n",
        "    #     os.mkdir(DATA_ROOT)\n",
        "    # if os.path.DATA_ROOTOTS_ATLAS_PATH) == False:\n",
        "    #     os.mkdir(PLOTS_ATLAS_PATH)\n",
        "    # if os.path.exists(SNPY_DATA_ATLAS_PATH) == False:\n",
        "    #     os.mkdir(SNPY_DATA_ATLAS_PATH)\n",
        "    # if os.path.exists(DATA_ATLAS_PATH) == False:\n",
        "    #     os.mkdir(DATA_ATLAS_PATH)\n",
        "    # if os.path.exists(SNPY_DATA_ATLAS_PATH) == False:\n",
        "    #     os.mkdir(SNPY_DATA_ATLAS_PATH)\n",
        "    # if os.path.exists(DATA_ZTF_PATH) == False:\n",
        "    #     os.mkdir(DATA_ZTF_PATH)\n",
        "    # if os.path.exists(PLOTS_BURNS_PATH) == False:\n",
        "    #     os.mkdir(PLOTS_BURNS_PATH)\n",
        "    # if os.path.exists(SNPY_ROOT) == False:\n",
        "    #     os.mkdir(SNPY_ROOT)\n",
        "    # if os.path.exists(PLOTS_ZTF_PATH) == False:\n",
        "    #     os.mkdir(PLOTS_ZTF_PATH)\n",
        "    # if os.path.exists(SNPY_DATA_ZTF_PATH) == False:\n",
        "    #     os.mkdir(SNPY_DATA_ZTF_PATH)\n",
        "    return\n",
        "\n",
        "def TNS_details(ra, dec):\n",
        "    # Code from David\n",
        "\n",
        "    headers = tns_redshifts.build_tns_header(tns_bot_id, tns_bot_name)\n",
        "    tns_api_url = f\"https://www.wis-tns.org/api/get\"\n",
        "\n",
        "    # get the API URLs\n",
        "    search_tns_url = tns_redshifts.build_tns_url(tns_api_url, mode=\"search\")\n",
        "    get_tns_url = tns_redshifts.build_tns_url(tns_api_url, mode=\"get\")\n",
        "\n",
        "    search_data = tns_redshifts.build_tns_search_query_data(tns_bot_api_key, ra, dec)\n",
        "    transients = tns_redshifts.rate_limit_query_tns(search_data, headers, search_tns_url)\n",
        "\n",
        "    get_data = tns_redshifts.build_tns_get_query_data(tns_bot_api_key, transients[0])\n",
        "    transient_detail = tns_redshifts.rate_limit_query_tns(get_data, headers, get_tns_url)\n",
        "\n",
        "    return transient_detail\n",
        "\n",
        "def snpy_fit(paths, plot_save=PLOTS_ROOT, model_save=SNPY_ROOT,\n",
        "             model='EBV_model2', shape='st', bands=None, output=False, show_plots=False, use_saved=True):\n",
        "    params = {} # mu, z, st, Tmax, EBVhost, DM\n",
        "    n_targets = len(paths)\n",
        "    for n in range(n_targets):\n",
        "        # Set up iterable variables\n",
        "        n_name = paths[n][:-9].split('/')[-1] # Splits along backslash and removes '.txt'\n",
        "        n_save = model_save + n_name + '_' + model + '.snpy'\n",
        "        n_path = paths[n]\n",
        "        print('[ '+str(n+1)+' / '+str(n_targets)+'] Fiting data for '+n_name+'...')\n",
        "\n",
        "        # Attempt to retrieve previous fits\n",
        "        if os.path.exists(n_save) and use_saved:\n",
        "            print(n_name, 'found in files! Pulling data...')\n",
        "            n_s = snpy.get_sn(n_save)\n",
        "\n",
        "        # If no saved data / used_save=False, run fit\n",
        "        else:\n",
        "            try:\n",
        "                # Fit data -- using David configurations\n",
        "                print(n_path)\n",
        "                n_s = snpy.get_sn(n_path)\n",
        "                n_s.choose_model(model, stype=shape)\n",
        "                n_s.set_restbands() # Auto pick appropriate rest-bands\n",
        "                fitargs = {'mangle':1,'calibration':0} # I don't remember what calibration is\n",
        "                n_s.fit(bands=bands, dokcorr=True, k_stretch=False, reset_kcorrs=True, **fitargs)\n",
        "            except:\n",
        "                # If error, return None\n",
        "                n_s = None\n",
        "                PROBLEM_CHILDREN.append(n_name)\n",
        "                print('[!!!] Unknown Error... skipping\\n')\n",
        "\n",
        "        # If fit was successful, save\n",
        "        if n_s is not None:\n",
        "            n_mu = n_s.get_distmod()\n",
        "\n",
        "            # Save Model\n",
        "            n_s.save(n_save)\n",
        "\n",
        "            # Save paramaters - mu, z, st, Tmax, EBVhost, DM\n",
        "            params.update({n_name : [n_mu, n_s.z, n_s.st, n_s.Tmax, n_s.EBVhost, n_s.DM]})\n",
        "\n",
        "            # Print output\n",
        "            if output:\n",
        "                # Print fit summary\n",
        "                n_s.summary()\n",
        "\n",
        "                # Print paramaters\n",
        "                print('Redshift:\\t z = '+str(n_s.z))\n",
        "                print('Distance: \\t mu = '+str(round(n_mu, 4))+'\\n')\n",
        "\n",
        "            # Plotting\n",
        "            n_s.plot(outfile=plot_save+n_name+'_snpyplots.png')\n",
        "            if show_plots:\n",
        "                plt.show()\n",
        "            else:\n",
        "                plt.close()\n",
        "\n",
        "    print('Problem children:\\n', '[', len(PROBLEM_CHILDREN), ']', PROBLEM_CHILDREN)\n",
        "    plt.clf()\n",
        "    return params\n",
        "\n",
        "def plot_SNooPy_mu_vs_z(save_plot=True, saveLoc=SNPY_DATA_ATLAS_PATH):\n",
        "    data = np.genfromtxt(ROOT_SAVE+'ATLAS_variables.txt', delimiter=', ', dtype=str, skip_header=1)\n",
        "    name, mu, z = data[:, 0], data[:, 7].astype(float), data[:, 4].astype(float)\n",
        "\n",
        "    print(mu)\n",
        "    print(z)\n",
        "\n",
        "\n",
        "    for n in range(len(name)):\n",
        "        plt.loglog(z[n], mu[n], 'o')\n",
        "        if z[n] < 0.0125:\n",
        "            plt.text(z[n], mu[n], name[n], fontsize='xx-small')\n",
        "    plt.xlabel('Redshift [z]'); plt.ylabel('Distance Modulus [mu]')\n",
        "    plt.title('ATLAS SNe -- Fitted with SNooPy \\nDistance Modulus v. Redshift')\n",
        "    if save_plot:\n",
        "        plt.savefig(saveLoc+'SNooPy_mu_vs_z.png')\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "def plot_SNooPy_hist(binNum=10, save_plot=True, saveLoc=SNPY_DATA_ATLAS_PATH):\n",
        "    data = np.genfromtxt(ROOT_SAVE+'ATLAS_variables.txt', delimiter=', ', dtype=str, skip_header=1)\n",
        "    paramsData = [data[:, 3].astype(float), data[:, 4].astype(float), data[:, 5].astype(float)]\n",
        "    paramsNames = ['st', 'ATLAS SNooPy Fitting Parameters \\n Tmax', 'EBVhost']\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    for n in range(len(paramsNames)):\n",
        "        axes[n].hist(paramsData[n], bins=binNum)\n",
        "        axes[n].set_title(paramsNames[n])\n",
        "    if save_plot:\n",
        "        plt.savefig(saveLoc+'SNooPy_params_hist.png')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    return\n",
        "\n",
        "def plot_DvD(snpyDistances, burnsDistances, size=(8,5), save=False):\n",
        "    print(\"Ploting differences in distance calculations...\")\n",
        "    plt.figure(figsize=size)\n",
        "    for x in snpyDistances:\n",
        "        try:\n",
        "            plt.scatter(burnsDistances[x], snpyDistances[x], marker='o')\n",
        "            plt.text(burnsDistances[x]+0.05, snpyDistances[x]-0.05, x, fontsize='xx-small')\n",
        "            print('Burns Distance:', burnsDistances[x], '| SNooPy Distance:', snpyDistances[x])\n",
        "        except KeyError:\n",
        "            print(x, 'not found.')\n",
        "            pass\n",
        "    plt.title(\"Burns v. SNooPy Distance\")\n",
        "    plt.xlabel('Burns Distance'); plt.ylabel('SNooPy Distance')\n",
        "    plt.xlim(min(burnsDistances.values()), max(burnsDistances.values()))\n",
        "    plt.ylim(min(burnsDistances.values()), max(burnsDistances.values()))\n",
        "\n",
        "    if save:\n",
        "        plt.savefig('burns_v_snpy_dist.png')\n",
        "\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "def plot_residuals(snpyDistances, burnsDistances, snpyRedshifts, size=(8,5), save=False):\n",
        "    print(\"Ploting residuals...\")\n",
        "    plt.figure(figsize=size)\n",
        "    for x in snpyDistances:\n",
        "        try:\n",
        "            plt.scatter(snpyRedshifts[x], abs(burnsDistances[x]-snpyDistances[x]), marker='o')\n",
        "            plt.text(snpyRedshifts[x], abs(burnsDistances[x]-snpyDistances[x]), x, fontsize='xx-small')\n",
        "            print('Redshift:', snpyRedshifts[x], '| Burns-SNooPy Distance:', burnsDistances[x]-snpyDistances[x])\n",
        "        except KeyError:\n",
        "            print(x, 'not found.')\n",
        "            pass\n",
        "    plt.title(\"Burns-SNooPy Residuals\"); plt.xlabel('Redshift'); plt.ylabel('Burns-SNooPy')\n",
        "    if save:\n",
        "        plt.savefig('burns-snpy_res.png')\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "def read_DR3(loc='/content/HiloCATsSN1991bg/DR3_fits.dat'):\n",
        "    data = np.genfromtxt(loc, dtype=str, skip_header=1)\n",
        "    dr3 = {}\n",
        "    for n in range(len(data[:, 0])):\n",
        "        dr3.update({data[:, 0][n]: {'st': float(data[:, 1][n]), 'e_st': float(data[:, 2][n]), 'z': float(data[:, 3][n]),\n",
        "                           'Tmax': float(data[:, 5][n]), 'e_Tmax': float(data[:, 6][n]),\n",
        "                           'EBVHost': float(data[:, 25][n]), 'e_EBVHost': float(data[:, 26][n])}})\n",
        "    return dr3\n",
        "\n",
        "## BURNS -------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# [1] - Initialize\n",
        "def burns_init(name_path='/content/HiloCATsSN1991bg/targetLists/91bglike_justnames.txt', DATA_ROOT='/content/HiloCATsSN1991bg/targetLists/burns+25table2ext.txt'):\n",
        "    burnsNames = np.genfromtxt(name_path, dtype=str, delimiter=', ')\n",
        "    burnsData = np.genfromtxt(DATA_ROOT, dtype=str)\n",
        "    burnsDistances = {}\n",
        "    burnsNames = burnsData[:, 0]\n",
        "    for tar in np.stack((burnsData[:, 0], burnsData[:, 14]), axis=1):\n",
        "        burnsDistances.update({'SN'+tar[0]: float(tar[1])})\n",
        "    return burnsDistances, burnsNames\n",
        "\n",
        "def burns_fitting(names):\n",
        "    paths = []\n",
        "    for name in names:\n",
        "        paths.append('/content/HiloCATsSN1991bg/data/CSPdata/SN'+name+'_snpy.txt')\n",
        "    fit_args = {'model': 'EBV_model2', 'shape': 'st', 'bands': None, 'output': False, 'show_plots': False, 'use_saved': True}\n",
        "    params = snpy_fit(paths, plot_save=PLOTS_BURNS_PATH, model_save=SNPY_ROOT, **fit_args)\n",
        "\n",
        "    objname, z, mu = np.array([]), np.array([]), np.array([])\n",
        "    for obj in params:\n",
        "        objname = np.append(objname, obj)\n",
        "        z = np.append(z, params[obj][1])\n",
        "        mu = np.append(mu, params[obj][0])\n",
        "    return objname, z, mu\n",
        "\n",
        "## ATLAS -------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# [1] - Collect\n",
        "def atlas_collection(path=DATA_ATLAS_PATH, quiet=False, check_data=True):\n",
        "    if check_data and len(glob.glob(DATA_ATLAS_PATH+'*')) > 1:\n",
        "        print('ATLAS data already collected, passing step...')\n",
        "        return\n",
        "    else:\n",
        "        print('No data detected, collecting ATLAS data...')\n",
        "        if os.path.exists(ROOT_SAVE+'tmp.npz'):\n",
        "            pickle = np.load(ROOT_SAVE+'tmp.npz', allow_pickle=True)\n",
        "            data = pickle['data']\n",
        "\n",
        "        data = requests.post(\n",
        "            'https://star.pst.qub.ac.uk/sne/atlas4/api/objectlist/',\n",
        "            headers={'Authorization': f'Token {API_TOKEN}'},\n",
        "            data={'objectlistid':2}\n",
        "        ).json()\n",
        "\n",
        "        np.savez(ROOT_SAVE+'tmp.npz', data=data)\n",
        "\n",
        "        count = 0\n",
        "        for d in data:\n",
        "            if d['observation_status'] is not None and d['observation_status'].startswith('SN Ia') and '91bg' in d['observation_status']:\n",
        "                count += 1\n",
        "                if not quiet:\n",
        "                    print(d['atlas_designation'],d['observation_status'].replace(' ',''),d['ra'],d['dec'])\n",
        "\n",
        "\n",
        "                ids = d['id']\n",
        "                base_url = 'https://star.pst.qub.ac.uk/sne/atlas4/lightcurveforced/1161048951013729300/'\n",
        "                new_url = base_url.replace('1161048951013729300/',str(ids))\n",
        "                if not quiet:\n",
        "                    print(new_url)\n",
        "\n",
        "                idfile = path+'/' + str(ids)+'.txt'\n",
        "                if os.path.exists(idfile):\n",
        "                    continue\n",
        "                urllib.request.urlretrieve(str(new_url), str(idfile))\n",
        "                if not quiet:\n",
        "                    print(idfile)\n",
        "\n",
        "            if count > 300:\n",
        "                break\n",
        "    return\n",
        "\n",
        "# [2] - Process\n",
        "def atlas_processing(err_max=100, n_iter = 0, use_saved=True):\n",
        "    # [2.1] Aquire Data\n",
        "    print('[2.1] Retrieving data from...', DATA_ATLAS_PATH)\n",
        "    files = glob.glob(DATA_ATLAS_PATH+'/*')\n",
        "    # [2.2] Validate Data\n",
        "    print('[2.2] Sorting data...')\n",
        "    SNe = []\n",
        "    tar_num = len(files)\n",
        "    for n in range(tar_num):\n",
        "        n_name = files[n][48:-4]\n",
        "        print('[', n+1, '/', len(files), '] Validating data for...', n_name)\n",
        "        result = atlas_slice_data(path=files[n], err_max=err_max)\n",
        "        if result != None:\n",
        "            SNe.append(result)\n",
        "        else:\n",
        "            PROBLEM_CHILDREN.append(n_name)\n",
        "        if n_iter != 0 and n+1 >= n_iter:\n",
        "            break\n",
        "\n",
        "    # [2.3] Remove problem children\n",
        "    print('[2.3] Problem Children: ', PROBLEM_CHILDREN)\n",
        "    for SN in SNe:\n",
        "        for probname in PROBLEM_CHILDREN:\n",
        "            if SN.ATLASname == probname:\n",
        "                print('Removing...', SN.ATLASname)\n",
        "                SNe.remove(SN)\n",
        "    return SNe\n",
        "\n",
        "def atlas_slice_data(path, err_max=100):\n",
        "    name = path[48:-4]\n",
        "    data = np.genfromtxt(path, dtype=str, delimiter=',')\n",
        "\n",
        "    if len(data) == 0:\n",
        "        print('[!!!] File '+name+' empty...skipping')\n",
        "        return None\n",
        "\n",
        "    filters = data[:, 6]\n",
        "    t = data[:, 8].astype(float)\n",
        "    flux = data[:, 24]\n",
        "    dflux = data[:, 25]\n",
        "    mag = np.char.replace(data[:, 3], '>', '') # Removes greater than symbols\n",
        "    dmag = data[:, 4]\n",
        "\n",
        "    # Finds the empty spots of flux and mag and records the element\n",
        "    mod_empty = np.unique(np.hstack((np.hstack((np.where(flux == 'None')[0], np.where(dflux == 'None')[0])),\n",
        "                                     np.hstack((np.where(mag == 'None')[0], np.where(dmag == 'None')[0])))))\n",
        "    filters = np.delete(filters, mod_empty)\n",
        "    t = np.delete(t, mod_empty).astype(float)\n",
        "    flux = np.delete(flux, mod_empty).astype(float)\n",
        "    dflux = np.delete(dflux, mod_empty).astype(float)\n",
        "    mag = np.delete(mag, mod_empty).astype(float)\n",
        "    dmag = np.delete(dmag, mod_empty).astype(float)\n",
        "\n",
        "    # Finds negative fluxes\n",
        "    mod_positive = np.unique(np.hstack((np.hstack((np.where(flux <= 0)[0], np.where(dflux <= 0)[0])),\n",
        "                                np.hstack((np.where(mag <= 0)[0], np.where(dmag <= 0)[0])))))\n",
        "    filters = np.delete(filters, mod_positive)\n",
        "    t = np.delete(t, mod_positive)\n",
        "    flux = np.delete(flux, mod_positive)\n",
        "    dflux = np.delete(dflux, mod_positive)\n",
        "    mag = np.delete(mag, mod_positive)\n",
        "    dmag = np.delete(dmag, mod_positive)\n",
        "\n",
        "    # Find outliers beyond error limit\n",
        "    mod_err = np.unique(np.hstack(((np.where(abs(dflux) > err_max)[0]), np.where(abs(dmag) > err_max)[0]))) # Negatives fluxes & Error Limit\n",
        "    filters = np.delete(filters, mod_err)\n",
        "    t = np.delete(t, mod_err)\n",
        "    flux = np.delete(flux, mod_err)\n",
        "    dflux = np.delete(dflux, mod_err)\n",
        "    mag = np.delete(mag, mod_err)\n",
        "    dmag = np.delete(dmag, mod_err)\n",
        "\n",
        "    tempSN = ATLAS_SN(ATLASname=name, RA=np.average(data[:, 1].astype(float)), DEC=np.average(data[:, 2].astype(float)),\n",
        "                        t_o=t[np.where(filters=='o')[0]], flux_o=flux[np.where(filters=='o')[0]], dflux_o=dflux[np.where(filters=='o')[0]], mag_o=mag[np.where(filters=='o')[0]], dmag_o=dmag[np.where(filters=='o')[0]],\n",
        "                        t_c=t[np.where(filters=='c')[0]], flux_c=flux[np.where(filters=='c')[0]], dflux_c=dflux[np.where(filters=='c')[0]], mag_c=mag[np.where(filters=='c')[0]], dmag_c=dmag[np.where(filters=='c')[0]])\n",
        "\n",
        "    return tempSN\n",
        "\n",
        "# [3] - Save\n",
        "def atlas_write_to_file(SNe, t_lim=0.1, save_loc=ROOT_SAVE+'ATLAS_variables.txt', quiet=False, use_saved=True):\n",
        "    # Check for presaved data\n",
        "    savedData = {}\n",
        "    if use_saved and os.path.exists(save_loc):\n",
        "        data = np.genfromtxt(save_loc, delimiter=', ', dtype=str, skip_header=1)\n",
        "        if len(data) > 0:\n",
        "            for n in range(len(data[:, 0])):\n",
        "                savedData.update({data[n][1]: [data[n][0], data[n][4]]}) # atlasname: objname, z\n",
        "\n",
        "    with open(save_loc, 'w') as f:\n",
        "        f.write('objname, ATLASname, RA, DEC, z, tmin, tmax\\n') # Header\n",
        "        for n in range(len(SNe)):\n",
        "            if SNe[n].ATLASname in savedData:\n",
        "                obj = {'objname' : savedData[SNe[n].ATLASname][0], 'redshift' : savedData[SNe[n].ATLASname][1]}\n",
        "                SNe[n].objname = obj['objname']\n",
        "                SNe[n].z = obj['redshift']\n",
        "                print(\"Saved object data found for \"+SNe[n].ATLASname+\", retrieving...\")\n",
        "            else:\n",
        "                print(\"No saved data, sleeping for\", t_lim, 'seconds...')\n",
        "                time.sleep(t_lim)\n",
        "                obj = TNS_details(ra=SNe[n].RA, dec=SNe[n].DEC)\n",
        "                SNe[n].objname = 'SN'+obj['objname']\n",
        "                SNe[n].z = obj['redshift']\n",
        "\n",
        "            if len(SNe[n].t_o) > 0 and len(SNe[n].t_c) > 0:\n",
        "                t_max = max([np.max(SNe[n].t_o), np.max(SNe[n].t_c)])\n",
        "                t_min = min([np.min(SNe[n].t_o), np.min(SNe[n].t_c)])\n",
        "            elif len(SNe[n].t_o) == 0:\n",
        "                t_max = np.max(SNe[n].t_c)\n",
        "                t_min = np.min(SNe[n].t_c)\n",
        "            elif len(SNe[n].t_c) == 0:\n",
        "                t_max = np.max(SNe[n].t_o)\n",
        "                t_min = np.min(SNe[n].t_o)\n",
        "\n",
        "            if not quiet:\n",
        "                print('[ '+str(n+1)+' / '+str(len(SNe))+' ]', SNe[n].ATLASname+':', SNe[n].objname,\n",
        "                      '| z =', SNe[n].z, '| Tmin:', t_min, 'Tmax:', t_max, '\\n')\n",
        "            f.write(str(SNe[n].objname)+', '+str(SNe[n].ATLASname)+', '+str(SNe[n].RA)+', '+str(SNe[n].DEC)+', '+\n",
        "                    str(SNe[n].z)+', '+str(t_min)+', '+str(t_max)+'\\n')\n",
        "    return SNe\n",
        "\n",
        "def atlas_write_ASCII(SNe, quiet=True, use_saved=True):\n",
        "    knownVariables = {}\n",
        "    skip_header = True\n",
        "    variables_path = ROOT_SAVE+'ATLAS_variables.txt'\n",
        "    if use_saved and os.path.exists(variables_path):\n",
        "        with open(variables_path, 'r') as f:\n",
        "            for line in f.readlines():\n",
        "                if skip_header:\n",
        "                    skip_header = False\n",
        "                    pass\n",
        "                else:\n",
        "                    line = line[:-1].split(', ')\n",
        "                    name = line[1]\n",
        "                    line.remove(name)\n",
        "                    knownVariables.update({name : line})\n",
        "\n",
        "    ATLASnames = []\n",
        "    for SN in SNe:\n",
        "        ATLASnames.append(str(SN.objname)+'_snpy.txt')\n",
        "        with open(SNPY_DATA_ATLAS_PATH+str(SN.objname)+'_snpy.txt', 'w') as f:\n",
        "            if not quiet:\n",
        "                print(str(SN.objname)+' | z = '+str(SN.z)+', RA = '+str(SN.RA)+', DEC = '+str(SN.DEC))\n",
        "\n",
        "            # Line 1 -- Objname, Helio-Z, RA, Dec (Ex. SN1981D 0.005871 50.65992 -37.23272)\n",
        "            if SN.ATLASname in knownVariables.keys():\n",
        "                SN.objname = knownVariables[SN.ATLASname][0]\n",
        "            else:\n",
        "                print('No saved data for: '+str(SN.ATLASname)+', querying TNS...')\n",
        "                SN.objname = TNS_details(ra=SN.RA, dec=SN.DEC)['objname']\n",
        "            f.write(str(SN.objname)+' '+str(SN.z)+' '+str(SN.RA)+' '+str(SN.DEC)+'\\n')\n",
        "\n",
        "            # 'o'/'ATri'-filter photometry block -- Date (JD/MJD), mag, err (674.8593 12.94 0.11)\n",
        "            f.write('filter ATri\\n')\n",
        "            for i in range(len(SN.t_o)):\n",
        "                f.write(str(SN.t_o[i])+'\\t'+str(SN.mag_o[i])+'\\t'+str(SN.dmag_o[i])+'\\n')\n",
        "\n",
        "            # # 'c'/'ATgr'-filter photometry block\n",
        "            f.write('filter ATgr\\n')\n",
        "            for i in range(len(SN.t_c)):\n",
        "                f.write(str(SN.t_c[i])+'\\t'+str(SN.mag_c[i])+'\\t'+str(SN.dmag_c[i])+'\\n')\n",
        "    return ATLASnames\n",
        "\n",
        "# [4] - Fitting\n",
        "def atlas_fitting(SNe, save=True, output=True, show_plots=True, use_saved=True):\n",
        "    fit_args = {'model': 'EBV_model2', 'shape': 'st', 'bands': ['ATgr', 'ATri'], 'output': output, 'show_plots': show_plots, 'use_saved': use_saved}\n",
        "    paths = glob.glob(SNPY_DATA_ATLAS_PATH+'*')\n",
        "    params = snpy_fit(paths, plot_save=PLOTS_ROOT, model_save=SNPY_MODELS_ATLAS_PATH, **fit_args)\n",
        "\n",
        "    SNe_new = [] # mu, z, st, Tmax, EBVhost, DM\n",
        "    for SN in SNe:\n",
        "        if SN.objname in params:\n",
        "            SN.mu = params[SN.objname][0]\n",
        "            SN.z = params[SN.objname][1]\n",
        "            SN.st = params[SN.objname][2]\n",
        "            SN.Tmax = params[SN.objname][3]\n",
        "            SN.EBVhost = params[SN.objname][4]\n",
        "            SN.DM = params[SN.objname][5]\n",
        "            SNe_new.append(SN)\n",
        "        else:\n",
        "            print(SN.objname, 'is a problem child, removing...')\n",
        "\n",
        "    # Save distance mod\n",
        "    if save:\n",
        "        saved_params = np.genfromtxt(ROOT_SAVE+'ATLAS_variables.txt', delimiter=', ', dtype=str, skip_header=1)\n",
        "        with open(ROOT_SAVE+'ATLAS_variables_mu.txt', 'w') as f:\n",
        "            f.write('objname, ATLASname, RA, DEC, z, tmin, tmax, mu, st, Tmax, EBVhost, DM\\n')\n",
        "            for n in range(len(SNe_new)):\n",
        "                f.write(str(saved_params[n, 0])+', '+str(saved_params[n, 1])+', '+str(saved_params[n, 2])+', '+str(saved_params[n, 3])+', '+\n",
        "                        str(saved_params[n, 4])+', '+str(saved_params[n, 5])+', '+str(saved_params[n, 6])+', '+str(SNe_new[n].mu)+', '+\n",
        "                        str(SNe_new[n].st)+', '+str(SNe_new[n].Tmax)+', '+str(SNe_new[n].EBVhost)+', '+str(SNe_new[n].DM)+'\\n')\n",
        "    return SNe_new\n",
        "\n",
        "# [5] - Plot\n",
        "def atlas_plot_selctor(SNe, plot_type='SOLO', saveLoc=PLOTS_ATLAS_PATH, save_plot=True, show_plot=True):\n",
        "    if plot_type == 'SOLO':\n",
        "        print(\"[5] Plotting data [solo]...\")\n",
        "        with ZipFile(saveLoc+'/ATLASplots.zip', 'w') as zip_object:\n",
        "            for n in range(len(SNe)):\n",
        "                n_name = SNe[n].objname\n",
        "                atlas_solo_plot([SNe[n].t_o, SNe[n].flux_o, SNe[n].dflux_o], [SNe[n].t_c, SNe[n].flux_c, SNe[n].dflux_c],\n",
        "                                title=str(n_name)+', ['+str(round(SNe[n].RA, 4))+', '+str(round(SNe[n].DEC, 4))+']',\n",
        "                                saveLoc=saveLoc+n_name+'_ATLASplot.png', save_plot=save_plot, show_plot=show_plot)\n",
        "                zip_object.write(PLOTS_ATLAS_PATH+n_name+'_ATLASplot.png')\n",
        "                print('Plot saved to', PLOTS_ATLAS_PATH+n_name+'_ATLASplot.png')\n",
        "    elif plot_type == 'COMBINED':\n",
        "        print(\"[5] Plotting data [combined]...\")\n",
        "        fig, axs = plt.subplots(len(SNe), figsize=(12, len(SNe)*3.2))\n",
        "        fig.tight_layout(pad=5.0)\n",
        "        for n in range(len(SNe)):\n",
        "            n_name = SNe[n].objname\n",
        "            atlas_combined_plot(axs[n], [SNe[n].t_o, SNe[n].flux_o, SNe[n].dflux_o], [SNe[n].t_c, SNe[n].flux_c, SNe[n].dflux_c],\n",
        "                                title=str(n_name)+', ['+str(round(SNe[n].RA, 4))+', '+str(round(SNe[n].DEC, 4))+']')\n",
        "        if save_plot:\n",
        "            plt.savefig(saveLoc+'CombinedATLASplots.png')\n",
        "            print('Plot saved to', saveLoc+'CombinedATLASplots.png')\n",
        "        if show_plot:\n",
        "            plt.show()\n",
        "        else:\n",
        "            plt.close()\n",
        "    else:\n",
        "        print('Invalid plot type selected.')\n",
        "    return\n",
        "\n",
        "def atlas_solo_plot(data_o, data_c, title='Empty', saveLoc=PLOTS_ATLAS_PATH+'untitled.png', save_plot=True, show_plot=True):\n",
        "    plt.figure(figsize=(12, 3))\n",
        "    plt.errorbar(data_o[0], data_o[1], yerr=data_o[2], fmt='o', color='orange')\n",
        "    plt.errorbar(data_c[0], data_c[1], yerr=data_c[2], fmt='o', color='cyan')\n",
        "    plt.xlabel('Time [MJD]'); plt.ylabel('Flux [uJy]')\n",
        "    plt.title(title)\n",
        "    plt.ylim(0)\n",
        "    if save_plot:\n",
        "        plt.savefig(saveLoc)\n",
        "    if show_plot:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close()\n",
        "    return\n",
        "\n",
        "def atlas_combined_plot(ax, data_o, data_c, title='Empty'):\n",
        "    ax.errorbar(data_o[0], data_o[1], yerr=data_o[2], fmt='o', color='orange')\n",
        "    ax.errorbar(data_c[0], data_c[1], yerr=data_c[2], fmt='o', color='cyan')\n",
        "    ax.set_xlabel('Time [MJD]'); ax.set_ylabel('Flux [uJy]')\n",
        "    ax.set_title(title)\n",
        "    ax.set_ylim(0)\n",
        "    return\n",
        "\n",
        "def atlas_residuals(save_plot=True, show_plot=True):\n",
        "    dr3_data = read_DR3()\n",
        "    ATLAS_data = np.genfromtxt('/content/HiloCATsSN1991bg/saved_data/ATLAS_variables_mu.txt', dtype=str, delimiter=', ', skip_header=1)\n",
        "    ATLAS_dict = {}\n",
        "    for n in range(len(ATLAS_data[:, 0])):\n",
        "        ATLAS_dict.update({ATLAS_data[:, 0][n]: {'st': float(ATLAS_data[:, 8][n]),\n",
        "                                                 'Tmax': float(ATLAS_data[:, 9][n]),\n",
        "                                                 'EBVHost': float(ATLAS_data[:, 10][n])}})\n",
        "\n",
        "    # st_res, Tmax_res, EBV_res = [], [], []\n",
        "    # for name in ATLAS_dict:\n",
        "    #     print(name)\n",
        "    #     if name in dr3_data:\n",
        "\n",
        "    #         st_res = ATLAS_dict[name]['st'] - dr3_data[name]['st']\n",
        "    #         Tmax_res = ATLAS_dict[name]['Tmax'] - dr3_data[name]['Tmax']\n",
        "    #         EBV_res = ATLAS_dict[name]['EBVHost'] - dr3_data[name]['EBVHost']\n",
        "\n",
        "    # print(ATLAS_dict.keys())\n",
        "    # print(dr3_data.keys())\n",
        "\n",
        "    # print(dr3_data['SN2021bls'])\n",
        "\n",
        "\n",
        "    # fig, axs = plt.subplots(3, figsize=(15, 5))\n",
        "    # fig.tight_layout(pad=5.0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # print(SNe[0].st - dr3_data[SNe[0].objname])\n",
        "    # print(dr3_data[SNe[0].objname])\n",
        "\n",
        "    # for SN in SNe:\n",
        "\n",
        "\n",
        "    return\n",
        "\n",
        "## ZTF ---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# [1] - Pull\n",
        "def ztf_collection(ra, dec, jds, jde, submit=False, limit=1000):\n",
        "    print(\"Number of targets =\", len(ra))\n",
        "    ralist, declist = [], []\n",
        "    for n in range(len(ra)):\n",
        "        ralist.append(ra[n])\n",
        "        declist.append(dec[n])\n",
        "        if len(ralist) % limit == 0:\n",
        "            ralist = []\n",
        "            declist = []\n",
        "            if submit:\n",
        "                print('Submiting request to ZTF...')\n",
        "                ztf_submit_post(ralist, declist, jds, jde)\n",
        "    if submit and len(ralist) > 0:\n",
        "        print('Submiting request to ZTF...')\n",
        "        ztf_submit_post(ralist, declist, jds, jde)\n",
        "    return\n",
        "\n",
        "def ztf_submit_post(ra_list, dec_list, jds, jde):\n",
        "    email = 'mekhidw@hawaii.edu' # email you subscribed with.\n",
        "    userpass = 'wxdk286' # password that was issued to you.\n",
        "\n",
        "    ra, dec = json.dumps(ra_list), json.dumps(dec_list)\n",
        "    jdend = json.dumps(jde)\n",
        "    jdstart = json.dumps(jds)\n",
        "    payload = {'ra': ra, 'dec': dec, 'jdstart': jdstart, 'jdend': jdend, 'email': email, 'userpass': userpass}\n",
        "\n",
        "    # fixed IP address/URL where requests are submitted:\n",
        "    url = 'https://ztfweb.ipac.caltech.edu/cgi-bin/batchfp.py/submit'\n",
        "    r = requests.post(url, auth=('ztffps', 'dontgocrazy!'), data=payload)\n",
        "\n",
        "    print(ra)\n",
        "    print(dec)\n",
        "    print(jdstart)\n",
        "    print(jdend)\n",
        "    print(\"Status_code=\",r.status_code)\n",
        "    return\n",
        "\n",
        "# [2] - Process\n",
        "def ztf_processing(path='/content/HiloCATsSN1991bg/data/ZTF/batchfp_req0001745132_lc.txt',\n",
        "                   err_max= 100, zoom_tar=200, show_plots=True, save_plots=True):\n",
        "    data = np.genfromtxt(path, delimiter=' ', skip_header=54, dtype=str)\n",
        "    flux = data[:, 24].astype(float)\n",
        "    fluxerr = data[:, 25].astype(float)\n",
        "    time = data[:, 22].astype(float)\n",
        "    filter = data[:, 4]\n",
        "\n",
        "    # Get ra & dec from file\n",
        "    skip_start = 3\n",
        "    with open(path, 'r') as f:\n",
        "        for i in range(skip_start):\n",
        "            f.readline()\n",
        "        ra = float(f.readline().split(' ')[5])\n",
        "        dec = float(f.readline().split(' ')[5])\n",
        "\n",
        "    # Correct for outliers\n",
        "    invalid_values = np.array([])\n",
        "    invalid_values = np.append(invalid_values, np.where(fluxerr < 0)[0]) # Negative errors\n",
        "    invalid_values = np.append(invalid_values, np.where(fluxerr >= err_max)[0]) # Large errors\n",
        "    invalid_values = np.append(invalid_values, np.where(flux < 0)[0]) # Negative fluxes\n",
        "\n",
        "    # Commit fixes\n",
        "    invalid_values = np.unique(invalid_values.astype(int))\n",
        "    flux = np.delete(flux, invalid_values)\n",
        "    fluxerr = np.delete(fluxerr, invalid_values)\n",
        "    time = np.delete(time, invalid_values)\n",
        "    filter = np.delete(filter, invalid_values)\n",
        "\n",
        "    # Slice data around peak\n",
        "    zoom = 0\n",
        "    crop = 1000\n",
        "    while zoom < zoom_tar:\n",
        "        peak = np.where(flux == np.max(flux))[0][0]\n",
        "        time_m = time[peak-crop:peak+crop]\n",
        "        flux_m = flux[peak-crop:peak+crop]\n",
        "        fluxerr_m = fluxerr[peak-crop:peak+crop]\n",
        "        filter_m = filter[peak-crop:peak+crop]\n",
        "        zoom = np.average(flux_m)\n",
        "        if zoom < zoom_tar:\n",
        "            crop = crop -10\n",
        "\n",
        "\n",
        "    return ra, dec, time_m, flux_m, fluxerr_m, filter_m\n",
        "\n",
        "# [3] - Details\n",
        "def ztf_details(ra, dec):\n",
        "    tns_details = TNS_details(ra=ra, dec=dec)\n",
        "    return tns_details\n",
        "\n",
        "# [4] - Saving\n",
        "def ztf_write_to_ASCII(t, flux, fluxerr, filter, objname, z, ra, dec):\n",
        "    f_index = [np.where(filter=='ZTF_g')[0], np.where(filter=='ZTF_r')[0], np.where(filter=='ZTF_i')[0]]\n",
        "    # f_color = ['green', 'red', 'blue']\n",
        "    f_label = ['g', 'r', 'i']\n",
        "\n",
        "    with open(SNPY_DATA_ZTF_PATH+objname+'_snpy.txt', 'w') as f:\n",
        "        # Line 1 -- Objname, Helio-Z, RA, Dec (Ex. SN1981D 0.005871 50.65992 -37.23272)\n",
        "        f.write(str(objname)+' '+str(z)+' '+str(ra)+' '+str(dec)+'\\n')\n",
        "\n",
        "        for j in range(len(f_label)):\n",
        "            f.write('filter '+str(f_label[j])+'\\n')\n",
        "            for i in f_index[j]:\n",
        "                f.write(str(t[i])+'\\t'+str(flux[i])+'\\t'+str(fluxerr[i])+'\\n')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # # 'r'-filter photometry block\n",
        "        # f.write('filter g\\n')\n",
        "        # for i in f_index[0]:\n",
        "        #     f.write(str(t[i])+'\\t'+str(flux[i])+'\\t'+str(fluxerr[i])+'\\n')\n",
        "        # # 'i'-filter photometry block\n",
        "        # f.write('filter g\\n')\n",
        "        # for i in f_index[0]:\n",
        "        #     f.write(str(t[i])+'\\t'+str(flux[i])+'\\t'+str(fluxerr[i])+'\\n')\n",
        "    return\n",
        "\n",
        "# [5] - Fitting\n",
        "def ztf_fitting(output=False, show_plots=False, use_saved=False):\n",
        "    fit_args = {'model': 'EBV_model2', 'shape': 'st', 'bands': ['g', 'r', 'i'], 'output': output, 'show_plots': show_plots, 'use_saved': use_saved}\n",
        "    paths = glob.glob(SNPY_DATA_ZTF_PATH+'*')\n",
        "    params = snpy_fit(paths, plot_save=PLOTS_ROOT, model_save=SNPY_MODELS_ZTF_PATH, **fit_args)\n",
        "\n",
        "    return\n",
        "\n",
        "# [6] - Plot\n",
        "def ztf_plotting(t, flux, fluxerr, filter, objname, sigma=1):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    f_index = [np.where(filter=='ZTF_g')[0], np.where(filter=='ZTF_r')[0], np.where(filter=='ZTF_i')[0]]\n",
        "    f_color = ['green', 'red', 'blue']\n",
        "    f_label = ['g', 'r', 'i']\n",
        "\n",
        "    for n in range(len(f_index)):\n",
        "        plt.errorbar(t[f_index[n]], flux[f_index[n]], yerr=fluxerr[f_index[n]]*sigma, fmt='o', color=f_color[n], label=f_label[n])\n",
        "\n",
        "    # plt.axvline(t[np.where(flux == np.max(flux))[0][0]], label='Peak Light', color='black') # Peak\n",
        "    plt.xlabel('Time [JD]'); plt.ylabel('Flux [counts]')\n",
        "    plt.title(objname+'\\nSigma = '+str(sigma))\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "def ztf_residuals(t, flux, fluxerr, filter, objname):\n",
        "    dr3_data = read_DR3()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" WORKFLOWS \"\"\"\n",
        "def Burns_process():\n",
        "    # [1] Initialize Data\n",
        "    print('[1] Initializing data...')\n",
        "    burnsDistances, burnsNames = burns_init()\n",
        "\n",
        "    print('[2] Fitting Burns SNe...')\n",
        "    objname, z, mu = burns_fitting(burnsNames)\n",
        "\n",
        "    # ATLASnames = glob.glob('/content/ATLASsnpy/*')\n",
        "    # for n in range(len(ATLASnames)):\n",
        "    #     ATLASnames[n] = ATLASnames[n][21:-9]\n",
        "    # snpyDistances, snpyRedshifts, snpyParams = SNooPy2_fitting(CPSpath='/content/ATLASsnpy',\n",
        "    #                                             tarNames=ATLASnames,\n",
        "    #                                             model='EBV_model2',\n",
        "    #                                             shape='st',\n",
        "    #                                             bands=['ATgr', 'ATri'],\n",
        "    #                                             output=True,\n",
        "    #                                             snpyPlots=True)\n",
        "    # with open('/content/snpy_fit_plots/snpy_fit_params.txt', 'w') as f:\n",
        "    #     f.write('Object Name, mu, z, st, Tmax, EBVhost\\n')\n",
        "    #     for name in snpyDistances:\n",
        "    #         f.write(str(name)+', '+str(snpyDistances[name])+', '+str(snpyRedshifts[name])\n",
        "    #                 +', '+str(snpyParams[name][0])+', '+str(snpyParams[name][1])+', '+str(snpyParams[name][2])+'\\n')\n",
        "\n",
        "    # # Plot Distance v. Distance\n",
        "    # plot_DvD(snpyDistances, burnsDistances, size=(8,5), save=True)\n",
        "\n",
        "    # # Plot Residuals\n",
        "    # plot_residuals(snpyDistances, burnsDistances, snpyRedshifts, size=(8,5), save=True)\n",
        "    return\n",
        "\n",
        "def ATLAS_process():\n",
        "    # # [1] Collecting ATLAS data\n",
        "    # print('[1] Collecting ATLAS data...')\n",
        "    # atlas_collection(quiet=False, check_data=True)\n",
        "\n",
        "    # # [2] Slice data & remove outliers\n",
        "    # print('[2] Processing ATLAS data...')\n",
        "    # SNe = atlas_processing(err_max=100, n_iter = 0, use_saved=True)\n",
        "    # print('[2!] ATLAS data processed...', len(SNe), 'SN found and validated.')\n",
        "\n",
        "    # # [3] Write ATLAS data to file\n",
        "    # print('[3.1] Writing ATLAS data to file...')\n",
        "    # SNe = atlas_write_to_file(SNe, t_lim=5, quiet=False, use_saved=True)\n",
        "    # print('[3.2] Writing ATLAS ASCII files...')\n",
        "    # ATLASnames = atlas_write_ASCII(SNe, quiet=False, use_saved=True)\n",
        "\n",
        "    # # [4] SNooPy fitting\n",
        "    # print('[4] Fitting ATLAS data with SNooPy...')\n",
        "    # atlas_fitting(SNe, save=True, output=False, show_plots=False, use_saved=True)\n",
        "\n",
        "    # # [5] Plotting\n",
        "    # print('[5] Normal plotting...')\n",
        "    # atlas_plot_selctor(SNe, plot_type='COMBINED', save_plot=True, show_plot=True)\n",
        "\n",
        "    print('[5] Residual plotting...')\n",
        "    atlas_residuals(save_plot=True, show_plot=True)\n",
        "\n",
        "    return\n",
        "\n",
        "def ZTF_process():\n",
        "    # [1] Pull ZTF data\n",
        "    print('[1] Pulling ZTF data...')\n",
        "    data = np.genfromtxt(ROOT_SAVE+'ATLAS_variables_mu.txt', delimiter=', ', skip_header=1, dtype=str)\n",
        "    data_dict = {'ra': data[:, 2].astype(float), 'dec': data[:, 3].astype(float), 'jds': min(data[:, 6]), 'jde': max(data[:, 7])}\n",
        "    ztf_collection(submit=False, **data_dict)\n",
        "\n",
        "    # [2] Processing ZTF data\n",
        "    print('[2] Processing ZTF data...')\n",
        "    ra, dec, t, flux, fluxerr, filter = ztf_processing(zoom_tar=300, show_plots=True, save_plots=False)\n",
        "\n",
        "    # [3] Get details\n",
        "    print('[3] Getting details...')\n",
        "    objDetails = TNS_details(ra=ra, dec=dec)\n",
        "    print(objDetails['objname']+': z =', objDetails['redshift'], '\\t| RA =', objDetails['radeg'], '\\t| DEC =', objDetails['decdeg'])\n",
        "\n",
        "    # # [4] Write to SNooPy ASCII\n",
        "    # print('[4] Writing to ASCII for SNooPy fitting...')\n",
        "    # ztf_write_to_ASCII(t, flux, fluxerr, filter, objDetails['objname'], objDetails['redshift'], objDetails['radeg'], objDetails['decdeg'])\n",
        "\n",
        "    # # [5] Fitting\n",
        "    # print('[5] Fitting with SNooPy...')\n",
        "    # ztf_fitting()\n",
        "\n",
        "    # # [6] Plotting\n",
        "    # print('[6.1] Normal plotting...')\n",
        "    # ztf_plotting(t, flux, fluxerr, filter, objDetails['objname'], sigma=3)\n",
        "\n",
        "    print('[6.1] Residuals plotting')\n",
        "    ztf_residuals(t, flux, fluxerr, filter, objDetails['objname'])\n",
        "\n",
        "    return\n",
        "\n",
        "def test_realm():\n",
        "\n",
        "    read_DR3()\n",
        "\n",
        "    return\n"
      ],
      "metadata": {
        "id": "58PC6v_ax3c4"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" MAIN \"\"\"\n",
        "if __name__ == '__main__':\n",
        "    # NOTES\n",
        "        # Full start-up is ~15 minutes\n",
        "\n",
        "    # Runtime tracker\n",
        "    start = time.time()\n",
        "\n",
        "    # Recovering vital directories\n",
        "    recover_dir()\n",
        "\n",
        "    # Workflow select\n",
        "    # Burns_process()\n",
        "    ATLAS_process()\n",
        "    # ZTF_process()\n",
        "    # test_realm()\n",
        "\n",
        "    print('|---------------------------|\\n Run-time: ', round(time.time()-start, 4), 'seconds\\n|---------------------------|')"
      ],
      "metadata": {
        "id": "rI6R5V4-tUsZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b370884c-8b67-4097-eefb-f4855659e876"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5] Residual plotting...\n",
            "|---------------------------|\n",
            " Run-time:  0.0146 seconds\n",
            "|---------------------------|\n"
          ]
        }
      ]
    }
  ]
}