{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9cPZcWQUwULzkqrkuhrJQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mekhi-woods/HiloCATsSN1991bg/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \"\"\" DEPRICATED FUNCTIONS \"\"\"\n",
        "# def plot_91bglike_SN1a(FILTER_WHEEL = ['u', 'g', 'r', 'i', 'B', 'V0']):\n",
        "    # KrisciunasPath = \"/content/HiloCATsSN1991bg/targetLists/91bglike_justnames.txt\"\n",
        "    # KrisciunasNames = np.genfromtxt(KrisciunasPath, dtype=str, delimiter=', ')\n",
        "\n",
        "    # allCPSPhot = \"/content/HiloCATsSN1991bg/data/CSPdata/SN_photo.dat\"\n",
        "    # allCPSPhotData = np.genfromtxt(allCPSPhot, dtype='str')\n",
        "\n",
        "    # names = allCPSPhotData[:,0]\n",
        "    # filters = allCPSPhotData[:,1]\n",
        "    # time = allCPSPhotData[:,2]\n",
        "    # light = allCPSPhotData[:,3]\n",
        "    # err = allCPSPhotData[:,4]\n",
        "\n",
        "    # plt.figure(figsize=(10,6))\n",
        "    # sigma = 1\n",
        "    # for tar in KrisciunasNames:\n",
        "    #     for n in range(len(FILTER_WHEEL)):\n",
        "    #         # output_names = names[(names == tar) & (filters == FILTER_WHEEL[n])]\n",
        "    #         output_light = light[(names == tar) & (filters == FILTER_WHEEL[n])].astype('float64')\n",
        "    #         output_time = time[(names == tar) & (filters == FILTER_WHEEL[n])].astype('float64') + 53000\n",
        "    #         output_err = err[(names == tar) & (filters == FILTER_WHEEL[n])].astype('float64')\n",
        "    #         plt.errorbar(output_time, output_light, yerr=output_err*sigma, fmt='o', label=FILTER_WHEEL[n])\n",
        "\n",
        "    #     plt.title(tar); plt.xlabel('Time [MJD]'); plt.ylabel('Intensity [mag]')\n",
        "    #     plt.gca().invert_yaxis()\n",
        "    #     plt.legend()\n",
        "    #     # plt.savefig('save\\\\'+str(tar)+'.png')\n",
        "    #     plt.show()\n",
        "    #     break\n",
        "    # return\n",
        "\n",
        "# def plot_DR3_tmax_st_EBVhost():\n",
        "    # data = np.genfromtxt('/content/HiloCATsSN1991bg/DR3_fits.dat', dtype=str, skip_header=1)\n",
        "    # DR3_st = np.stack((data[:, 1].astype(float), data[:, 2].astype(float)), axis=1)\n",
        "    # DR3_Tmax = np.stack((data[:, 5].astype(float), data[:, 6].astype(float)), axis=1)\n",
        "    # DR3_EBVhost = np.stack((data[:, 25].astype(float), data[:, 26].astype(float)), axis=1)\n",
        "\n",
        "    # fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,5))\n",
        "    # fig.suptitle(\"DR3's Tmax vs. st vs EBVhost\")\n",
        "    # sigmas = [[1, 1], [1, 1], [1, 1]]\n",
        "\n",
        "    # # Tmax vs. st\n",
        "    # ax1.errorbar(DR3_Tmax[:, 0], DR3_st[:, 0],\n",
        "    #              xerr=DR3_Tmax[:, 1]*sigmas[0][0], yerr=DR3_st[:, 1]*sigmas[0][1],\n",
        "    #              fmt='yo')\n",
        "    # ax1.set_xlabel('Tmax'); ax1.set_ylabel('st')\n",
        "    # ax1.set_title('Tmax vs. st, sigma(x='+str(sigmas[0][0])+', y='+str(sigmas[0][1])+')')\n",
        "\n",
        "    # # st vs. EBVhost\n",
        "    # ax2.errorbar(DR3_st[:, 0], DR3_EBVhost[:, 0],\n",
        "    #              xerr=DR3_st[:, 1]*sigmas[1][0], yerr=DR3_EBVhost[:, 1]*sigmas[1][1],\n",
        "    #              fmt='bo')\n",
        "    # ax2.set_xlabel('st'); ax2.set_ylabel('EBVhost')\n",
        "    # ax2.set_title('st vs. EBVhost, sigma(x='+str(sigmas[1][0])+', y='+str(sigmas[1][1])+')')\n",
        "\n",
        "    # # Tmax vs. EBVhost\n",
        "    # ax3.errorbar(DR3_Tmax[:, 0], DR3_EBVhost[:, 0],\n",
        "    #              xerr=DR3_Tmax[:, 1]*sigmas[2][0], yerr=DR3_EBVhost[:, 1]*sigmas[2][1],\n",
        "    #              fmt='ro')\n",
        "    # ax3.set_xlabel('Tmax'); ax3.set_ylabel('EBVhost')\n",
        "    # ax3.set_title('Tmax vs. EBVhost, sigma(x='+str(sigmas[2][0])+', y='+str(sigmas[2][1])+')')\n",
        "\n",
        "    # plt.show()\n",
        "    # return\n",
        "\n"
      ],
      "metadata": {
        "id": "ctmVmhAwsg7d"
      },
      "execution_count": 447,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \"\"\" START UP \"\"\"\n",
        "# import os\n",
        "# import shutil\n",
        "# if os.path.exists('/content/HiloCATsSN1991bg') == True:\n",
        "#     shutil.rmtree('/content/HiloCATsSN1991bg')\n",
        "#     !git clone https://github.com/mekhi-woods/HiloCATsSN1991bg.git\n",
        "# else:\n",
        "#     !git clone https://github.com/mekhi-woods/HiloCATsSN1991bg.git\n",
        "\n",
        "# !pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple snpy\n",
        "# !pip install requests\n",
        "# !pip install ztffp\n"
      ],
      "metadata": {
        "id": "gTAo57hVjmTa"
      },
      "execution_count": 448,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" IMPORTS \"\"\"\n",
        "import os\n",
        "import time\n",
        "import glob\n",
        "import snpy\n",
        "import ztffp\n",
        "import shutil\n",
        "import requests\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import matplotlib.pyplot as plt\n",
        "from zipfile import ZipFile\n",
        "from requests.auth import HTTPBasicAuth\n",
        "from HiloCATsSN1991bg.scripts import tns_redshifts"
      ],
      "metadata": {
        "id": "bg3Q3CWYsvzj"
      },
      "execution_count": 449,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" GLOBALS \"\"\"\n",
        "# Paths\n",
        "ROOT_SAVE = '/content/HiloCATsSN1991bg/saved_data/'\n",
        "MODELS_PATH = ROOT_SAVE+'models/'\n",
        "PLOTS_PATH = ROOT_SAVE+'plots/'\n",
        "DATA_PATH = ROOT_SAVE+'data/'\n",
        "ATLAS_PLOTS_PATH = PLOTS_PATH+'atlas/'\n",
        "ATLAS_SNPY_PLOTS_PATH = PLOTS_PATH+'atlas_snpy/'\n",
        "ATLAS_DATA_PATH = DATA_PATH+'atlas/'\n",
        "ATLAS_SNPY_DATA_PATH = DATA_PATH+'atlas_snpy/'\n",
        "ZTF_DATA_PATH = DATA_PATH+'ztf/'\n",
        "\n",
        "API_TOKEN = \"7f4e1dee8f52cf0c8cdaf55bf29d04bef4810fb4\"\n",
        "USE_PAST_CALC = True # Uses past calculations to speed up code\n",
        "USE_SAVED = False\n",
        "\n",
        "# Credintials\n",
        "tns_bot_id = '73181'\n",
        "tns_bot_name = 'YSE_Bot1'\n",
        "tns_bot_api_key = '0d771345fa6b876a5bb99cd5042ab8b5ae91fc67'\n",
        "ztf_email_address=\"mekhidw@hawaii.edu\"\n",
        "ztf_email_password=\"\"\n",
        "ztf_email_imapserver=\"imap.gmail.com\"\n",
        "ztf_user_password=\"wxdk286\"\n",
        "!export ztf_email_address\n",
        "!export ztf_email_password\n",
        "!export ztf_email_imapserver\n",
        "!export ztf_user_password"
      ],
      "metadata": {
        "id": "WbQz8fC_uhH6"
      },
      "execution_count": 450,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "MMHm15bbeovH"
      },
      "execution_count": 450,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" CLASSES \"\"\"\n",
        "class ATLAS_SN():\n",
        "    def __init__(self, ATLASname='EmptySN', objname='SN####abc', RA=0.00000000000, DEC=0.00000000000, z=0.00000000000,\n",
        "                 DM=0.00, st=0.00, EBVhost=0.00, Tmax=0.00, mu=0.00,\n",
        "                 t_o=np.array([0]), flux_o=np.array([0]), dflux_o=np.array([0]), mag_o=np.array([0]), dmag_o=np.array([0]),\n",
        "                 t_c=np.array([0]), flux_c=np.array([0]), dflux_c=np.array([0]), mag_c=np.array([0]), dmag_c=np.array([0])):\n",
        "        self.ATLASname=ATLASname\n",
        "        self.objname=objname\n",
        "        self.RA=RA\n",
        "        self.DEC=DEC\n",
        "        self.z=z\n",
        "\n",
        "        self.t_o=t_o\n",
        "        self.flux_o=flux_o\n",
        "        self.dflux_o=dflux_o\n",
        "        self.mag_o=mag_o\n",
        "        self.dmag_o=dmag_o\n",
        "\n",
        "        self.t_c=t_c\n",
        "        self.flux_c=flux_c\n",
        "        self.dflux_c=dflux_c\n",
        "        self.mag_c=mag_c\n",
        "        self.dmag_c=dmag_c\n",
        "\n",
        "        self.mu = mu\n",
        "        self.DM = DM\n",
        "        self.st = st\n",
        "        self.EBVhost = EBVhost\n",
        "        self.Tmax = Tmax\n",
        "        return\n",
        "\n",
        "    def __str__(self):\n",
        "        return (self.objname+' : '+self.ATLASname+' @ ('+str(self.RA)+', '+str(self.DEC)+')\\n'+\n",
        "                'O-Filter:'+\n",
        "                '\\t t [MJD]: '+str(np.min(self.t_o))+'...'+str(np.max(self.t_o))+'\\n'+\n",
        "                '\\t\\t flux [uJy]: '+str(np.min(self.flux_o))+'...'+str(np.max(self.flux_o))+'\\n'+\n",
        "                '\\t\\t dflux [duJy]: '+str(np.min(self.dflux_o))+'...'+str(np.max(self.dflux_o))+'\\n'+\n",
        "                '\\t\\t mag: '+str(np.min(self.mag_o))+'...'+str(np.max(self.mag_o))+'\\n'+\n",
        "                '\\t\\t dmag: '+str(np.min(self.dmag_o))+'...'+str(np.max(self.dmag_o))+'\\n'+\n",
        "                'C-Filter:'+\n",
        "                '\\t t [MJD]: '+str(np.min(self.t_c))+'...'+str(np.max(self.t_c))+'\\n'+\n",
        "                '\\t\\t flux [uJy]: '+str(np.min(self.flux_c))+'...'+str(np.max(self.flux_c))+'\\n'+\n",
        "                '\\t\\t dflux [duJy]: '+str(np.min(self.dflux_c))+'...'+str(np.max(self.dflux_c))+'\\n'\n",
        "                '\\t\\t mag: '+str(np.min(self.mag_c))+'...'+str(np.max(self.mag_c))+'\\n'+\n",
        "                '\\t\\t dmag: '+str(np.min(self.dmag_c))+'...'+str(np.max(self.dmag_c))+'\\n'+\n",
        "                'Params:'+\n",
        "                '\\t Distance Mod [mu]: '+str(self.mu)+'\\n'+\n",
        "                '\\t\\t DM: '+str(self.DM)+'\\n'+\n",
        "                '\\t\\t Shape [st]: '+str(self.st)+'\\n'\n",
        "                '\\t\\t EBVhost: '+str(self.EBVhost)+'\\n'+\n",
        "                '\\t\\t Peak Time [Tmax]: '+str(self.Tmax)+'\\n')\n",
        "\n",
        "    def coords(self):\n",
        "        return('('+str(self.RA)+', '+str(self.DEC)+')')\n",
        "\n",
        "    def flux_to_mag(self):\n",
        "        return [[-2.5*np.log10(self.flux_o) + 23.9, 1.0857*self.dflux_o/self.flux_o],\n",
        "                [-2.5*np.log10(self.flux_c) + 23.9, 1.0857*self.dflux_c/self.flux_c]]\n"
      ],
      "metadata": {
        "id": "mxQPN393v8Qi"
      },
      "execution_count": 451,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 452,
      "metadata": {
        "id": "3ExsdUj9XTCi"
      },
      "outputs": [],
      "source": [
        "\"\"\" FUNCTIONS \"\"\"\n",
        "# General functions\n",
        "def recover_dir():\n",
        "    if os.path.exists(ROOT_SAVE) == False:\n",
        "        os.mkdir(ROOT_SAVE)\n",
        "    if os.path.exists(MODELS_PATH) == False:\n",
        "        os.mkdir(MODELS_PATH)\n",
        "    if os.path.exists(PLOTS_PATH) == False:\n",
        "        os.mkdir(PLOTS_PATH)\n",
        "    if os.path.exists(DATA_PATH) == False:\n",
        "        os.mkdir(DATA_PATH)\n",
        "    if os.path.exists(ATLAS_PLOTS_PATH) == False:\n",
        "        os.mkdir(ATLAS_PLOTS_PATH)\n",
        "    if os.path.exists(ATLAS_SNPY_PLOTS_PATH) == False:\n",
        "        os.mkdir(ATLAS_SNPY_PLOTS_PATH)\n",
        "    if os.path.exists(ATLAS_DATA_PATH) == False:\n",
        "        os.mkdir(ATLAS_DATA_PATH)\n",
        "    if os.path.exists(ATLAS_SNPY_DATA_PATH) == False:\n",
        "        os.mkdir(ATLAS_SNPY_DATA_PATH)\n",
        "    if os.path.exists(ZTF_DATA_PATH) == False:\n",
        "        os.mkdir(ZTF_DATA_PATH)\n",
        "    if os.path.exists(ATLAS_SNPY_PLOTS_PATH+'/snpyplots.zip'):\n",
        "        os.remove(ATLAS_SNPY_PLOTS_PATH+'/snpyplots.zip')\n",
        "    return\n",
        "\n",
        "def TNS_details(ra, dec):\n",
        "    # Code from David\n",
        "\n",
        "    headers = tns_redshifts.build_tns_header(tns_bot_id, tns_bot_name)\n",
        "    tns_api_url = f\"https://www.wis-tns.org/api/get\"\n",
        "\n",
        "    # get the API URLs\n",
        "    search_tns_url = tns_redshifts.build_tns_url(tns_api_url, mode=\"search\")\n",
        "    get_tns_url = tns_redshifts.build_tns_url(tns_api_url, mode=\"get\")\n",
        "\n",
        "    search_data = tns_redshifts.build_tns_search_query_data(tns_bot_api_key, ra, dec)\n",
        "    transients = tns_redshifts.rate_limit_query_tns(search_data, headers, search_tns_url)\n",
        "\n",
        "    get_data = tns_redshifts.build_tns_get_query_data(tns_bot_api_key, transients[0])\n",
        "    transient_detail = tns_redshifts.rate_limit_query_tns(get_data, headers, get_tns_url)\n",
        "\n",
        "    return transient_detail\n",
        "\n",
        "# Fitting functions\n",
        "def snpy_fit(filePath, model='max_model', shapeParam='dm15', BandsToFit = ['B','g','r','i'], summarize=True, saveplots=False, saveLoc=ATLAS_SNPY_PLOTS_PATH, show_plots=True):\n",
        "    s = snpy.get_sn(filePath)\n",
        "\n",
        "    # Set model parameters\n",
        "    s.choose_model(model, stype=shapeParam)\n",
        "    s.set_restbands() # Auto pick appropriate rest-bands\n",
        "\n",
        "    # Fit data -- using David configurations\n",
        "    fitargs = {'mangle':1,'calibration':0, 'quiet':False} # I don't remember what calibration is\n",
        "    s.fit(BandsToFit,\n",
        "          dokcorr=True,\n",
        "          k_stretch=False,\n",
        "          reset_kcorrs=True,\n",
        "          **fitargs)\n",
        "\n",
        "    # Show results\n",
        "    if summarize:\n",
        "        s.summary()\n",
        "        # for param in s.parameters:\n",
        "        #     print(\"{} = {} +/- {}\".format(param, s.parameters[param], s.errors[param]))\n",
        "    if saveplots:\n",
        "        print('Plot saved to', ATLAS_SNPY_PLOTS_PATH+filePath[-17:-9]+'_snpyplots.png')\n",
        "        s.plot(outfile=ATLAS_SNPY_PLOTS_PATH+filePath[-17:-9]+'_snpyplots.png')\n",
        "        if show_plots:\n",
        "            plt.show()\n",
        "        else:\n",
        "            plt.close()\n",
        "\n",
        "        with ZipFile(ATLAS_SNPY_PLOTS_PATH+'snpyplots.zip', 'a') as zip_object:\n",
        "            zip_object.write(ATLAS_SNPY_PLOTS_PATH+filePath[-17:-9]+'_snpyplots.png')\n",
        "\n",
        "    return s\n",
        "\n",
        "def SNooPy2_fitting(dataPath, tarNames, model='EBV_model2', shape='st', bands=['B','g','r','i'], output=False, snpyPlots=False, show_plots=True):\n",
        "    problemChildren = []\n",
        "\n",
        "    if len(bands) == 0:\n",
        "        bands = None\n",
        "\n",
        "    tarPaths = []\n",
        "    for tar in tarNames:\n",
        "        tarPaths.append(dataPath+str(tar))\n",
        "\n",
        "    SNe_mu = {}\n",
        "    SNe_z = {}\n",
        "    SNe_params = {}\n",
        "\n",
        "    for i in range(len(tarPaths)):\n",
        "        tarName = tarNames[i][:-9]\n",
        "        tarSave = MODELS_PATH+tarName+'_'+model+'.snpy'\n",
        "        print('[ '+str(i+1)+' / '+str(len(tarPaths))+'] Fiting data for '+tarName+'...')\n",
        "\n",
        "        # Create/Retrieve Fit\n",
        "        valid = True\n",
        "\n",
        "        if os.path.exists(tarSave) and USE_SAVED:\n",
        "            print(tarName, 'found in files! Pulling data...')\n",
        "            s_n = snpy.get_sn(tarSave)\n",
        "        elif os.path.exists(tarPaths[i]):\n",
        "            try:\n",
        "                s_n = snpy_fit(tarPaths[i],\n",
        "                                model=model,\n",
        "                                shapeParam=shape,\n",
        "                                BandsToFit=None,\n",
        "                                summarize=output,\n",
        "                                saveplots=snpyPlots,\n",
        "                                saveLoc=ATLAS_SNPY_PLOTS_PATH,\n",
        "                                show_plots=show_plots) # Enter snpy fit function\n",
        "            except ValueError:\n",
        "                problemChildren.append(tarName)\n",
        "                print('[!!!] ValueError: No data near maximum light... skipping\\n')\n",
        "                valid = False\n",
        "            except RuntimeError:\n",
        "                problemChildren.append(tarName)\n",
        "                print('[!!!] RuntimeError: Model has trailed off fitting filter... skipping\\n')\n",
        "                valid = False\n",
        "            except TypeError:\n",
        "                problemChildren.append(tarName)\n",
        "                print('[!!!] TypeError: m > k must hold (I have no clue what this means)... skipping\\n')\n",
        "                valid = False\n",
        "            except:\n",
        "                problemChildren.append(tarName)\n",
        "                print('[!!!] Unknown Error... skipping\\n')\n",
        "                valid = False\n",
        "        else:\n",
        "            print(tarName, 'does not exsist in CSP data... skipping')\n",
        "            valid = False\n",
        "\n",
        "        if valid:\n",
        "            # Save model\n",
        "            s_n.save(tarSave)\n",
        "\n",
        "            # Pull SNooPY distance\n",
        "            snpy_mu = s_n.get_distmod() # Nab paramaters from SNe objects)\n",
        "\n",
        "            # Update dictionary/list\n",
        "            SNe_mu.update({tarName: snpy_mu})\n",
        "            SNe_z.update({tarName: s_n.z})\n",
        "            SNe_params.update({tarName: [s_n.st, s_n.Tmax, s_n.EBVhost, s_n.DM]})\n",
        "\n",
        "            # Print info\n",
        "            print('Redshift:\\t z = '+str(s_n.z))\n",
        "            print('Distance: \\t mu = '+str(round(snpy_mu, 4))+'\\n')\n",
        "\n",
        "    print('Problem children:\\n', '[', len(problemChildren), ']', problemChildren)\n",
        "    plt.close()\n",
        "    return SNe_mu, SNe_z, SNe_params\n",
        "\n",
        "def ATLAS_snpy_fitting(SNe, ATLASnames, show_plot=True):\n",
        "    SNe_mu, SNe_z, SNe_params = SNooPy2_fitting(ATLAS_SNPY_DATA_PATH, ATLASnames, model='EBV_model2', shape='st', bands=['ATri', 'ATgr'], output=True, snpyPlots=True, show_plots=show_plot)\n",
        "    SNe_new = []\n",
        "    for SN in SNe:\n",
        "        try:\n",
        "            SN.mu = SNe_mu[SN.objname]\n",
        "            SN.z = SNe_z[SN.objname]\n",
        "            SN.st = SNe_params[SN.objname][0]\n",
        "            SN.Tmax = SNe_params[SN.objname][1]\n",
        "            SN.EBVhost = SNe_params[SN.objname][2]\n",
        "            SN.DM = SNe_params[SN.objname][3]\n",
        "            SNe_new.append(SN)\n",
        "        except KeyError:\n",
        "            print(SN.objname, 'is a problem child, removing...')\n",
        "\n",
        "    return SNe_new\n",
        "\n",
        "# Plotting functions\n",
        "def plot_SNooPy_mu_vs_z(save_plot=True, saveLoc=ATLAS_SNPY_PLOTS_PATH):\n",
        "    data = np.genfromtxt(ROOT_SAVE+'ATLAS_variables.txt', delimiter=', ', dtype=str, skip_header=1)\n",
        "    name, mu, z = data[:, 0], data[:, 1].astype(float), data[:, 2].astype(float)\n",
        "\n",
        "    for n in range(len(name)):\n",
        "        plt.loglog(z[n], mu[n], 'o')\n",
        "        if z[n] < 0.0125:\n",
        "            plt.text(z[n], mu[n], name[n], fontsize='xx-small')\n",
        "    plt.xlabel('Redshift [z]'); plt.ylabel('Distance Modulus [mu]')\n",
        "    plt.title('ATLAS SNe -- Fitted with SNooPy \\nDistance Modulus v. Redshift')\n",
        "    if save_plot:\n",
        "        plt.savefig(saveLoc+'SNooPy_mu_vs_z.png')\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "def plot_SNooPy_hist(binNum=10, save_plot=True, saveLoc=ATLAS_SNPY_PLOTS_PATH):\n",
        "    data = np.genfromtxt(ROOT_SAVE+'ATLAS_variables.txt', delimiter=', ', dtype=str, skip_header=1)\n",
        "    paramsData = [data[:, 3].astype(float), data[:, 4].astype(float), data[:, 5].astype(float)]\n",
        "    paramsNames = ['st', 'ATLAS SNooPy Fitting Parameters \\n Tmax', 'EBVhost']\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    for n in range(len(paramsNames)):\n",
        "        axes[n].hist(paramsData[n], bins=binNum)\n",
        "        axes[n].set_title(paramsNames[n])\n",
        "    if save_plot:\n",
        "        plt.savefig(saveLoc+'SNooPy_params_hist.png')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    return\n",
        "\n",
        "def plot_DvD(snpyDistances, burnsDistances, size=(8,5), save=False):\n",
        "    print(\"Ploting differences in distance calculations...\")\n",
        "    plt.figure(figsize=size)\n",
        "    for x in snpyDistances:\n",
        "        try:\n",
        "            plt.scatter(burnsDistances[x], snpyDistances[x], marker='o')\n",
        "            plt.text(burnsDistances[x]+0.05, snpyDistances[x]-0.05, x, fontsize='xx-small')\n",
        "            print('Burns Distance:', burnsDistances[x], '| SNooPy Distance:', snpyDistances[x])\n",
        "        except KeyError:\n",
        "            print(x, 'not found.')\n",
        "            pass\n",
        "    plt.title(\"Burns v. SNooPy Distance\")\n",
        "    plt.xlabel('Burns Distance'); plt.ylabel('SNooPy Distance')\n",
        "    plt.xlim(min(burnsDistances.values()), max(burnsDistances.values()))\n",
        "    plt.ylim(min(burnsDistances.values()), max(burnsDistances.values()))\n",
        "\n",
        "    if save:\n",
        "        plt.savefig('burns_v_snpy_dist.png')\n",
        "\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "def plot_residuals(snpyDistances, burnsDistances, snpyRedshifts, size=(8,5), save=False):\n",
        "    print(\"Ploting residuals...\")\n",
        "    plt.figure(figsize=size)\n",
        "    for x in snpyDistances:\n",
        "        try:\n",
        "            plt.scatter(snpyRedshifts[x], abs(burnsDistances[x]-snpyDistances[x]), marker='o')\n",
        "            plt.text(snpyRedshifts[x], abs(burnsDistances[x]-snpyDistances[x]), x, fontsize='xx-small')\n",
        "            print('Redshift:', snpyRedshifts[x], '| Burns-SNooPy Distance:', burnsDistances[x]-snpyDistances[x])\n",
        "        except KeyError:\n",
        "            print(x, 'not found.')\n",
        "            pass\n",
        "    plt.title(\"Burns-SNooPy Residuals\"); plt.xlabel('Redshift'); plt.ylabel('Burns-SNooPy')\n",
        "    if save:\n",
        "        plt.savefig('burns-snpy_res.png')\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "def solo_plotting(t_o, t_c, flux_o, flux_c, flux_err_o, flux_err_c, err_max, name='Empty', coords=[0, 0], size=(12, 4), save=False, saveLoc=ATLAS_PLOTS_PATH, show_plot=True):\n",
        "    plt.figure(figsize=size)\n",
        "\n",
        "    plt.errorbar(t_o, flux_o, yerr=flux_err_o, fmt='o', color='orange')\n",
        "    plt.errorbar(t_c, flux_c, yerr=flux_err_c, fmt='o', color='cyan')\n",
        "\n",
        "    plt.title('Light Curve: '+str(name)+'\\n'+str(coords[0])+', '+str(coords[1])+'\\nMax Error = '+str(err_max))\n",
        "    plt.xlabel('Time [MJD]')\n",
        "    plt.ylabel('Flux [uJy]')\n",
        "    plt.ylim(0)\n",
        "    plt.savefig(saveLoc+name+'_ATLASplot.png')\n",
        "    if show_plot:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close()\n",
        "    return\n",
        "\n",
        "def combined_plotting(ax, t_o, t_c, flux_o, flux_c, flux_err_o, flux_err_c, name='Empty', coords=[0, 0]):\n",
        "    ax.errorbar(t_o, flux_o, yerr=flux_err_o, fmt='o', color='orange')\n",
        "    ax.errorbar(t_c, flux_c, yerr=flux_err_c, fmt='o', color='cyan')\n",
        "\n",
        "    ax.set_title('Light Curve: '+str(name)+'\\n'+str(coords[0])+', '+str(coords[1]))\n",
        "    ax.set_xlabel('Time [MJD]')\n",
        "    ax.set_ylabel('Flux [uJy]')\n",
        "    ax.set_ylim(0)\n",
        "    return\n",
        "\n",
        "def plot_ATLAS(xyo, xyc, ax=plt, name='Empty', coords=[0, 0], save=False, saveloc=ATLAS_PLOTS_PATH):\n",
        "    ax.errorbar(xyo[0], xyo[1], yerr=xyo[2], fmt='o', color='orange')\n",
        "    ax.errorbar(xyc[0], xyc[1], yerr=xyc[2], fmt='o', color='cyan')\n",
        "\n",
        "    ax.set_title('Light Curve: '+str(name)+'\\n'+str(coords[0])+', '+str(coords[1]))\n",
        "    ax.set_xlabel('Time [MJD]'); ax.set_ylabel('Flux [uJy]')\n",
        "    if save:\n",
        "        plt.savefig(saveloc+name+'_ATLASplot.png')\n",
        "    return\n",
        "\n",
        "# Specific functions\n",
        "def snpy_ASCII_formatting(SNe):\n",
        "    knownVariables = {}\n",
        "    skip_header = True\n",
        "    with open(ROOT_SAVE+'ATLAS_variables.txt', 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            if skip_header:\n",
        "                skip_header = False\n",
        "                pass\n",
        "            else:\n",
        "                line = line[:-1].split(', ')\n",
        "                name = line[1]\n",
        "                line.remove(name)\n",
        "                knownVariables.update({name : line})\n",
        "\n",
        "    ATLASnames = []\n",
        "    for SN in SNe:\n",
        "        ATLASnames.append(str(SN.objname)+'_snpy.txt')\n",
        "        with open(ATLAS_SNPY_DATA_PATH+str(SN.objname)+'_snpy.txt', 'w') as f:\n",
        "            # Line 1\n",
        "            # Ex. SN1981D 0.005871 50.65992 -37.23272\n",
        "            #     Name    Helio Z  RA        Dec\n",
        "            try:\n",
        "                SN.objname = knownVariables[SN.ATLASname][0]\n",
        "            except KeyError:\n",
        "                print('No saved data for...', SN.ATLASname)\n",
        "            f.write(str(SN.objname)+' '+str(SN.z)+' '+str(SN.RA)+' '+str(SN.DEC)+'\\n')\n",
        "            print(str(SN.objname)+' '+str(SN.z)+' '+str(SN.RA)+' '+str(SN.DEC))\n",
        "\n",
        "            # 'ATri'-filter photometry block\n",
        "            # Ex. filter O\n",
        "            #     674.8593      12.94   0.11\n",
        "            #     Date (JD/MJD) mag     err\n",
        "            f.write('filter ATri\\n')\n",
        "            for i in range(len(SN.t_o)):\n",
        "                f.write(str(SN.t_o[i])+'\\t'+str(SN.mag_o[i])+'\\t'+str(SN.dmag_o[i])+'\\n')\n",
        "\n",
        "            # # 'ATgr'-filter photometry block\n",
        "            f.write('filter ATgr\\n')\n",
        "            for i in range(len(SN.t_c)):\n",
        "                f.write(str(SN.t_c[i])+'\\t'+str(SN.mag_c[i])+'\\t'+str(SN.dmag_c[i])+'\\n')\n",
        "    return ATLASnames\n",
        "\n",
        "def data_collection(quiet=False):\n",
        "        if os.path.exists(ROOT_SAVE+'tmp.npz'):\n",
        "            pickle = np.load(ROOT_SAVE+'tmp.npz', allow_pickle=True)\n",
        "            data = pickle['data']\n",
        "\n",
        "        data = requests.post(\n",
        "            'https://star.pst.qub.ac.uk/sne/atlas4/api/objectlist/',\n",
        "            headers={'Authorization': f'Token {API_TOKEN}'},\n",
        "            data={'objectlistid':2}\n",
        "        ).json()\n",
        "\n",
        "        np.savez(ROOT_SAVE+'tmp.npz', data=data)\n",
        "\n",
        "        count = 0\n",
        "        for d in data:\n",
        "            if d['observation_status'] is not None and d['observation_status'].startswith('SN Ia') and '91bg' in d['observation_status']:\n",
        "                count += 1\n",
        "                if not quiet:\n",
        "                    print(d['atlas_designation'],d['observation_status'].replace(' ',''),d['ra'],d['dec'])\n",
        "\n",
        "\n",
        "                ids = d['id']\n",
        "                base_url = 'https://star.pst.qub.ac.uk/sne/atlas4/lightcurveforced/1161048951013729300/'\n",
        "                new_url = base_url.replace('1161048951013729300/',str(ids))\n",
        "                if not quiet:\n",
        "                    print(new_url)\n",
        "\n",
        "                idfile = ATLAS_DATA_PATH+'/' + str(ids)+'.txt'\n",
        "                if os.path.exists(idfile):\n",
        "                    continue\n",
        "                urllib.request.urlretrieve(str(new_url), str(idfile))\n",
        "                if not quiet:\n",
        "                    print(idfile)\n",
        "\n",
        "            if count > 300:\n",
        "                break\n",
        "\n",
        "def slice_data(path, err_max=100):\n",
        "    name = path[48:-4]\n",
        "    data = np.genfromtxt(path, dtype=str, delimiter=',')\n",
        "\n",
        "    if len(data) == 0:\n",
        "        print('[!!!] File '+name+' empty...skipping')\n",
        "        return None\n",
        "\n",
        "    filters = data[:, 6]\n",
        "    t = data[:, 8].astype(float)\n",
        "    flux = data[:, 24]\n",
        "    dflux = data[:, 25]\n",
        "    mag = np.char.replace(data[:, 3], '>', '') # Removes greater than symbols\n",
        "    dmag = data[:, 4]\n",
        "\n",
        "    # Finds the empty spots of flux and mag and records the element\n",
        "    mod_empty = np.unique(np.hstack((np.hstack((np.where(flux == 'None')[0], np.where(dflux == 'None')[0])),\n",
        "                                     np.hstack((np.where(mag == 'None')[0], np.where(dmag == 'None')[0])))))\n",
        "    filters = np.delete(filters, mod_empty)\n",
        "    t = np.delete(t, mod_empty).astype(float)\n",
        "    flux = np.delete(flux, mod_empty).astype(float)\n",
        "    dflux = np.delete(dflux, mod_empty).astype(float)\n",
        "    mag = np.delete(mag, mod_empty).astype(float)\n",
        "    dmag = np.delete(dmag, mod_empty).astype(float)\n",
        "\n",
        "    # Finds negative fluxes\n",
        "    mod_positive = np.unique(np.hstack((np.hstack((np.where(flux <= 0)[0], np.where(dflux <= 0)[0])),\n",
        "                                np.hstack((np.where(mag <= 0)[0], np.where(dmag <= 0)[0])))))\n",
        "    filters = np.delete(filters, mod_positive)\n",
        "    t = np.delete(t, mod_positive)\n",
        "    flux = np.delete(flux, mod_positive)\n",
        "    dflux = np.delete(dflux, mod_positive)\n",
        "    mag = np.delete(mag, mod_positive)\n",
        "    dmag = np.delete(dmag, mod_positive)\n",
        "\n",
        "    # Find outliers beyond error limit\n",
        "    mod_err = np.unique(np.hstack(((np.where(abs(dflux) > err_max)[0]), np.where(abs(dmag) > err_max)[0]))) # Negatives fluxes & Error Limit\n",
        "    filters = np.delete(filters, mod_err)\n",
        "    t = np.delete(t, mod_err)\n",
        "    flux = np.delete(flux, mod_err)\n",
        "    dflux = np.delete(dflux, mod_err)\n",
        "    mag = np.delete(mag, mod_err)\n",
        "    dmag = np.delete(dmag, mod_err)\n",
        "\n",
        "    tempSN = ATLAS_SN(ATLASname=name, RA=np.average(data[:, 1].astype(float)), DEC=np.average(data[:, 2].astype(float)),\n",
        "                        t_o=t[np.where(filters=='o')[0]], flux_o=flux[np.where(filters=='o')[0]], dflux_o=dflux[np.where(filters=='o')[0]], mag_o=mag[np.where(filters=='o')[0]], dmag_o=dmag[np.where(filters=='o')[0]],\n",
        "                        t_c=t[np.where(filters=='c')[0]], flux_c=flux[np.where(filters=='c')[0]], dflux_c=dflux[np.where(filters=='c')[0]], mag_c=mag[np.where(filters=='c')[0]], dmag_c=dmag[np.where(filters=='c')[0]])\n",
        "\n",
        "    return tempSN\n",
        "\n",
        "def TNS_obj_detection(SNe, t_lim=0.1, saveLoc=ROOT_SAVE+'ATLAS_variables.txt', use_saved=True):\n",
        "    # Check for presaved data\n",
        "    savedData = {}\n",
        "    if use_saved:\n",
        "        data = np.genfromtxt(saveLoc, delimiter=', ', dtype=str, skip_header=1)\n",
        "        if len(data) > 0:\n",
        "            for n in range(len(data[:, 0])):\n",
        "                savedData.update({data[n][1]: [data[n][0], data[n][4]]})\n",
        "\n",
        "    with open(saveLoc, 'w') as f:\n",
        "        f.write('objname, ATLASname, RA, DEC, z\\n') # Header\n",
        "        for n in range(len(SNe)):\n",
        "            if SNe[n].ATLASname in savedData:\n",
        "                obj = {'objname' : savedData[SNe[n].ATLASname][0], 'redshift' : savedData[SNe[n].ATLASname][1]}\n",
        "                SNe[n].objname = obj['objname']\n",
        "                SNe[n].z = obj['redshift']\n",
        "                print(\"Saved object data found for \"+SNe[n].ATLASname+\", retrieving...\")\n",
        "            else:\n",
        "                print(\"No saved data, sleeping for\", t_lim, 'seconds...')\n",
        "                time.sleep(t_lim)\n",
        "                obj = TNS_details(ra=SNe[n].RA, dec=SNe[n].DEC)\n",
        "                SNe[n].objname = 'SN'+obj['objname']\n",
        "                SNe[n].z = obj['redshift']\n",
        "\n",
        "\n",
        "\n",
        "            print('[ '+str(n+1)+' / '+str(len(SNe))+' ]', SNe[n].ATLASname+':', SNe[n].objname, '| z =', SNe[n].z, '\\n')\n",
        "            f.write(str(SNe[n].objname)+', '+str(SNe[n].ATLASname)+', '+str(SNe[n].RA)+', '+str(SNe[n].DEC)+', '+str(SNe[n].z)+'\\n')\n",
        "\n",
        "    return\n",
        "\n",
        "# Main processing functions\n",
        "def ATLAS_main_processing(err_max=100, yaxis='flux', t_lim = 0.1, n_iter = 0, plot_mode = 'SOLO', show_plot=True):\n",
        "    # [2.1] Aquire Data\n",
        "    print('[2.1] Retrieving data from...', ATLAS_DATA_PATH)\n",
        "    files = glob.glob(ATLAS_DATA_PATH+'/*')\n",
        "    problemChildren = ['1032212120425304400']   # Running list of problematic SNe\n",
        "                                                # '1032212120425304400' - David believes it might be a shock breakout but ATLAS reports it as SN1a\n",
        "                                                #\n",
        "    # [2.2] Validate Data\n",
        "    print('[2.2] Sorting data...')\n",
        "    SNe = []\n",
        "    for n in range(len(files)):\n",
        "        print('[', n+1, '/', len(files), '] Validating data for...', files[n][48:-4])\n",
        "        result = slice_data(path=files[n], err_max=err_max)\n",
        "        if result != None:\n",
        "            SNe.append(result)\n",
        "        else:\n",
        "            problemChildren.append(files[n][48:-4])\n",
        "        if n_iter != 0 and n+1 >= n_iter:\n",
        "            break\n",
        "\n",
        "    # [2.3] Remove problem children\n",
        "    print('[2.3] Problem Children: ', problemChildren)\n",
        "    for SN in SNe:\n",
        "        for probname in problemChildren:\n",
        "            if SN.ATLASname == probname:\n",
        "                print('Removing...', SN.ATLASname)\n",
        "\n",
        "    # [2.4] Save RA, DEC, Redshift, and Object Name\n",
        "    print('[2.4] Saving parameters to file...')\n",
        "    print(t_lim, 'second pause between entries...')\n",
        "    TNS_obj_detection(SNe, t_lim=t_lim, use_saved=True)\n",
        "\n",
        "    # [2.5] Plot data\n",
        "    if plot_mode == 'SOLO':\n",
        "        print(\"[2.5] Plotting data [indivisual]...\")\n",
        "        with ZipFile(ATLAS_PLOTS_PATH+'/ATLASplots.zip', 'w') as zip_object:\n",
        "            for SN in SNe:\n",
        "                solo_plotting(name=SN.ATLASname, coords=[SN.RA, SN.DEC], err_max=err_max,\n",
        "                              t_o=SN.t_o, flux_o=SN.flux_o, flux_err_o=SN.dflux_o,\n",
        "                              t_c=SN.t_c, flux_c=SN.flux_c, flux_err_c=SN.dflux_c,\n",
        "                              save=True, saveLoc=ATLAS_PLOTS_PATH, show_plot=show_plot)\n",
        "                zip_object.write(ATLAS_PLOTS_PATH+SN.ATLASname+'_ATLASplot.png')\n",
        "                print('Plot saved to', ATLAS_PLOTS_PATH+SN.ATLASname+'_ATLASplot.png')\n",
        "    elif plot_mode == 'COMBINED':\n",
        "        print(\"[2.5] Plotting data [combined]...\")\n",
        "        fig, axs = plt.subplots(len(SNe), figsize=(12, len(SNe)*3.2))\n",
        "        fig.tight_layout(pad=5.0)\n",
        "        for n in range(len(SNe)):\n",
        "            combined_plotting(ax=axs[n], name=SN.ATLASname, coords=[SN.RA, SN.DEC],\n",
        "                              t_o=SNe[n].t_o, flux_o=SNe[n].flux_o, flux_err_o=SNe[n].dflux_o,\n",
        "                              t_c=SN.t_c, flux_c=SN.flux_c, flux_err_c=SN.dflux_c)\n",
        "        plt.savefig(ATLAS_PLOTS_PATH+'CombinedATLASplots.png')\n",
        "        print('Plot saved to', ATLAS_PLOTS_PATH+'CombinedATLASplots.png')\n",
        "        if show_plot:\n",
        "            plt.show()\n",
        "        else:\n",
        "            plt.close()\n",
        "\n",
        "    return SNe\n",
        "\n",
        "def ZTF_main_processing():\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" WORKFLOWS \"\"\"\n",
        "def SNooPy_fitting():\n",
        "    recover_dir()\n",
        "\n",
        "    # Initialize Data\n",
        "    KrisciunasNames = np.genfromtxt(\"/content/HiloCATsSN1991bg/targetLists/91bglike_justnames.txt\", dtype=str, delimiter=', ')\n",
        "\n",
        "    burnsData = np.genfromtxt('/content/HiloCATsSN1991bg/targetLists/burns+25table2ext.txt', dtype=str)\n",
        "    burnsDistances = {}\n",
        "    burnsNames = burnsData[:, 0]\n",
        "    for tar in np.stack((burnsData[:, 0], burnsData[:, 14]), axis=1):\n",
        "        burnsDistances.update({'SN'+tar[0]: float(tar[1])})\n",
        "\n",
        "    # Fitting Data\n",
        "    snpyDistances, snpyRedshifts = SNooPy2_fitting(CPSpath='/content/HiloCATsSN1991bg/data/CSPdata',\n",
        "                                                   tarNames=KrisciunasNames,\n",
        "                                                   model='EBV_model2',\n",
        "                                                   shape='st',\n",
        "                                                   bands=['B','g','r','i'],\n",
        "                                                   output=False,\n",
        "                                                   snpyPlots=True)\n",
        "\n",
        "    # ATLASnames = glob.glob('/content/ATLASsnpy/*')\n",
        "    # for n in range(len(ATLASnames)):\n",
        "    #     ATLASnames[n] = ATLASnames[n][21:-9]\n",
        "    # snpyDistances, snpyRedshifts, snpyParams = SNooPy2_fitting(CPSpath='/content/ATLASsnpy',\n",
        "    #                                             tarNames=ATLASnames,\n",
        "    #                                             model='EBV_model2',\n",
        "    #                                             shape='st',\n",
        "    #                                             bands=['ATgr', 'ATri'],\n",
        "    #                                             output=True,\n",
        "    #                                             snpyPlots=True)\n",
        "    # with open('/content/snpy_fit_plots/snpy_fit_params.txt', 'w') as f:\n",
        "    #     f.write('Object Name, mu, z, st, Tmax, EBVhost\\n')\n",
        "    #     for name in snpyDistances:\n",
        "    #         f.write(str(name)+', '+str(snpyDistances[name])+', '+str(snpyRedshifts[name])\n",
        "    #                 +', '+str(snpyParams[name][0])+', '+str(snpyParams[name][1])+', '+str(snpyParams[name][2])+'\\n')\n",
        "\n",
        "    # Plot Distance v. Distance\n",
        "    plot_DvD(snpyDistances, burnsDistances, size=(8,5), save=True)\n",
        "\n",
        "    # Plot Residuals\n",
        "    plot_residuals(snpyDistances, burnsDistances, snpyRedshifts, size=(8,5), save=True)\n",
        "    return\n",
        "\n",
        "def ATLAS_process():\n",
        "    # # [1] Collecting ATLAS data\n",
        "    # print('[1] Collecting ATLAS data...')\n",
        "    # data_collection(quiet=False)\n",
        "\n",
        "    # [2] Slice data, remove outliers, & plot\n",
        "    print('[2] Processing ATLAS data...')\n",
        "    SNe = ATLAS_main_processing(err_max=100, t_lim = 0.1, n_iter = 20, plot_mode = 'COMBINED', show_plot=True)\n",
        "    print('[2!] ATLAS data processed...', len(SNe), 'SN found and validated.')\n",
        "\n",
        "    # [3] Write ATLAS data to SNooPy ASCII file\n",
        "    print('[3] Writing ATLAS data to ASCII file for SNooPy...')\n",
        "    ATLASnames = snpy_ASCII_formatting(SNe)\n",
        "\n",
        "    # [4] SNooPy fitting\n",
        "    print('[4] Fitting ATLAS data with SNooPy...')\n",
        "    SNe = ATLAS_snpy_fitting(SNe, ATLASnames, show_plot=False)\n",
        "\n",
        "    # # [5] SNooPy fit mu v. Redshift\n",
        "    # plot_SNooPy_mu_vs_z()\n",
        "\n",
        "    # # [6] Histogram of fit parameters\n",
        "    # plot_SNooPy_hist(binNum=10)\n",
        "    return\n",
        "\n",
        "def ZTF_process():\n",
        "    # [1] Collecting ZTF data\n",
        "    print('[1] Collecting ZTF data...')\n",
        "    data = np.genfromtxt(ROOT_SAVE+'ATLAS_variables.txt', delimiter=', ', skip_header=1, dtype=str)\n",
        "    cords_91bglike = np.stack((data[:, 2], data[:, 3]), axis=1)\n",
        "    test_name, test_ra, test_decl = data[0][0], data[0][2], data[0][3]\n",
        "    # print(test_name, test_ra, test_decl)\n",
        "\n",
        "    # help(ztffp)\n",
        "\n",
        "    # print(ztffp.wget_check())\n",
        "    ztffp.test_email_connection()\n",
        "\n",
        "\n",
        "    # names = data[:, 0]\n",
        "    # print(names[0][2:], cords_91bglike[0][0], cords_91bglike[0][1])\n",
        "\n",
        "    # ztffp.run_ztf_fp(ra=cords_91bglike[0][0], decl=cords_91bglike[0][1], source_name=names[0][2:])\n",
        "\n",
        "    return\n"
      ],
      "metadata": {
        "id": "58PC6v_ax3c4"
      },
      "execution_count": 453,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" MAIN \"\"\"\n",
        "if __name__ == '__main__':\n",
        "    # Runtime tracker\n",
        "    start = time.time()\n",
        "\n",
        "    # Recovering vital directories\n",
        "    recover_dir()\n",
        "\n",
        "    # Workflow select\n",
        "    # SNooPy_fitting()\n",
        "    # ATLAS_process()\n",
        "    ZTF_process()\n",
        "\n",
        "    print('|---------------------------|\\n Run-time: ', round(time.time()-start, 4), 'seconds\\n|---------------------------|')"
      ],
      "metadata": {
        "id": "rI6R5V4-tUsZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}