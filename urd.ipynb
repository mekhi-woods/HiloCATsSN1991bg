{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnkShS58unz5l//8OWECv3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mekhi-woods/HiloCATsSN1991bg/blob/master/urd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# M.D. Woods - 10/11/24\n",
        "import warnings\n",
        "# warnings.simplefilter(\"ignore\", UserWarning)\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy\n",
        "import snpy\n",
        "import glob\n",
        "import shutil\n",
        "import sncosmo\n",
        "import numpy as np\n",
        "import time as systime\n",
        "import matplotlib.pyplot as plt\n",
        "from astro_ghost.ghostHelperFunctions import getTransientHosts\n",
        "from astropy.coordinates import SkyCoord, Galactic\n",
        "from astropy.table import Table\n",
        "from astroquery.sdss import SDSS\n",
        "from astropy.stats import sigma_clip\n",
        "from astropy.stats import sigma_clipped_stats\n",
        "\n",
        "from scripts import general as gen\n",
        "from scripts import get_vpec\n",
        "\n",
        "CONSTANTS = gen.get_constants()"
      ],
      "metadata": {
        "id": "IM66uIKB-wGI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SN91bg:\n",
        "    def __init__(self, objname=None, originalname=None, coords=(0.00, 0.00), z=0.00, origin=None, discovery_data=None):\n",
        "        self.objname = objname\n",
        "        self.originalname = originalname\n",
        "        self.coords = coords\n",
        "        self.z = z\n",
        "        self.z_cmb = np.nan\n",
        "        self.origin = origin\n",
        "        self.discovery_date = discovery_data\n",
        "\n",
        "        self.period = None\n",
        "        self.params = {}\n",
        "\n",
        "        self.zp = np.array([])\n",
        "        self.filters = np.array([])\n",
        "        self.time = np.array([])\n",
        "        self.flux = np.array([])\n",
        "        self.dflux = np.array([])\n",
        "        self.mag = np.array([])\n",
        "        self.dmag = np.array([])\n",
        "\n",
        "        return\n",
        "    def __str__(self):\n",
        "        return (self.objname + ' | ' + self.originalname + ' | ' + self.origin + ' | ' + str(self.coords) +\n",
        "                ' | (z | z_cmb): (' + str(self.z) + ' | ' + str(round(self.z_cmb, 2)) + ')')\n",
        "    def print_info(self):\n",
        "        # Header\n",
        "        print('---------------------------------------------------------------------------------------------')\n",
        "        print('|+| ' + self.objname + ' |+|\\n' + self.originalname + ' | ' + self.origin + ' | ' + str(self.coords) +\n",
        "              ' | (z | z_cmb): (' + str(self.z) + ' | ' + str(round(self.z_cmb, 4)) + ')')\n",
        "        print('---------------------------------------------------------------------------------------------')\n",
        "\n",
        "        # Print array ranges\n",
        "        print('\\tFilters: \\t' + str(np.unique(self.filters)))\n",
        "        print('\\tFlux: \\t\\t(' + str(round(np.min(self.flux), 3)) + ' -- ' + str(round(np.max(self.flux), 3)) + ')' +\n",
        "              ' | ' + 'dFlux: (' + str(round(np.min(self.dflux), 3)) + ' -- ' + str(round(np.max(self.dflux), 3)) + ')')\n",
        "        print('\\tMag: \\t\\t(' + str(round(np.min(self.mag), 3)) + ' -- ' + str(round(np.max(self.mag), 3)) + ')' +\n",
        "              ' | ' + 'dMag: (' + str(round(np.min(self.dmag), 3)) + ' -- ' + str(round(np.max(self.dmag), 3)) + ')')\n",
        "        print('\\tMJDs-MJDe: \\t(' + str(self.period[0]) + ' -- ' + str(self.period[1]) + ')')\n",
        "        print('---------------------------------------------------------------------------------------------')\n",
        "\n",
        "        # Print params\n",
        "        if len(self.params) > 0:\n",
        "            for p in self.params:\n",
        "                print('\\t'+p+': ' + str(round(self.params[p]['value'], 3)) +\n",
        "                      ' +/- ' + str(round(self.params[p]['err'], 3)))\n",
        "        print('---------------------------------------------------------------------------------------------')\n",
        "    def plot(self, y_type='mag', save_loc='', zoom=0, subplots=False, date_lines=True):\n",
        "        print('[+++] Plotting LC of '+self.objname+'...')\n",
        "        filter_dict = {'u': 'teal', 'g': 'green', 'r': 'red', 'i': 'indigo', 'B': 'blue',\n",
        "                       'V0': 'violet', 'V1': 'purple', 'V': 'red', 'Y': 'goldenrod', 'Hdw': 'tomato', 'H': 'salmon',\n",
        "                       'J': 'aquamarine', 'Jrc2': 'cadetblue', 'Jdw': 'turquoise', 'Ydw': 'olive',\n",
        "                       'c': 'cyan', 'o': 'orange', 'ZTF_g': 'green', 'ZTF_r': 'red', 'ZTF_i': 'indigo'}\n",
        "\n",
        "        # Plot\n",
        "        unique_filters, num_plts = np.unique(self.filters), len(np.unique(self.filters))\n",
        "        if not subplots:\n",
        "            plt.figure(figsize=(10, 4), constrained_layout=True)\n",
        "            size = None\n",
        "        elif self.origin == 'CSP':\n",
        "            plt.figure(figsize=(25, 8), constrained_layout=True)\n",
        "            size = (2, 6)\n",
        "        elif self.origin == 'ATLAS':\n",
        "            plt.figure(figsize=(12, 4), constrained_layout=True)\n",
        "            size = (1, 2)\n",
        "        elif self.origin == 'ZTF':\n",
        "            plt.figure(figsize=(25, 5), constrained_layout=True)\n",
        "            size = (1, 3)\n",
        "        elif self.origin == 'ATLAS-ZTF':\n",
        "            plt.figure(figsize=(25, 8), constrained_layout=True)\n",
        "            size = (2, 5)\n",
        "        else:\n",
        "            raise ValueError('[!!!] Origin not valid!'\n",
        "                             )\n",
        "\n",
        "        # Plot for each filter\n",
        "        for i in range(num_plts):\n",
        "            if size is not None:\n",
        "                plt.subplot(size[0], size[1], i+1)\n",
        "            indexes = np.where(self.filters == unique_filters[i])[0]\n",
        "            if y_type == 'mag':\n",
        "                plt.errorbar(self.time[indexes], self.mag[indexes], yerr=self.dmag[indexes], fmt='o', ms=4, elinewidth=0.3,\n",
        "                             color=filter_dict[self.filters[indexes][0]], label=self.filters[indexes][0])\n",
        "            elif y_type == 'flux':\n",
        "                plt.errorbar(self.time[indexes], self.flux[indexes], yerr=self.dflux[indexes],\n",
        "                             fmt='o', ms=4, elinewidth=0.3,\n",
        "                             color=filter_dict[self.filters[indexes][0]], label=self.filters[indexes][0])\n",
        "\n",
        "            # Format\n",
        "            if size is not None and i > 0:\n",
        "                plt.gca().get_yaxis().set_visible(False)  # Turn off y-axis labels\n",
        "\n",
        "        if date_lines:\n",
        "            # Tmax line\n",
        "            if len(self.params) > 0:\n",
        "                if 'Tmax' in list(self.params.keys()):\n",
        "                    plt.axvline(x=self.params['Tmax']['value'],\n",
        "                                color='maroon', ls='-.', label='Tmax', linewidth=3, alpha=0.5)\n",
        "                elif 't0' in list(self.params.keys()):\n",
        "                    plt.axvline(x=self.params['t0']['value'],\n",
        "                                color='maroon', ls='-.', label='Tmax', linewidth=3, alpha=0.5)\n",
        "\n",
        "            # Plot discovery date\n",
        "            plt.axvline(x=float(self.discovery_date),\n",
        "                        color='peru', ls='--', label='Discovery Date', linewidth=3, alpha=0.5)\n",
        "\n",
        "        if zoom > 0:\n",
        "            if 'Tmax' in list(self.params.keys()):\n",
        "                plt.xlim(self.params['Tmax']['value']-zoom, self.params['Tmax']['value']+zoom)\n",
        "            elif 't0' in list(self.params.keys()):\n",
        "                plt.xlim(self.params['t0']['value']-zoom, self.params['t0']['value']+zoom)\n",
        "\n",
        "            plt.xlabel('MJD')\n",
        "            plt.legend()\n",
        "        if y_type == 'mag':\n",
        "            plt.gca().invert_yaxis()\n",
        "        elif y_type == 'flux':\n",
        "            plt.ylim(0)\n",
        "        plt.suptitle('Lightcurve -- '+self.objname+' | '+self.originalname+' -- '+y_type)\n",
        "        if len(save_loc) != 0:\n",
        "            print('[+++] Saving to '+save_loc)\n",
        "            plt.savefig(save_loc)\n",
        "        plt.show()\n",
        "        return\n",
        "    # -----------------------------------------------------------------------------------------------------------------\n",
        "    def save_class(self, save_loc):\n",
        "        print('[+++] '+self.objname+' -- Saving class to '+save_loc+'classes/'+self.objname+'_class.txt')\n",
        "        with open(save_loc+'classes/'+self.objname+'_class.txt', 'w') as f:\n",
        "            f.write(self.origin + ' ' + self.objname + ' ' + self.originalname +\n",
        "                    ' ' + str(self.coords[0]) + ' ' + str(self.coords[1]) +\n",
        "                    ' ' + str(self.z) + ' ' + str(self.z_cmb) + ' ' + str(self.discovery_date) + '\\n')\n",
        "            f.write('++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n')\n",
        "\n",
        "            for p in self.params:\n",
        "                f.write(p+', ' + str(self.params[p]['value']) + ', ' + str(self.params[p]['err']) + '\\n')\n",
        "\n",
        "            f.write('++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n')\n",
        "            cats = [self.zp, self.filters, self.time, self.flux, self.dflux, self.mag, self.dmag]\n",
        "            cat_names = ['zp', 'filters', 'time', 'flux', 'dflux', 'mag', 'dmag']\n",
        "            for i in range(len(cat_names)):\n",
        "                f.write(cat_names[i])\n",
        "                for j in range(len(self.zp)):\n",
        "                    f.write(', ' + str(cats[i][j]))\n",
        "                f.write('\\n')\n",
        "        return\n",
        "    def load_from_file(self, file):\n",
        "        print('[+++] Loading class from '+file)\n",
        "        with open(file, 'r') as f:\n",
        "            hdr = f.readline().split(' ')\n",
        "            self.origin, self.objname, self.originalname, self.coords, self.z, self.z_cmb, self.discovery_date = (\n",
        "                hdr[0], hdr[1], hdr[2],\n",
        "                (float(hdr[3]), float(hdr[4])), float(hdr[5]), float(hdr[6]), float(hdr[7][:-1]))\n",
        "\n",
        "            f.readline()\n",
        "\n",
        "            line = f.readline()\n",
        "            while '+++' not in line:\n",
        "                line = line.split(', ')\n",
        "                self.params.update({line[0]: {'value': float(line[1]), 'err': float(line[2])}})\n",
        "                line = f.readline()\n",
        "\n",
        "            self.zp = np.array(f.readline().split(', ')[1:]).astype(float)\n",
        "            self.filters = np.array(f.readline().split(', ')[1:]).astype(str)\n",
        "            self.filters[-1] = self.filters[-1][:-1]  # Removes the /n from the end of the line\n",
        "            self.time = np.array(f.readline().split(', ')[1:]).astype(float)\n",
        "            self.flux = np.array(f.readline().split(', ')[1:]).astype(float)\n",
        "            self.dflux = np.array(f.readline().split(', ')[1:]).astype(float)\n",
        "            self.mag = np.array(f.readline().split(', ')[1:]).astype(float)\n",
        "            self.dmag = np.array(f.readline().split(', ')[1:]).astype(float)\n",
        "\n",
        "            self.period = (np.min(self.time), np.max(self.time))\n",
        "        return self\n",
        "    # -----------------------------------------------------------------------------------------------------------------\n",
        "    def fit(self, algo='snpy', save_loc=None):\n",
        "        if save_loc is None:\n",
        "            save_loc = CONSTANTS[algo+'_'+self.origin.lower() + '_saved_loc']\n",
        "\n",
        "        # Choose algorithm\n",
        "        if algo == \"snpy\":\n",
        "            self.write_snpy_ascii(save_loc=save_loc + 'ascii/')\n",
        "            self.snpy_fit(save_loc=save_loc)\n",
        "        elif algo == 'salt':\n",
        "            self.salt_fit(save_loc=save_loc)\n",
        "        if self.params['mu']['value'] <= 0.00:\n",
        "            return None\n",
        "\n",
        "        # Analysis\n",
        "        self.get_host_mass(use_key=True)\n",
        "\n",
        "        # Save\n",
        "        self.save_class(save_loc)\n",
        "        return\n",
        "    def make_class(self, data_set, path, dmag_max=0.00, dflux_max=0.00):\n",
        "        if data_set == 'CSP':\n",
        "            print('[+++] Creating class using CSP data...')\n",
        "            print(path)\n",
        "            # Header elements\n",
        "            with open(path, 'r') as f:\n",
        "                objname, z, ra, dec = f.readline().split(' ')\n",
        "                objname, z, ra, dec = objname[2:], float(z), float(ra), float(dec[:-1])\n",
        "            originalname = path.split('/')[-1].split('_')[0]\n",
        "\n",
        "            # Query TNS for transient details\n",
        "            objname, z_void, discdate = gen.TNS_details(ra, dec)  # Voiding the redshift from TNS, its None for some reason\n",
        "\n",
        "            # Make class\n",
        "            temp_sn = SN91bg(objname=objname,\n",
        "                             originalname=originalname,\n",
        "                             coords=(ra, dec),\n",
        "                             z=z,\n",
        "                             origin='CSP',\n",
        "                             discovery_data=discdate)\n",
        "\n",
        "            # Set arrays\n",
        "            class_filter = ''\n",
        "            with open(path, 'r') as f:\n",
        "                f.readline()  # Skips header\n",
        "                for line in f.readlines():\n",
        "                    data_line = line[:-1].split(' ')\n",
        "                    if len(data_line) == 2:\n",
        "                        class_filter = data_line[1]\n",
        "                    elif len(data_line) >= 3:\n",
        "                        if len(data_line) == 4:\n",
        "                            data_line = data_line[1:]\n",
        "                        n_time, n_mag, n_dmag = float(data_line[0]), float(data_line[1]), float(data_line[2])\n",
        "                        zp = float(CONSTANTS['csp_zpts_' + class_filter])\n",
        "                        n_time = n_time + 53000  # JD to MJD\n",
        "\n",
        "                        n_flux = 10 ** ((n_mag - zp) / -2.5)\n",
        "                        n_dflux = np.abs(n_flux) * np.log(10) * ((1 / 2.5) * n_dmag)\n",
        "\n",
        "                        temp_sn.zp = np.append(temp_sn.zp, zp)\n",
        "                        temp_sn.filters = np.append(temp_sn.filters, class_filter)\n",
        "                        temp_sn.time = np.append(temp_sn.time, n_time)\n",
        "                        temp_sn.flux = np.append(temp_sn.flux, n_flux)\n",
        "                        temp_sn.dflux = np.append(temp_sn.dflux, n_dflux)\n",
        "                        temp_sn.mag = np.append(temp_sn.mag, n_mag)\n",
        "                        temp_sn.dmag = np.append(temp_sn.dmag, n_dmag)\n",
        "        elif data_set == 'ATLAS':\n",
        "            print('[+++] Creating class using ATLAS data...')\n",
        "            print(path)\n",
        "\n",
        "            # Load data\n",
        "            data = np.genfromtxt(path, delimiter=',', dtype=str, skip_header=1)\n",
        "\n",
        "            # Check if  file empty\n",
        "            if len(data) == 0:\n",
        "                print('[!!!] File [' + path + '] empty!')\n",
        "                return None\n",
        "\n",
        "            # Query TNS for transient details\n",
        "            ra, dec = np.average(data[:, 1].astype(float)), np.average(data[:, 2].astype(float))\n",
        "            objname, z, discdate = gen.TNS_details(ra, dec)\n",
        "\n",
        "            # Make class\n",
        "            temp_sn = SN91bg(objname=objname,\n",
        "                             originalname=path.split('/')[-1].split('.')[0],\n",
        "                             coords=(ra, dec),\n",
        "                             z=np.nan if z == 'None' else float(z),\n",
        "                             origin='ATLAS',\n",
        "                             discovery_data=discdate)\n",
        "\n",
        "            # Set arrays\n",
        "            temp_sn.zp = data[:, 7].astype(float)\n",
        "            temp_sn.filters = data[:, 6]\n",
        "            temp_sn.time = data[:, 8]\n",
        "            temp_sn.flux = data[:, 16]\n",
        "            temp_sn.dflux = data[:, 17]\n",
        "            temp_sn.mag = data[:, 3]\n",
        "            temp_sn.dmag = data[:, 4]\n",
        "        elif data_set == 'ZTF':\n",
        "            print('[+++] Creating class using ZTF data...')\n",
        "            print(path)\n",
        "\n",
        "            # Load data\n",
        "            data = np.genfromtxt(path, delimiter=None, dtype=str, skip_header=56)\n",
        "\n",
        "            # Check if file is empty\n",
        "            if len(data) == 0:\n",
        "                print('[!!!] File [' + path + '] empty!')\n",
        "                return None\n",
        "\n",
        "            with (open(path, 'r') as f):\n",
        "                ztf_spread = float(CONSTANTS['ztf_spread'])\n",
        "\n",
        "                hdr = f.readlines()\n",
        "                ra, dec = float(hdr[3].split(' ')[-2]), float(hdr[4].split(' ')[-2])\n",
        "                objname, z, discdate = gen.TNS_details(ra, dec)\n",
        "                originalname = path.split('/')[-1].split('.')[0].split('_')[1]\n",
        "                z = np.nan if z == 'None' else float(z)\n",
        "\n",
        "                # Get magnitudes m = -2.5log(F) + zp\n",
        "                time, flux, dflux, zp, filters = data[:, 22], data[:, 24], data[:, 25], data[:, 20], data[:, 4]\n",
        "                valid_ints = np.unique(np.hstack((np.where(flux != 'null')[0], np.where(dflux != 'null')[0])))\n",
        "                time, zp, filters = time[valid_ints].astype(float), zp[valid_ints].astype(float), filters[valid_ints]\n",
        "                flux, dflux = flux[valid_ints].astype(float), dflux[valid_ints].astype(float)\n",
        "                time = time - 2400000.5  # JD to MJD\n",
        "                mag = (-2.5 * np.log10(flux)) + zp\n",
        "                dmag = np.abs(-1.08573620476 * (dflux / flux))\n",
        "\n",
        "                # Adjusting around tmax\n",
        "                if ztf_spread != 0 and len(time) != 0:\n",
        "                    t_max_guess = float(discdate)\n",
        "                    zoom_indexes = np.where(time < t_max_guess + ztf_spread)\n",
        "                    zoom_indexes = np.where(time[zoom_indexes] > t_max_guess - ztf_spread)\n",
        "\n",
        "                    time = time[zoom_indexes]\n",
        "                    flux = flux[zoom_indexes]\n",
        "                    dflux = dflux[zoom_indexes]\n",
        "                    mag = mag[zoom_indexes]\n",
        "                    dmag = dmag[zoom_indexes]\n",
        "                    zp = zp[zoom_indexes]\n",
        "                    filters = filters[zoom_indexes]\n",
        "\n",
        "            # Make class\n",
        "            temp_sn = SN91bg(objname=objname,\n",
        "                             originalname=originalname,\n",
        "                             coords=(ra, dec),\n",
        "                             z=z,\n",
        "                             origin='ZTF',\n",
        "                             discovery_data=discdate)\n",
        "\n",
        "            # Set arrays\n",
        "            temp_sn.zp = zp\n",
        "            temp_sn.filters = filters\n",
        "            temp_sn.time = time\n",
        "            temp_sn.flux = flux\n",
        "            temp_sn.dflux = dflux\n",
        "            temp_sn.mag = mag\n",
        "            temp_sn.dmag = dmag\n",
        "        else:\n",
        "            raise ValueError(\"Data set '\" +\n",
        "                             data_set + \"' not recognized\")\n",
        "\n",
        "        # Clean data\n",
        "        temp_sn.clean_data(dmag_max, dflux_max)\n",
        "\n",
        "        # Final stage\n",
        "        if temp_sn.period is None:\n",
        "            print('[!!!] No valid points found in file!')\n",
        "            return None\n",
        "        else:\n",
        "            print('      Class created successfully!')\n",
        "            return temp_sn\n",
        "    def clean_data(self, dmag_max=0.00, dflux_max=0.00):\n",
        "        print('[+++] '+self.objname+' -- Cleaning data...')\n",
        "\n",
        "        # Adjust Maximums\n",
        "        if dmag_max == 'median':\n",
        "            dmag_max = np.median(self.dmag)\n",
        "        if dflux_max == 'median':\n",
        "            dflux_max = np.median(self.dflux)\n",
        "        if dmag_max == 'average':\n",
        "            dmag_max = np.median(self.dmag)\n",
        "        if dflux_max == 'average':\n",
        "            dflux_max = np.average(self.dflux)\n",
        "\n",
        "        new_zp, new_filters, new_time, new_mag, new_dmag, new_flux, new_dflux = (\n",
        "            np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([]))\n",
        "        for n in range(len(self.zp)):\n",
        "            n_zp, n_filters, n_time = self.zp[n], self.filters[n], self.time[n]\n",
        "            n_mag, n_dmag, n_flux, n_dflux = self.mag[n], self.dmag[n], self.flux[n], self.dflux[n]\n",
        "            n_mag = str(n_mag).replace('>', '')\n",
        "            if n_mag == 'None' or n_dmag == 'None' or n_flux == 'None' or n_dflux == 'None':\n",
        "                continue\n",
        "            if float(n_dflux) == 0 or float(n_dmag) == 0 or float(n_mag) <= 0 or float(n_flux) <= 0:\n",
        "                continue\n",
        "            # Cut errors\n",
        "            if (dmag_max != 0) and (float(n_dmag) > dmag_max):\n",
        "                continue\n",
        "            if (dflux_max != 0) and (float(n_dflux) > dflux_max):\n",
        "                continue\n",
        "\n",
        "            new_zp = np.append(new_zp, float(n_zp))\n",
        "            new_filters = np.append(new_filters, n_filters)\n",
        "            new_time = np.append(new_time, float(n_time))\n",
        "            new_mag = np.append(new_mag, float(n_mag))\n",
        "            new_dmag = np.append(new_dmag, float(n_dmag))\n",
        "            new_flux = np.append(new_flux, float(n_flux))\n",
        "            new_dflux = np.append(new_dflux, float(n_dflux))\n",
        "\n",
        "        self.zp = np.copy(new_zp)\n",
        "        self.filters = np.copy(new_filters)\n",
        "        self.time = np.copy(new_time)\n",
        "        self.mag = np.copy(new_mag)\n",
        "        self.dmag = np.copy(new_dmag)\n",
        "        self.flux = np.copy(new_flux)\n",
        "        self.dflux = np.copy(new_dflux)\n",
        "\n",
        "        if len(self.time) > 0:\n",
        "            self.period = (np.min(self.time), np.max(self.time))\n",
        "\n",
        "        return\n",
        "    def write_snpy_ascii(self, save_loc='default/'):\n",
        "        print('[+++] '+self.objname+' -- Saving data to ASCII files for SNooPy...')\n",
        "        filter_dict = {'o': 'ATri', 'c': 'ATgr',\n",
        "                       'ZTF_g': 'g', 'ZTF_r': 'r', 'ZTF_i': 'i',\n",
        "                       'B': 'B', 'H': 'H', 'J': 'J', 'Jrc2': 'Jrc2', 'V': 'V', 'V0': 'V0', 'Y': 'Y', 'Ydw': 'Ydw', 'g': 'g', 'i': 'i', 'r': 'r', 'u': 'u'}\n",
        "        with open(save_loc + self.objname + '_snpy.txt', 'w') as f:\n",
        "            # Line 1 -- Objname, Helio-Z, RA, Dec (Ex. SN1981D 0.005871 50.65992 -37.23272)\n",
        "            f.write(str(self.objname)+' '+str(self.z)+' '+str(self.coords[0])+' '+str(self.coords[1])+'\\n')\n",
        "            for f_w in np.unique(self.filters):\n",
        "                f_indexes = np.where(self.filters == f_w)[0]\n",
        "                f.write('filter ' + filter_dict[f_w] + '\\n')\n",
        "                for i in f_indexes:\n",
        "                    # filter photometry block -- Date (JD/MJD), mag, err (i.e. 674.8593 12.94 0.11)\n",
        "                    f.write(str(self.time[i]) + '\\t' + str(self.mag[i]) + '\\t' + str(self.dmag[i]) + '\\n')\n",
        "        print('      Saved file to '+save_loc + self.objname + '_snpy.txt')\n",
        "        return\n",
        "    def snpy_fit(self, save_loc, use_saved=False, show_plot=True, quiet=False):\n",
        "        print('[+++] '+self.objname+' -- Fitting data with SNooPy...')\n",
        "        load_path = save_loc + 'ascii/' + self.objname + '_snpy.txt'\n",
        "        save_path = save_loc + 'models/' + self.objname + '_EBV_model2.snpy'\n",
        "        param_names = ['mu', 'st', 'Tmax', 'EBVhost']\n",
        "        snpy_param_names = ['DM', 'st', 'Tmax', 'EBVhost']\n",
        "\n",
        "        # Check quiet\n",
        "        if quiet:\n",
        "            sys.stdout = open(os.devnull, 'w')\n",
        "\n",
        "        # Check saved models\n",
        "        if use_saved and os.path.isfile(save_path):\n",
        "            print('[+++] Saved model found! Pulling from...', save_path)\n",
        "            n_s = snpy.get_sn(save_path)\n",
        "            for i in range(len(param_names)):\n",
        "                self.params.update({param_names[i]: {'value': n_s.parameters[snpy_param_names[i]],\n",
        "                                                     'err': n_s.errors[snpy_param_names[i]]}})\n",
        "            return\n",
        "\n",
        "        # Load Data\n",
        "        try:\n",
        "            n_s = snpy.get_sn(load_path)\n",
        "        except Exception as error:\n",
        "            self.params.update({'mu': {'value': 0.00, 'err': 0.00}})\n",
        "            print('[!!!] Failed to load ASCII file -- ', error)\n",
        "            return\n",
        "        # n_s.k_version = '91bg'\n",
        "        n_s.choose_model('EBV_model2', stype='st')\n",
        "        n_s.set_restbands()  # Auto pick appropriate rest-bands\n",
        "\n",
        "        # Remove empty filters -- fix for 'ValueError: attempt to get argmin of an empty sequence'\n",
        "        for class_filter in list(n_s.data.keys()):\n",
        "            if len(n_s.data[class_filter].magnitude) == 0:\n",
        "                del n_s.data[class_filter]\n",
        "            elif self.origin == 'CSP' and class_filter in ['u', 'Y', 'J', 'H', 'Jrc2', 'Ydw']:\n",
        "                print('[***] Special Process for CSP! Removing ' + class_filter + '...')\n",
        "                del n_s.data[class_filter]\n",
        "        print('      Best filters:', list(n_s.data.keys()))\n",
        "\n",
        "        for i in range(5):\n",
        "            try:\n",
        "                if self.origin == 'CSP':\n",
        "                    initial_filters = []\n",
        "                    for fil in ['B', 'V', 'g']:\n",
        "                        if fil in list(n_s.data.keys()):\n",
        "                            initial_filters.append(fil)\n",
        "                    print('[***] Special Process for CSP! Fitting as '+str(initial_filters)+' -> remaining...')\n",
        "\n",
        "                    n_s.fit(initial_filters, dokcorr=True, k_stretch=False, reset_kcorrs=True,\n",
        "                            **{'mangle': 1, 'calibration': 0})\n",
        "                    n_s.fit(bands=None, dokcorr=True, k_stretch=False, reset_kcorrs=True,\n",
        "                            **{'mangle': 1, 'calibration': 0})\n",
        "                else:\n",
        "                    n_s.fit(bands=None, dokcorr=True, k_stretch=False, reset_kcorrs=True,\n",
        "                            **{'mangle': 1, 'calibration': 0})\n",
        "                n_s.save(save_path)\n",
        "\n",
        "                # Save parameters\n",
        "                for j in range(len(param_names)):\n",
        "                    self.params.update({param_names[j]: {'value': n_s.parameters[snpy_param_names[j]],\n",
        "                                                         'err': n_s.errors[snpy_param_names[j]]}})\n",
        "\n",
        "                if show_plot:\n",
        "                    n_s.plot(outfile=save_loc + 'plots/' + self.objname + '_snpyplots.png')\n",
        "                    plt.show()\n",
        "                    systime.sleep(3)\n",
        "                plt.close()\n",
        "                break\n",
        "            except Exception as error:\n",
        "                if 'All weights for filter' and 'are zero.' in str(error):\n",
        "                    print('[!!!] Weights for filter', str(error).split(' ')[4], 'are zero. Removing...')\n",
        "                    del n_s.data[str(error).split(' ')[4]]\n",
        "                elif str(error) == 'Error:  to solve for EBVhost, you need to fit more than one filter':\n",
        "                    print('[!!!] To few filters to fit!')\n",
        "                    self.params.update({'mu': {'value': -1.0, 'err': -1.0}})\n",
        "                    break\n",
        "                else:\n",
        "                    self.params.update({'mu': {'value': -1.0, 'err': -1.0}})\n",
        "                    print(error)\n",
        "\n",
        "        # Restore print statements\n",
        "        sys.stdout = sys.__stdout__\n",
        "\n",
        "        return\n",
        "    def salt_fit(self, save_loc, show_plot=True, quiet=False):\n",
        "        print('[+++] '+self.objname+' -- Fitting data with SALT3...')\n",
        "\n",
        "        # Check quiet\n",
        "        if quiet:\n",
        "            sys.stdout = open(os.devnull, 'w')\n",
        "\n",
        "        alpha, beta = float(CONSTANTS['salt_alpha']), float(CONSTANTS['salt_beta'])\n",
        "        mB_const, M0 = float(CONSTANTS['salt_mB_const']), float(CONSTANTS['salt_absolute_mag'])\n",
        "        try:\n",
        "            # Fix filters\n",
        "            filter_dict = {'u': 'cspu', 'g': 'cspg', 'r': 'cspr', 'i': 'cspi', 'B': 'cspB',\n",
        "                           'V0': 'cspv3014', 'V1': 'cspv3009', 'V': 'cspv9844', 'Y': 'cspys',\n",
        "                           'J': 'cspjs', 'Jrc2': 'cspjd', 'Jdw': 'cspjd', 'Ydw': 'cspyd', 'Hdw': 'csphd', 'H': 'csphs',\n",
        "                           'c': 'atlasc', 'o': 'atlaso', 'ZTF_g': 'ztfg', 'ZTF_r': 'ztfr', 'ZTF_i': 'ztfi'}\n",
        "            salt_time, salt_filters, salt_flux = np.array([]), np.array([]), np.array([])\n",
        "            salt_dflux, salt_zp = np.array([]), np.array([])\n",
        "\n",
        "            # Fix filters\n",
        "            for i in range(len(self.filters)):\n",
        "                if self.origin == 'CSP' and self.filters[i] in ['u', 'Y', 'J', 'H', 'Jrc2', 'Ydw']:\n",
        "                    continue\n",
        "                salt_time = np.append(salt_time, self.time[i])\n",
        "                salt_filters = np.append(salt_filters, filter_dict[self.filters[i]])\n",
        "                salt_flux = np.append(salt_flux, self.flux[i])\n",
        "                salt_dflux = np.append(salt_dflux, self.dflux[i])\n",
        "                salt_zp = np.append(salt_zp, self.zp[i])\n",
        "            print('[***] Special Process for CSP!', np.unique(self.filters), '->', np.unique(salt_filters))\n",
        "\n",
        "            data = Table([salt_time, salt_filters, salt_flux, salt_dflux, salt_zp, np.full(len(salt_time), 'ab')],\n",
        "                         names=('time', 'band', 'flux', 'fluxerr', 'zp', 'zpsys'))\n",
        "\n",
        "            # Create Model\n",
        "            model = sncosmo.Model(source='salt3')\n",
        "\n",
        "            # Fit data to model\n",
        "            # details = gen.TNS_details(self.coords[0], self.coords[1])\n",
        "            model.set(z=self.z, t0=self.discovery_date)  # set the model's redshift.\n",
        "            result, fitted_model = sncosmo.fit_lc(data, model, ['t0', 'x0', 'x1', 'c'], bounds={'x1': (-5, 5)})\n",
        "\n",
        "            param_names = ['t0', 'x0', 'x1', 'c']\n",
        "            for i in range(len(param_names)):\n",
        "                self.params.update({param_names[i]: {'value': result.parameters[i+1],\n",
        "                                                     'err': result.errors[param_names[i]]}})\n",
        "\n",
        "            # Calculate\n",
        "            pho_mB = -2.5 * np.log10(self.params['x0']['value']) + mB_const\n",
        "            pho_mB_err = np.abs(-2.5 * (self.params['x0']['err'] / (self.params['x0']['value'] * np.log(10))))\n",
        "\n",
        "            mu = pho_mB + (alpha * self.params['x1']['value']) - (beta * self.params['c']['value']) - M0\n",
        "            mu_err = np.sqrt(pho_mB_err ** 2 + (np.abs(alpha) * self.params['x1']['err']) ** 2 + (np.abs(beta) * self.params['c']['err']) ** 2)\n",
        "\n",
        "            self.params.update({'mu': {'value': mu, 'err': mu_err}})\n",
        "\n",
        "            # Plot data with fit\n",
        "            if show_plot:\n",
        "                sncosmo.plot_lc(data, model=fitted_model, errors=result.errors)\n",
        "                print('Saving plots to', save_loc + '/plots/' + self.objname + '_salt3lc.png')\n",
        "                plt.savefig(save_loc + '/plots/' + self.objname + '_salt3lc.png')\n",
        "                plt.show()\n",
        "\n",
        "            print('      Successfully fit ' + self.objname + '!')\n",
        "            print('Pausing for 1 seconds...')\n",
        "            systime.sleep(1)\n",
        "        except Exception as error:\n",
        "            print(error)\n",
        "            self.params.update({'mu': {'value': -1.0, 'err': -1.0}})\n",
        "\n",
        "        # Restore print statements\n",
        "        sys.stdout = sys.__stdout__\n",
        "\n",
        "        return\n",
        "    def get_host_mass(self, use_key=False):\n",
        "        print('[+++] '+self.objname+' -- Finding host galaxy mass using GHOST...')\n",
        "        local_coords = SkyCoord(self.coords[0], self.coords[1], unit=\"deg\")\n",
        "        galac_coords = local_coords.transform_to(Galactic())\n",
        "\n",
        "        # Get CMB redshift\n",
        "        helio_corr = (float(CONSTANTS['cmb_v_helio']) / float(CONSTANTS['cmb_c']) *\n",
        "                      ((np.sin(galac_coords.b.deg) * np.sin(float(CONSTANTS['cmb_b_h'])) + np.cos(galac_coords.b.deg) *\n",
        "                        np.cos(float(CONSTANTS['cmb_b_h'])) * np.cos(galac_coords.l.deg - float(CONSTANTS['cmb_l_h'])))))\n",
        "        corr_term = 1 - helio_corr\n",
        "        self.z_cmb = (1 + self.z) / corr_term - 1\n",
        "\n",
        "        # Peculiar Velocity Correction -- using 'get_vpec.py' from David\n",
        "        VP = get_vpec.VelocityCorrection(f\"twomass++_velocity_LH11.npy\")\n",
        "        self.z_cmb = VP.correct_redshift(self.z, 0, local_coords.galactic.l.deg, local_coords.galactic.b.deg)\n",
        "        vpec, vpec_sys = get_vpec.main(self.coords[0], self.coords[1], self.z_cmb)\n",
        "        self.z_cmb += vpec / 3e5\n",
        "\n",
        "        # Try mass key\n",
        "        if use_key:\n",
        "            mass_key = {}\n",
        "            with open(CONSTANTS['mass_key_txt'], 'r') as f:\n",
        "                temp = f.readlines()\n",
        "                for line in temp:\n",
        "                    line = line[:-1].split(', ')\n",
        "                    if len(line) != 3:\n",
        "                        continue\n",
        "                    mass_key.update({line[0]: {'mass': line[1], 'mass_err': line[2]}})\n",
        "            if self.objname in mass_key:\n",
        "                print('      Found object in mass key! Pulling...')\n",
        "                if float(mass_key[self.objname]['mass']) < 0:\n",
        "                    print('      Found mass known to not be in GLADE/PanSTARR/SDSS')\n",
        "                    return\n",
        "                self.params.update({'hostMass': {'value': float(mass_key[self.objname]['mass']),\n",
        "                                                 'err': float(mass_key[self.objname]['mass_err'])}})\n",
        "                print('[+++] Mass taken from mass key!')\n",
        "                return\n",
        "\n",
        "        # Getting host data -- checks GLADE then PANSTARRS\n",
        "        gMag, iMag, iAbsMag = -999.00, -999.00, -999.00\n",
        "        gMagErr, iMagErr, iAbsMagErr = -999.00, -999.00, -999.00\n",
        "        try:\n",
        "            with warnings.catch_warnings():\n",
        "                warnings.simplefilter(\"ignore\")\n",
        "                host_data = getTransientHosts(transientCoord=[local_coords],\n",
        "                                              transientName=[self.objname],\n",
        "                                              verbose=False,\n",
        "                                              starcut=\"gentle\", savepath='default/ghost_stuff/',\n",
        "                                              GHOSTpath=CONSTANTS['ghost_data_loc'])\n",
        "                print('      Identified Host Galaxy:', host_data.loc[0, 'NED_name'])\n",
        "\n",
        "                # Get magnitudes from GLADE/PANSTARRS/SDSS\n",
        "                if ~np.isnan(host_data.loc[0, 'gKronMag']) and ~np.isnan(host_data.loc[0, 'iKronMag']):\n",
        "                    print('[+++] Mass taken from GLADE/PANSTARRS!')\n",
        "                    gMag, iMag, iAbsMag = (host_data['gKronMag'].loc[0], host_data['iKronMag'].loc[0],\n",
        "                                           host_data['iKronMag'].loc[0] - gen.current_cosmo().distmod(self.z).value)\n",
        "                    gMagErr, iMagErr, iAbsMagErr = (host_data['gKronMagErr'].loc[0],\n",
        "                                                    host_data['iKronMagErr'].loc[0], host_data['iKronMagErr'].loc[0])\n",
        "        except Exception as error:\n",
        "            print('Unknown GHOST error:', error)\n",
        "\n",
        "        # Try SDSS\n",
        "        if gMag == -999.00:\n",
        "            print('[!!!] GHOST failed to find mass with GLADE/PANSTARRS, attempting to use SDSS...')\n",
        "            result = SDSS.query_crossid(local_coords,\n",
        "                                        photoobj_fields=['modelMag_g', 'modelMagErr_g', 'modelMag_i', 'modelMagErr_i'])\n",
        "            if result is None:\n",
        "                print('[!!!] GLADE/PANSTARRS/SDSS failed to find mass, returning zero mass...')\n",
        "                self.params.update({'hostMass': {'value': 0.00, 'err': 0.00}})\n",
        "                with open(CONSTANTS['mass_key_txt'], 'a') as f:\n",
        "                    print('      Updating mass key with ' + self.objname + '...')\n",
        "                    f.write(self.objname + ', -999.99, -999.99\\n')\n",
        "                return\n",
        "            else:\n",
        "                print('[+++] Mass taken from SDSS!')\n",
        "                gMag, iMag, iAbsMag = (result['modelMag_g'].value[0], result['modelMag_i'].value[0],\n",
        "                                       result['modelMag_i'].value[0] - gen.current_cosmo().distmod(self.z).value)\n",
        "                gMagErr, iMagErr, iAbsMagErr = (result['modelMagErr_g'].value[0],\n",
        "                                                result['modelMagErr_i'].value[0], result['modelMagErr_i'].value[0])\n",
        "\n",
        "        # Mass Calculation -- Taylor et al. 2011 -- eq. 8\n",
        "        host_mass = (1.15 + (0.7 * (gMag - iMag)) - (0.4 * iAbsMag))\n",
        "\n",
        "        # Error Propagation\n",
        "        giMagErr = np.sqrt((gMagErr ** 2) + (iMagErr ** 2))\n",
        "        host_mass_err = np.sqrt(((0.7 ** 2) * (giMagErr ** 2)) + ((0.4 ** 2) * (iAbsMagErr ** 2)))\n",
        "\n",
        "        # Save Mass\n",
        "        self.params.update({'hostMass': {'value': host_mass, 'err': host_mass_err}})\n",
        "        print('      Success!', self.objname, 'host galaxy has a mass of:', host_mass, '+/-', host_mass_err, 'log(M_*/[M_sun])')\n",
        "\n",
        "        # Update mass key\n",
        "        if use_key:\n",
        "            with open(CONSTANTS['mass_key_txt'], 'a') as f:\n",
        "                print('      Updating mass key with ' + self.objname + '...')\n",
        "                f.write(self.objname + ', ' + str(host_mass) + ', ' + str(host_mass_err) + '\\n')\n",
        "\n",
        "        print('      Removing GHOST data...')\n",
        "        shutil.rmtree('default/ghost_stuff/')  # Clear messy data\n",
        "        os.mkdir('default/ghost_stuff/')\n",
        "        return"
      ],
      "metadata": {
        "id": "GD-hNi3k-wWs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting Functions ------------------------------------------------------------------------------------------------- #\n",
        "def norm_fit(algo='snpy', save_loc=None, dmag_max=0.00, dflux_max=0.00):\n",
        "    SNe, files = [], glob.glob('data/CSPdata/*.txt')\n",
        "    for path in files:\n",
        "        print('[', files.index(path) + 1, '/', len(files), ']')\n",
        "        print('-----------------------------------------------------------------------------------------------')\n",
        "        tempSN = SN91bg().make_class(data_set='CSP', path=path, dmag_max=dmag_max, dflux_max=dflux_max)\n",
        "        if tempSN is not None:\n",
        "            tempSN.fit(algo)\n",
        "\n",
        "        # Check if fit failed\n",
        "        if (tempSN is None or\n",
        "                tempSN.params['mu']['value'] <= 0 or\n",
        "                'hostMass' not in tempSN.params or\n",
        "                tempSN.params['hostMass']['value'] <= 0):\n",
        "            print('[-----] Failed!')\n",
        "        else:\n",
        "            print('[+++++] Success!')\n",
        "            SNe.append(tempSN)\n",
        "\n",
        "    print('Sucessfully fit [', len(SNe), '/', len(files), ']!')\n",
        "    if save_loc is not None:\n",
        "        save_params_to_file(save_loc, SNe)\n",
        "    return SNe\n",
        "def combined_fit(algo='snpy', dmag_max=0.00, dflux_max=0.00):\n",
        "    sys.stdout = open(os.devnull, 'w')  # Lots of unnecessary output\n",
        "\n",
        "    # Load and set up files\n",
        "    csp_files, atlas_files, ztf_files = glob.glob('data/CSP/*.txt'), glob.glob('data/ATLAS/*.txt'), glob.glob('data/ZTF/*.txt')\n",
        "    CSP_SNe, ATLAS_SNe, ZTF_SNe, atlas_names = {}, {}, {}, []\n",
        "    for file in csp_files:\n",
        "        tempSN = SN91bg().make_class('CSP', file, dmag_max, dflux_max)\n",
        "        if tempSN is not None:\n",
        "            CSP_SNe.update({tempSN.objname: tempSN})\n",
        "    for file in atlas_files:\n",
        "        tempSN = SN91bg().make_class('ATLAS', file, dmag_max, dflux_max)\n",
        "        if tempSN is not None:\n",
        "            ATLAS_SNe.update({tempSN.objname: tempSN})\n",
        "    for file in ztf_files:\n",
        "        tempSN = SN91bg().make_class('ZTF', file, dmag_max, dflux_max)\n",
        "        if tempSN is not None:\n",
        "            ZTF_SNe.update({tempSN.objname: tempSN})\n",
        "\n",
        "    sys.stdout = sys.__stdout__\n",
        "\n",
        "    # List of overlap\n",
        "    atlas_ztf_list = []\n",
        "    for element in list(ATLAS_SNe.keys()):\n",
        "        if element in list(ZTF_SNe.keys()):\n",
        "            atlas_ztf_list.append(element)\n",
        "\n",
        "    # List of all unique SNe\n",
        "    combined_list = np.unique(np.hstack((np.hstack((list(CSP_SNe.keys()), list(ATLAS_SNe.keys()))),\n",
        "                                         list(ZTF_SNe.keys()))))\n",
        "\n",
        "    # Combine filters and data\n",
        "    combined_SNe = []\n",
        "    for name in combined_list:\n",
        "        if name in atlas_ztf_list:\n",
        "            new_zp = np.hstack((ATLAS_SNe[name].zp, ZTF_SNe[name].zp))\n",
        "            new_filters = np.hstack((ATLAS_SNe[name].filters, ZTF_SNe[name].filters))\n",
        "            new_time = np.hstack((ATLAS_SNe[name].time, ZTF_SNe[name].time))\n",
        "            new_flux = np.hstack((ATLAS_SNe[name].flux, ZTF_SNe[name].flux))\n",
        "            new_dflux = np.hstack((ATLAS_SNe[name].dflux, ZTF_SNe[name].dflux))\n",
        "            new_mag = np.hstack((ATLAS_SNe[name].mag, ZTF_SNe[name].mag))\n",
        "            new_dmag = np.hstack((ATLAS_SNe[name].dmag, ZTF_SNe[name].dmag))\n",
        "\n",
        "            ATLAS_SNe[name].origin = 'ATLAS-ZTF'\n",
        "            ATLAS_SNe[name].zp = new_zp\n",
        "            ATLAS_SNe[name].filters = new_filters\n",
        "            ATLAS_SNe[name].time = new_time\n",
        "            ATLAS_SNe[name].flux = new_flux\n",
        "            ATLAS_SNe[name].dflux = new_dflux\n",
        "            ATLAS_SNe[name].mag = new_mag\n",
        "            ATLAS_SNe[name].dmag = new_dmag\n",
        "            combined_SNe.append(ATLAS_SNe[name])\n",
        "        elif name in list(CSP_SNe.keys()):\n",
        "            combined_SNe.append(CSP_SNe[name])\n",
        "        elif name in list(ATLAS_SNe.keys()):\n",
        "            combined_SNe.append(ATLAS_SNe[name])\n",
        "        elif name in list(ZTF_SNe.keys()):\n",
        "            combined_SNe.append(ZTF_SNe[name])\n",
        "\n",
        "    # Fitting data\n",
        "    fit_combined_SNe = []\n",
        "    for n_SN in combined_SNe:\n",
        "        print('-----------------------------------------------------------------------------------------------------')\n",
        "        print('[', combined_SNe.index(n_SN) + 1, '/', len(combined_SNe), '] Fitting data for ' + n_SN.objname + ' [' + algo + '] [' + n_SN.origin + ']...')\n",
        "        n_SN.fit(algo=algo, save_loc=CONSTANTS[algo + '_combined_saved_loc'])\n",
        "\n",
        "        # Check if fit failed\n",
        "        if (n_SN is None or\n",
        "                n_SN.params['mu']['value'] <= 0 or\n",
        "                'hostMass' not in n_SN.params or\n",
        "                n_SN.params['hostMass']['value'] <= 0):\n",
        "            print('[-----] Failed!')\n",
        "        else:\n",
        "            print('[+++++] Success!')\n",
        "            fit_combined_SNe.append(n_SN)\n",
        "\n",
        "    print('=====================================================================================================\\n',\n",
        "          'Successfully fit [', len(fit_combined_SNe), '/', len(combined_SNe), ']!\\n',\n",
        "          '=====================================================================================================\\n')\n",
        "    return fit_combined_SNe\n",
        "def batch_fit(data_set, algo='snpy', dmag_max=0.00, dflux_max=0.00):\n",
        "    SNe, files = [], glob.glob(CONSTANTS[data_set.lower()+'_data_loc'] + '*.txt')\n",
        "    for path in files:\n",
        "        print('[', files.index(path) + 1, '/', len(files), ']')\n",
        "        print('-----------------------------------------------------------------------------------------------')\n",
        "        tempSN = SN91bg().make_class(data_set=data_set, path=path, dmag_max=dmag_max, dflux_max=dflux_max)\n",
        "        if tempSN is not None:\n",
        "            tempSN.fit(algo)\n",
        "\n",
        "        # Check if fit failed\n",
        "        if (tempSN is None or\n",
        "                tempSN.params['mu']['value'] <= 0 or\n",
        "                'hostMass' not in tempSN.params or\n",
        "                tempSN.params['hostMass']['value'] <= 0):\n",
        "            print('[-----] Failed!')\n",
        "        else:\n",
        "            print('[+++++] Success!')\n",
        "            SNe.append(tempSN)\n",
        "\n",
        "    print('Sucessfully fit [', len(SNe), '/', len(files), ']!')\n",
        "    return SNe\n",
        "def batch_load(data_set, algo='snpy'):\n",
        "    SNe = []\n",
        "    for path in glob.glob('saved/' + algo + '/' + data_set.lower() + '/classes/*_class.txt'):\n",
        "        SNe.append(SN91bg().load_from_file(path))\n",
        "    return SNe\n"
      ],
      "metadata": {
        "id": "ApTd-c_r_HtX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# File Saving / Augmentation ---------------------------------------------------------------------------------------- #\n",
        "def save_params_to_file(save_loc, SNe):\n",
        "    print('[+++] Saving params to '+save_loc+'...')\n",
        "    if len(SNe) == 0:\n",
        "        print('[+++] No params to save!')\n",
        "        return\n",
        "    with open(save_loc, 'w') as f:\n",
        "        hdr = 'objname, ra, dec, z, z_cmb, MJDs, MJDe, origin'\n",
        "        for params in SNe[0].params:\n",
        "            hdr += ', ' + str(params) + ', ' + str(params) + '_err'\n",
        "        f.write(hdr + '\\n')\n",
        "        for n_SN in SNe:\n",
        "            line = (n_SN.objname + ', ' + str(n_SN.coords[0]) + ', ' + str(n_SN.coords[1]) + ', ' +\n",
        "                    str(n_SN.z) + ', ' + str(n_SN.z_cmb) + ', ' +\n",
        "                    str(n_SN.period[0]) + ', ' + str(n_SN.period[1]) + ', ' + str(n_SN.origin))\n",
        "            for param in n_SN.params:\n",
        "                line += ', ' + str(n_SN.params[param]['value']) + ', ' + str(n_SN.params[param]['err'])\n",
        "            f.write(line + '\\n')\n",
        "    return\n",
        "def sample_cutter(path, algo='snpy'):\n",
        "    data = np.genfromtxt(path, delimiter=', ', skip_header=1, dtype=str)\n",
        "    original_num = str(len(data[:, 0]))\n",
        "    if len(data) == 0:\n",
        "        print('[+++] No params to cut!')\n",
        "        return\n",
        "    with open(path, 'r') as f:\n",
        "        hdr = f.readline().split(', ')\n",
        "        hdr[-1] = hdr[-1][:-1]\n",
        "    if algo == 'snpy':\n",
        "        print('[+++] Cutting sample for SNooPy data...')\n",
        "        cuts = {'z': 0.015, 'EBVhost': (-0.2, 0.3), 'EBVhost_err': 0.1, 'st': (-999, 0.8), 'st_err': 0.1, 'Tmax_err': 1, 'mu_err': 0.2}\n",
        "        f_out = '      | '\n",
        "        for c in cuts:\n",
        "            f_out += c + ': ' + str(cuts[c]) + ' | '\n",
        "        print(f_out)\n",
        "        data = data[(data[:, hdr.index('z_cmb')].astype(float) > cuts['z']) &\n",
        "                    (data[:, hdr.index('EBVhost')].astype(float) > cuts['EBVhost'][0]) &\n",
        "                    (data[:, hdr.index('EBVhost')].astype(float) < cuts['EBVhost'][1]) &\n",
        "                    (data[:, hdr.index('EBVhost_err')].astype(float) < cuts['EBVhost_err']) &\n",
        "                    (data[:, hdr.index('st')].astype(float) > cuts['st'][0]) &\n",
        "                    (data[:, hdr.index('st')].astype(float) < cuts['st'][1]) &\n",
        "                    (data[:, hdr.index('st_err')].astype(float) < cuts['st_err']) &\n",
        "                    (data[:, hdr.index('Tmax_err')].astype(float) < cuts['Tmax_err']) &\n",
        "                    (data[:, hdr.index('mu_err')].astype(float) < cuts['mu_err'])]\n",
        "    elif algo == 'salt':\n",
        "        print('[+++] Cutting sample for SALT data...')\n",
        "        # cuts = {'z': 0.015, 'c': (-0.3, 1.0), 'c_err': 0.1, 'x1_err': 1.0, 't0_err': 1, 'mu_err': 0.2}\n",
        "        cuts = {'z': 0.015, 'c': (-0.3, 0.6), 'c_err': 0.1, 'x1_err': 0.5, 't0_err': 1, 'mu_err': 0.2}\n",
        "        f_out = '      | '\n",
        "        for c in cuts:\n",
        "            f_out += c + ': ' + str(cuts[c]) + ' | '\n",
        "        print(f_out)\n",
        "        data = data[(data[:, hdr.index('z_cmb')].astype(float) > cuts['z']) &\n",
        "                    (data[:, hdr.index('c')].astype(float) > cuts['c'][0]) &\n",
        "                    (data[:, hdr.index('c')].astype(float) < cuts['c'][1]) &\n",
        "                    (data[:, hdr.index('c_err')].astype(float) < cuts['c_err']) &\n",
        "                    (data[:, hdr.index('x1_err')].astype(float) < cuts['x1_err']) &\n",
        "                    (data[:, hdr.index('t0_err')].astype(float) < cuts['t0_err']) &\n",
        "                    (data[:, hdr.index('mu_err')].astype(float) < cuts['mu_err'])]\n",
        "\n",
        "    # Save to file\n",
        "    with open(path[:-4]+'_cut.txt', 'w') as f:\n",
        "        f_out = hdr[0]\n",
        "        for h in hdr[1:]:\n",
        "            f_out += ', ' + h\n",
        "        f.write(f_out + '\\n')\n",
        "        for line in data[:]:\n",
        "            f_out = line[0]\n",
        "            for item in line[1:]:\n",
        "                f_out += ', ' + str(item)\n",
        "            f.write(f_out + '\\n')\n",
        "    print('      Cut file saved to...', path[:-4]+'_cut.txt')\n",
        "    print('      [ '+str(len(data[:, 0]))+' / '+original_num+' ]')\n",
        "\n",
        "    # Display Residual Scatter\n",
        "    resid_scatter = sigma_clipped_stats(data[:, hdr.index('mu')].astype(float) -\n",
        "                                   gen.current_cosmo().distmod(data[:, hdr.index('z_cmb')].astype(float)).value)[2]\n",
        "    print('Hubble Residual Scatter:', resid_scatter)\n",
        "\n",
        "    return\n",
        "def merge_snpy_salt_params(snpy_path, salt_path, save_loc):\n",
        "    snpy_data = np.genfromtxt(snpy_path, delimiter=', ', skip_header=1, dtype=str)\n",
        "    salt_data = np.genfromtxt(salt_path, delimiter=', ', skip_header=1, dtype=str)\n",
        "\n",
        "    with open(snpy_path, 'r') as f:\n",
        "        hdr_snpy = f.readline().split(', ')\n",
        "        hdr_snpy[-1] = hdr_snpy[-1][:-1]\n",
        "    with open(salt_path, 'r') as f:\n",
        "        hdr_salt = f.readline().split(', ')\n",
        "        hdr_salt[-1] = hdr_salt[-1][:-1]\n",
        "\n",
        "    source, n = ['snpy', 'salt'], 0\n",
        "    names = []\n",
        "    with open(save_loc, 'w') as f:\n",
        "        print('objname, z_cmb, origin, mu, mu_err, hostMass, hostMass_err', file=f)\n",
        "        for data in [snpy_data, salt_data]:\n",
        "            for i in range(len(data[:, 0])):\n",
        "                if data[i, 0] not in names:\n",
        "                    if source[n] == 'snpy':\n",
        "                        print(data[i, hdr_snpy.index('objname')] + ',',\n",
        "                              data[i, hdr_snpy.index('z_cmb')] + ',',\n",
        "                              data[i, hdr_snpy.index('origin')] + '_' + source[n].upper() + ',',\n",
        "                              data[i, hdr_snpy.index('mu')] + ',',\n",
        "                              data[i, hdr_snpy.index('mu_err')] + ',',\n",
        "                              data[i, hdr_snpy.index('hostMass')] + ',',\n",
        "                              data[i, hdr_snpy.index('hostMass_err')],\n",
        "                              file=f)\n",
        "                    elif source[n] == 'salt':\n",
        "                        print(data[i, hdr_salt.index('objname')] + ',',\n",
        "                              data[i, hdr_salt.index('z_cmb')] + ',',\n",
        "                              data[i, hdr_salt.index('origin')] + '_' + source[n].upper() + ',',\n",
        "                              data[i, hdr_salt.index('mu')] + ',',\n",
        "                              data[i, hdr_salt.index('mu_err')] + ',',\n",
        "                              data[i, hdr_salt.index('hostMass')] + ',',\n",
        "                              data[i, hdr_salt.index('hostMass_err')],\n",
        "                              file=f)\n",
        "                    names.append(data[i, 0])\n",
        "            n += 1\n",
        "    print('Final number of objects:', len(names),\n",
        "          '[snpy: '+str(len(snpy_data[:, 0]))+']',\n",
        "          '[salt: '+str(len(salt_data[:, 0]))+']')\n",
        "    print('Saved merged param file to... ', save_loc)\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "DmQl5NPH-qRG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Functions ------------------------------------------------------------------------------------------------ #\n",
        "def resid_v_z(path, title='', save_loc=None):\n",
        "    color_wheel = {'ZTF': '#D8973C', 'ATLAS': '#BD632F', 'CSP': '#72513B', 'ATLAS-ZTF': '#273E47',\n",
        "                   'ZTF_SNPY': '#D8973C', 'ATLAS_SNPY': '#BD632F', 'CSP_SNPY': '#72513B', 'ATLAS-ZTF_SNPY': '#273E47',\n",
        "                   'ZTF_SALT': '#D8973C', 'ATLAS_SALT': '#BD632F', 'CSP_SALT': '#72513B', 'ATLAS-ZTF_SALT': '#273E47',\n",
        "                   'Pan+': 'BD632F', 'Histogram': '#3B5058',\n",
        "                   '10dexfill': '#A4243B', 'mediandexfill': '#D8C99B'}\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15, 6), gridspec_kw={'width_ratios': [10, 1]}, constrained_layout=True)\n",
        "\n",
        "    # Pull data from saved text & header\n",
        "    data = np.genfromtxt(path, delimiter=', ', skip_header=1, dtype=str)\n",
        "    with open(path, 'r') as f:\n",
        "        hdr = f.readline().split(', ')\n",
        "        hdr[-1] = hdr[-1][:-1]\n",
        "\n",
        "    # Set Arrays\n",
        "    z = data[:, hdr.index('z_cmb')].astype(float)\n",
        "    mass, mass_err = data[:, hdr.index('hostMass')].astype(float), data[:, hdr.index('hostMass_err')].astype(float)\n",
        "    mu, mu_err = data[:, hdr.index('mu')].astype(float), data[:, hdr.index('mu_err')].astype(float)\n",
        "    resid_mu, resid_mu_err = sigma_clip(mu - gen.current_cosmo().distmod(z).value, sigma=3.0), np.copy(mu_err)\n",
        "\n",
        "    # Make main plot\n",
        "    for origin in np.unique(data[:, hdr.index('origin')]):\n",
        "        format_dict = {'marker': 'o', 'fmt': 'o', 'label': origin, 'alpha': 1, 'ms': 6}\n",
        "        if 'SNPY' in origin:\n",
        "            format_dict['label'] = origin[:-5]\n",
        "        elif 'SALT' in origin:\n",
        "            format_dict['label'], format_dict['marker'] = None, '^'\n",
        "\n",
        "        indexes = np.where(data[:, hdr.index('origin')] == origin)[0]\n",
        "        axs[0].errorbar(z[indexes], resid_mu[indexes], yerr=resid_mu_err[indexes],\n",
        "                        color=color_wheel[origin], elinewidth=0.8, **format_dict)\n",
        "\n",
        "    # Make histogram\n",
        "    axs[1].hist(resid_mu, bins=int((np.max(resid_mu) - np.min(resid_mu)) / 0.1),  # Bin Width = 0.1\n",
        "                orientation=\"horizontal\", color=color_wheel['Histogram'])\n",
        "\n",
        "    # Extra Info\n",
        "    extra_info = '$\\sigma$: '+str(round(np.std(resid_mu), 4)) + ', $n$: ' + str(len(resid_mu))\n",
        "    if 'merged' in path:\n",
        "        extra_info += r' | SALT3: $\\triangle$, SNooPy: $\\bigcirc$'\n",
        "    axs[0].text(np.min(z), np.max(resid_mu),\n",
        "                extra_info,\n",
        "                horizontalalignment='left', verticalalignment='bottom')\n",
        "\n",
        "    # Formatting\n",
        "    fig.suptitle(title)\n",
        "    axs[0].set(xlabel='Host Galaxy CMB Redshift', ylabel='Hubble Residuals (mag)')  # Sub-plot Labels\n",
        "    axs[1].get_yaxis().set_visible(False)  # Turn off y-axis labels\n",
        "    axs[0].legend(loc='best')\n",
        "\n",
        "    # Saving Figure\n",
        "    if save_loc is not None:\n",
        "        print('Saved figure to... ', save_loc)\n",
        "        plt.savefig(save_loc)\n",
        "    plt.show()\n",
        "    return\n",
        "def resid_v_mass(path, cut=10, title='', labels=False, save_loc=None):\n",
        "    # Pull data from saved text\n",
        "    data = np.genfromtxt(path, delimiter=', ', skip_header=1, dtype=str)\n",
        "\n",
        "    # Get header\n",
        "    with open(path, 'r') as f:\n",
        "        hdr = f.readline().split(', ')\n",
        "        hdr[-1] = hdr[-1][:-1]\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 6), gridspec_kw={'width_ratios': [10, 1]}, constrained_layout=True)\n",
        "    color_wheel = {'ZTF': '#81ADC8', 'ATLAS': '#EEDFAA', 'CSP': '#CD4631', 'ATLAS-ZTF': '#DEA47E',\n",
        "                   'ZTF_SNPY': '#dcb160', 'ATLAS_SNPY': '#f4ac45', 'CSP_SNPY': '#af7b3f', 'ATLAS-ZTF_SNPY': '#694a38',\n",
        "                   'ZTF_SALT': '#dcb160', 'ATLAS_SALT': '#f4ac45', 'CSP_SALT': '#af7b3f', 'ATLAS-ZTF_SALT': '#694a38',\n",
        "                   'Pan+': 'maroon', 'Histogram': '#775A4A'}\n",
        "\n",
        "    # Set Arrays\n",
        "    mass, mass_err = data[:, hdr.index('hostMass')].astype(float), data[:, hdr.index('hostMass_err')].astype(float)\n",
        "    mu, mu_err = data[:, hdr.index('mu')].astype(float), data[:, hdr.index('mu_err')].astype(float)\n",
        "    z = data[:, hdr.index('z_cmb')].astype(float)\n",
        "    resid_mu = sigma_clip(mu - gen.current_cosmo().distmod(z).value, sigma=3.0)\n",
        "    resid_mu_err = np.copy(mu_err)\n",
        "\n",
        "    # Make main plot\n",
        "    for origin in np.unique(data[:, hdr.index('origin')]):\n",
        "        if 'SALT' in origin:\n",
        "            mk = 'x'\n",
        "        else:\n",
        "            mk = 'o'\n",
        "        indexes = np.where(data[:, hdr.index('origin')] == origin)[0]\n",
        "\n",
        "        axs[0].errorbar(mass[indexes], resid_mu[indexes], xerr=mass_err[indexes], yerr=resid_mu_err[indexes],\n",
        "                        color=color_wheel[origin], fmt='o', label=origin, alpha=1, marker=mk)\n",
        "\n",
        "        # Labels\n",
        "        if labels:\n",
        "            for i in range(len(resid_mu[indexes])):\n",
        "                axs[0].text(mass[indexes][i], resid_mu[indexes][i], str(data[:, 0][indexes][i]), size='x-small', va='top')\n",
        "\n",
        "    # Make histogram\n",
        "    axs[1].hist(resid_mu, bins=30, orientation=\"horizontal\", color=color_wheel['Histogram'])\n",
        "\n",
        "    # Get Mass Step\n",
        "    if cut == 'median':\n",
        "        cut = round(np.median(mass), 4)\n",
        "    mass_step_dict, resid_dict = mass_step_calc(mu, mu_err, mass, z, cut=cut)\n",
        "\n",
        "    # Plot Mass Step\n",
        "    plt_details = {'linestyle': '--', 'linewidth': 1.5, 'color': 'k'}\n",
        "    fill_details = {'color': 'k', 'alpha': 0.2}\n",
        "    axs[0].hlines(y=resid_dict['lower_resid']['value'], xmin=np.min(mass)-0.3, xmax=cut, **plt_details)  # Left\n",
        "    axs[0].hlines(y=resid_dict['upper_resid']['value'], xmin=cut, xmax=np.max(mass)+0.3, **plt_details)  # Right\n",
        "    axs[0].fill_between([np.min(mass)-0.3, cut], resid_dict['lower_resid']['value'] - resid_dict['lower_resid']['err'],\n",
        "                        resid_dict['lower_resid']['value'] + resid_dict['lower_resid']['err'], **fill_details)  # Left\n",
        "    axs[0].fill_between([cut, np.max(mass)+0.3], resid_dict['upper_resid']['value'] - resid_dict['upper_resid']['err'],\n",
        "                        resid_dict['upper_resid']['value'] + resid_dict['upper_resid']['err'], **fill_details)  # Right\n",
        "    axs[0].vlines(x=cut, ymin=resid_dict['lower_resid']['value'], ymax=resid_dict['upper_resid']['value'], **plt_details)\n",
        "\n",
        "    # Formatting\n",
        "    fig.suptitle(title +\n",
        "                 'Scatter: ' + str(round(sigma_clipped_stats(resid_mu)[2], 2)) + ' | # of pts: ' + str(len(resid_mu)) +\n",
        "                 ' | SNR: ' + str(round(np.sqrt(np.abs(np.average(resid_mu)) / np.abs(np.std(resid_mu_err))), 2)) +\n",
        "                 '\\nMass Step ('+str(cut)+'): ' + str(round(mass_step_dict['value'], 4)) + ' +/- ' + str(round(mass_step_dict['err'], 6)),\n",
        "                 size='medium')\n",
        "    ylimiter, xlimiter = np.max(np.abs(resid_mu)) + 0.3, [np.min(mass)-0.3, np.max(mass)+0.3]\n",
        "    axs[0].set_ylim(-ylimiter, ylimiter)\n",
        "    axs[1].set_ylim(-ylimiter, ylimiter)\n",
        "    axs[0].set_xlim(xlimiter[0], xlimiter[1])\n",
        "    axs[0].set(xlabel=\"Host Stellar Mass (log $M_{*}$/$[M_{\\odot}]$)\", ylabel='Hubble Residuals (mag)')  # Sub-plot Labels\n",
        "    # axs[0].set_ylim(-1.4, 1.4); axs[0].set_xlim(7.5, 13.0)\n",
        "    axs[1].get_yaxis().set_visible(False)  # Turn off y-axis labels\n",
        "    axs[0].legend(loc='best')\n",
        "\n",
        "    # Saving Figure\n",
        "    if save_loc is not None:\n",
        "        print('Saved figure to... ', save_loc)\n",
        "        plt.savefig(save_loc)\n",
        "    plt.show()\n",
        "    return\n",
        "def resid_v_mass_med(path, title='', save_loc=None):\n",
        "    color_wheel = {'ZTF': '#D8973C', 'ATLAS': '#BD632F', 'CSP': '#72513B', 'ATLAS-ZTF': '#273E47',\n",
        "                   'ZTF_SNPY': '#D8973C', 'ATLAS_SNPY': '#BD632F', 'CSP_SNPY': '#72513B', 'ATLAS-ZTF_SNPY': '#273E47',\n",
        "                   'ZTF_SALT': '#D8973C', 'ATLAS_SALT': '#BD632F', 'CSP_SALT': '#72513B', 'ATLAS-ZTF_SALT': '#273E47',\n",
        "                   'Pan+': 'BD632F', 'Histogram': '#3B5058',\n",
        "                   '10dexfill': '#A4243B', 'mediandexfill': '#D8C99B'}\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15, 6), gridspec_kw={'width_ratios': [10, 1]}, constrained_layout=True)\n",
        "\n",
        "    # Pull data from saved text & header\n",
        "    data = np.genfromtxt(path, delimiter=', ', skip_header=1, dtype=str)\n",
        "    with open(path, 'r') as f:\n",
        "        hdr = f.readline().split(', ')\n",
        "        hdr[-1] = hdr[-1][:-1]\n",
        "\n",
        "    # Set Arrays\n",
        "    z = data[:, hdr.index('z_cmb')].astype(float)\n",
        "    mass, mass_err = data[:, hdr.index('hostMass')].astype(float), data[:, hdr.index('hostMass_err')].astype(float)\n",
        "    mu, mu_err = data[:, hdr.index('mu')].astype(float), data[:, hdr.index('mu_err')].astype(float)\n",
        "    resid_mu, resid_mu_err = sigma_clip(mu - gen.current_cosmo().distmod(z).value, sigma=3.0), np.copy(mu_err)\n",
        "    origins = data[:, hdr.index('origin')]\n",
        "\n",
        "    # David Adjustments for Outliers\n",
        "    mn,_,std = sigma_clipped_stats(mu - gen.current_cosmo().distmod(z).value,sigma=3.0)\n",
        "    iGood = abs(mu - gen.current_cosmo().distmod(z).value - mn) < 3.0*std\n",
        "    mu,mu_err,z,resid_mu,resid_mu_err,mass,mass_err,origins = (\n",
        "        mu[iGood],mu_err[iGood],z[iGood],resid_mu[iGood],resid_mu_err[iGood],mass[iGood],mass_err[iGood],origins[iGood])\n",
        "\n",
        "    # intrinsic dispersion added in quadrature\n",
        "    mu_err = np.sqrt(mu_err ** 2.0 + 0.1 ** 2.0)\n",
        "\n",
        "    # Make main plot\n",
        "    for origin in np.unique(origins):\n",
        "        format_dict = {'marker': 'o', 'fmt': 'o', 'label': origin, 'alpha': 1, 'ms': 6}\n",
        "        if 'SNPY' in origin:\n",
        "            format_dict['label'] = origin[:-5]\n",
        "        elif 'SALT' in origin:\n",
        "            format_dict['label'], format_dict['marker'] = None, '^'\n",
        "\n",
        "        indexes = np.where(origins == origin)[0]\n",
        "        axs[0].errorbar(mass[indexes], resid_mu[indexes], xerr=mass_err[indexes], yerr=resid_mu_err[indexes],\n",
        "                        color=color_wheel[origin], elinewidth=0.8, **format_dict)\n",
        "\n",
        "    # Make histogram\n",
        "    axs[1].hist(resid_mu, bins=int((np.max(resid_mu) - np.min(resid_mu)) / 0.1),  # Bin Width = 0.1\n",
        "                orientation=\"horizontal\", color=color_wheel['Histogram'])\n",
        "\n",
        "    # Extra Info\n",
        "    extra_info = '$\\sigma$: '+str(round(np.std(resid_mu), 4)) + ', $n$: ' + str(len(resid_mu))\n",
        "    if 'merged' in path:\n",
        "        extra_info += r' | SALT3: $\\triangle$, SNooPy: $\\bigcirc$'\n",
        "    axs[0].text(np.min(mass), np.max(resid_mu),\n",
        "                extra_info,\n",
        "                horizontalalignment='left', verticalalignment='bottom')\n",
        "\n",
        "    # Display Both Mass Steps\n",
        "    for cut in [10, 'median']:\n",
        "        num_cut, lin_color = cut, color_wheel['10dexfill']\n",
        "        if cut == 'median':\n",
        "            num_cut, lin_color = round(np.median(mass), 4), color_wheel['mediandexfill']\n",
        "\n",
        "        # Get Mass Step\n",
        "        mass_step_dict, resid_dict = mass_step_calc(mu, mu_err, mass, z, cut=num_cut)\n",
        "\n",
        "        # Plot Mass Step\n",
        "        lin_details = {'linestyle': '--', 'linewidth': 1.0, 'color': lin_color}\n",
        "        fill_details = {'color': lin_color, 'alpha': 0.2}\n",
        "        axs[0].vlines(x=num_cut, ymin=resid_dict['lower_resid']['value'], ymax=resid_dict['upper_resid']['value'],\n",
        "                      **lin_details)\n",
        "        axs[0].hlines(y=resid_dict['lower_resid']['value'], xmin=np.min(mass) - 0.3, xmax=num_cut,\n",
        "                      **lin_details)  # Left\n",
        "        axs[0].fill_between([np.min(mass) - 0.3, num_cut],\n",
        "                            resid_dict['lower_resid']['value'] - resid_dict['lower_resid']['err'],\n",
        "                            resid_dict['lower_resid']['value'] + resid_dict['lower_resid']['err'],\n",
        "                            **fill_details)\n",
        "        axs[0].hlines(y=resid_dict['upper_resid']['value'], xmin=num_cut, xmax=np.max(mass) + 0.3,\n",
        "                      **lin_details)  # Right\n",
        "        axs[0].fill_between([num_cut, np.max(mass) + 0.3],\n",
        "                            resid_dict['upper_resid']['value'] - resid_dict['upper_resid']['err'],\n",
        "                            resid_dict['upper_resid']['value'] + resid_dict['upper_resid']['err'],\n",
        "                            label=str(cut) + ': ' +\n",
        "                                  str(round(mass_step_dict['value'], 4)) + ' +/- ' +\n",
        "                                  str(round(mass_step_dict['err'], 4)),\n",
        "                            **fill_details)  # Right\n",
        "\n",
        "    # Formatting\n",
        "    fig.suptitle(title)\n",
        "    axs[0].set(xlabel=\"Host Stellar Mass (log $M_{*}$/$[M_{\\odot}]$)\",\n",
        "               ylabel='Hubble Residuals (mag)')  # Sub-plot Labels\n",
        "    axs[1].get_yaxis().set_visible(False)  # Turn off y-axis labels\n",
        "    axs[0].legend(loc='best')\n",
        "\n",
        "    # Saving Figure\n",
        "    if save_loc is not None:\n",
        "        print('Saved figure to... ', save_loc)\n",
        "        plt.savefig(save_loc)\n",
        "    plt.show()\n",
        "    return\n",
        "def resid_v_mass_stacked():\n",
        "\n",
        "    n = 0\n",
        "    subplot_titles = ['Merged', 'SNooPy Only', 'SALT3 Only']\n",
        "    fig, axs = plt.subplots(3, 2, figsize=(12, 6), gridspec_kw={'width_ratios': [10, 1]}, constrained_layout=True)\n",
        "    for path in ['output/combiend__snpy_params_cut.txt', 'output/combiend__snpy_params_cut.txt', 'output/combiend__salt_params_cut.txt']:\n",
        "        # Pull data from saved text\n",
        "        data = np.genfromtxt(path, delimiter=', ', skip_header=1, dtype=str)\n",
        "\n",
        "        # Get header\n",
        "        with open(path, 'r') as f:\n",
        "            hdr = f.readline().split(', ')\n",
        "            hdr[-1] = hdr[-1][:-1]\n",
        "\n",
        "        color_wheel = {'ZTF': '#81ADC8', 'ATLAS': '#EEDFAA', 'CSP': '#CD4631', 'ATLAS-ZTF': '#DEA47E',\n",
        "                       'ZTF_SNPY': '#dcb160', 'ATLAS_SNPY': '#f4ac45', 'CSP_SNPY': '#af7b3f',\n",
        "                       'ATLAS-ZTF_SNPY': '#694a38',\n",
        "                       'ZTF_SALT': '#dcb160', 'ATLAS_SALT': '#f4ac45', 'CSP_SALT': '#af7b3f',\n",
        "                       'ATLAS-ZTF_SALT': '#694a38',\n",
        "                       'Pan+': 'maroon', 'Histogram': '#775A4A'}\n",
        "\n",
        "        # Set Arrays\n",
        "        z = data[:, hdr.index('z_cmb')].astype(float)\n",
        "        mass, mass_err = data[:, hdr.index('hostMass')].astype(float), data[:, hdr.index('hostMass_err')].astype(float)\n",
        "        mu, mu_err = data[:, hdr.index('mu')].astype(float), data[:, hdr.index('mu_err')].astype(float)\n",
        "        resid_mu, resid_mu_err = sigma_clip(mu - gen.current_cosmo().distmod(z).value, sigma=3.0), np.copy(mu_err)\n",
        "\n",
        "        # Make main plot\n",
        "        for origin in np.unique(data[:, hdr.index('origin')]):\n",
        "            if 'SALT' in origin:\n",
        "                format_dict = {'marker': '^', 'fmt': 'o', 'label': None, 'alpha': 1, 'ms': 6}\n",
        "            else:\n",
        "                format_dict = {'marker': 'o', 'fmt': 'o', 'label': origin[:5], 'alpha': 1, 'ms': 5}\n",
        "            indexes = np.where(data[:, hdr.index('origin')] == origin)[0]\n",
        "            axs[n, 0].errorbar(mass[indexes], resid_mu[indexes], xerr=mass_err[indexes], yerr=resid_mu_err[indexes],\n",
        "                            color=color_wheel[origin], **format_dict)\n",
        "\n",
        "        # Make histogram\n",
        "        axs[n, 1].hist(resid_mu, bins=10, orientation=\"horizontal\", color=color_wheel['Histogram'])\n",
        "\n",
        "        # Get Mass Step\n",
        "        for cut in [10, 'median']:\n",
        "            if cut == 'median':\n",
        "                num_cut = round(np.median(mass), 4)\n",
        "                lin_color, label = 'r', str(cut)\n",
        "            else:\n",
        "                num_cut = cut\n",
        "                lin_color = 'k'\n",
        "\n",
        "            mass_step_dict, resid_dict = mass_step_calc(mu, mu_err, mass, z, cut=num_cut)\n",
        "\n",
        "            # Plot Mass Step\n",
        "            plt_details = {'linestyle': '--', 'linewidth': 1.0, 'color': lin_color}\n",
        "            fill_details = {'color': lin_color, 'alpha': 0.2}\n",
        "            axs[n, 0].hlines(y=resid_dict['lower_resid']['value'], xmin=np.min(mass) - 0.3, xmax=num_cut,\n",
        "                          **plt_details)  # Left\n",
        "            axs[n, 0].hlines(y=resid_dict['upper_resid']['value'], xmin=num_cut, xmax=np.max(mass) + 0.3,\n",
        "                          **plt_details)  # Right\n",
        "            axs[n, 0].fill_between([np.min(mass) - 0.3, num_cut],\n",
        "                                resid_dict['lower_resid']['value'] - resid_dict['lower_resid']['err'],\n",
        "                                resid_dict['lower_resid']['value'] + resid_dict['lower_resid']['err'],\n",
        "                                **fill_details)  # Left\n",
        "            axs[n, 0].fill_between([num_cut, np.max(mass) + 0.3],\n",
        "                                resid_dict['upper_resid']['value'] - resid_dict['upper_resid']['err'],\n",
        "                                resid_dict['upper_resid']['value'] + resid_dict['upper_resid']['err'],\n",
        "                                **fill_details)  # Right\n",
        "            axs[n, 0].vlines(x=num_cut, ymin=resid_dict['lower_resid']['value'], ymax=resid_dict['upper_resid']['value'],\n",
        "                             **plt_details)\n",
        "\n",
        "        # Formatting\n",
        "        axs[n, 0].set_title(subplot_titles[n] + '\\n' +\n",
        "                            'Scatter: ' + str(round(np.std(resid_mu), 2)) + ' | # of pts: ' + str(len(resid_mu))+ '\\n'+str(cut))\n",
        "        axs[n, 0].get_xaxis().set_visible(False);\n",
        "        axs[n, 1].get_xaxis().set_visible(False)\n",
        "        axs[n, 1].get_yaxis().set_visible(False)\n",
        "\n",
        "        n += 1\n",
        "\n",
        "    # Formatting\n",
        "    axs[2, 0].get_xaxis().set_visible(True); axs[2, 1].get_xaxis().set_visible(True)\n",
        "    # ylimiter, xlimiter = np.max(np.abs(resid_mu)) + 0.3, [np.min(mass) - 0.3, np.max(mass) + 0.3]\n",
        "    # axs[0].set(xlabel=\"Host Stellar Mass (log $M_{*}$/$[M_{\\odot}]$)\",ylabel='Hubble Residuals (mag)')  # Sub-plot Labels\n",
        "    # axs[1].get_yaxis().set_visible(False)  # Turn off y-axis labels\n",
        "    axs[2, 0].legend(loc='best')\n",
        "\n",
        "    # Saving Figure\n",
        "    save_loc=None\n",
        "    if save_loc is not None:\n",
        "        print('Saved figure to... ', save_loc)\n",
        "        plt.savefig(save_loc)\n",
        "    plt.show()\n",
        "\n",
        "    return\n",
        "def norm_vs_91bg_hist(param, width=None):\n",
        "    snenormIa = np.genfromtxt('txts/HiCAT_DR3_params.txt', delimiter=', ', skip_header=1, dtype=str)\n",
        "    sne91bg = np.genfromtxt('output/combiend__snpy_params.txt', delimiter=', ', skip_header=1, dtype=str)\n",
        "    snenormIa_hdr = ('objname, ra, dec, z, z_cmb, MJDs, MJDe, origin, mu, mu_err, st, st_err, Tmax, Tmax_err, EBVhost, '\n",
        "                     'EBVhost_err, hostMass, hostMass_err').split(', ')\n",
        "    sne91bg_hdr = ('objname, ra, dec, z, z_cmb, MJDs, MJDe, origin, mu, mu_err, st, st_err, Tmax, Tmax_err, EBVhost, '\n",
        "                   'EBVhost_err, hostMass, hostMass_err').split(', ')\n",
        "\n",
        "    set1 = sigma_clip(snenormIa[:, snenormIa_hdr.index(param)].astype(float), sigma=3.0)\n",
        "    set2 = sigma_clip(sne91bg[:, sne91bg_hdr.index(param)].astype(float), sigma=3.0)\n",
        "    if width is None:\n",
        "        width = np.min([np.std(set1), np.std(set2)])\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.hist(set1, color='#62BEC1', label='Normal SNe', alpha=1, bins=int((np.max(set1) - np.min(set1)) / width))\n",
        "    plt.hist(set2, color='#5AD2F4', label='91bg-like', alpha=0.825, bins=int((np.max(set2) - np.min(set2)) / width))\n",
        "\n",
        "    # Data Lines\n",
        "    plt.axvline(x=np.median(set1), label='Normal SNe Median', linewidth=2.5, color='#52a1a3', linestyle=':')\n",
        "    plt.axvline(x=np.median(set2), label='91bg-like Median', linewidth=2.5, color='#4bb0cc', linestyle='--')\n",
        "\n",
        "    # Formatting\n",
        "    plt.title('Normal SNeIa v. 91bg-like SNeIa -- '+param)\n",
        "    plt.legend()\n",
        "\n",
        "    # Save Plot\n",
        "    # plt.savefig('saved/HiCATvPan+_'+title.split(' ')[4].lower()+'.png')\n",
        "    # print('Saved to...', 'saved/HiCATvPan+_'+title.split(' ')[4].lower()+'.png')\n",
        "\n",
        "    plt.show()\n",
        "    return\n",
        "def snpy_hist(hicat_params_file, norm_params_file, save_loc='', sigma = 3.0, st_width = 0.02, c_width = 0.02):\n",
        "    # Open data\n",
        "    hicat_data = np.genfromtxt(hicat_params_file, delimiter=', ', skip_header=1, dtype=str)\n",
        "    with open(hicat_params_file, 'r') as f:\n",
        "        hicat_hdr = f.readline().split(', ')\n",
        "        hicat_hdr[-1] = hicat_hdr[-1][:-1]\n",
        "    dr3_data = np.genfromtxt(norm_params_file, delimiter=', ', skip_header=1, dtype=str)\n",
        "    with open(norm_params_file, 'r') as f:\n",
        "        dr3_hdr = f.readline().split(', ')\n",
        "        dr3_hdr[-1] = dr3_hdr[-1][:-1]\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(14, 4), constrained_layout=True)\n",
        "    # ST plot\n",
        "    set1 = sigma_clip(dr3_data[:, dr3_hdr.index('st')].astype(float), sigma=sigma)\n",
        "    ax[0].hist(set1, int((np.max(set1) - np.min(set1)) / st_width), label='DR3', color='#5AD2F4')\n",
        "    ax[0].axvline(x=np.median(set1), label=r'$\\tilde{x}_{DR3}$ = '+str(round(np.median(set1),2)),\n",
        "                  linewidth=2.5, color='#4bb0cc', linestyle='--')\n",
        "    set2 = sigma_clip(hicat_data[:, hicat_hdr.index('st')].astype(float), sigma=sigma)\n",
        "    ax[0].hist(set2, int((np.max(set2) - np.min(set2)) / st_width), label='HiCAT', color='#62BEC1', alpha=0.75)\n",
        "    ax[0].axvline(x=np.median(set2), label=r'$\\tilde{x}_{HiCAT}$ = '+str(round(np.median(set2),2)),\n",
        "                  linewidth=2.5, color='#52a1a3', linestyle=':')\n",
        "    ax[0].legend()\n",
        "    ax[0].set_title('Stretch [st]')\n",
        "\n",
        "    # EBVhost plot\n",
        "    set1 = sigma_clip(dr3_data[:, dr3_hdr.index('EBVhost')].astype(float), sigma=sigma)\n",
        "    ax[1].hist(set1, int((np.max(set1) - np.min(set1)) / c_width), label='DR3', color='#5AD2F4')\n",
        "    ax[1].axvline(x=np.median(set1), label=r'$\\tilde{x}_{DR3}$ = '+str(round(np.median(set1),2)),\n",
        "                  linewidth=2.5, color='#4bb0cc', linestyle='--')\n",
        "    set2 = sigma_clip(hicat_data[:, hicat_hdr.index('EBVhost')].astype(float), sigma=sigma)\n",
        "    ax[1].hist(set2, int((np.max(set2) - np.min(set2)) / c_width), label='HiCAT', color='#62BEC1', alpha=0.75)\n",
        "    ax[1].axvline(x=np.median(set2), label=r'$\\tilde{x}_{HiCAT}$ = '+str(round(np.median(set2),2)),\n",
        "                  linewidth=2.5, color='#52a1a3', linestyle=':')\n",
        "    ax[1].legend()\n",
        "    ax[1].set_title('Color [E(B-V) Host]')\n",
        "    # ax[1].set_xlim(-0.05, 0.45)\n",
        "    # ax[1].invert_xaxis()\n",
        "\n",
        "    # plt.suptitle('HiCAT 91bg-like Type Ia SNe v. DR3 Normal Type Ia SNe\\n SNooPy paramaters')\n",
        "    if len(save_loc) > 0:\n",
        "        plt.savefig(save_loc, dpi=300)\n",
        "    plt.show()\n",
        "    return\n",
        "def salt_hist(hicat_params_file, norm_params_file, save_loc='', sigma = 3.0, st_width = 0.3, c_width = 0.08):\n",
        "    # Open data\n",
        "    hicat_data = np.genfromtxt(hicat_params_file, delimiter=', ', skip_header=1, dtype=str)\n",
        "    with open(hicat_params_file, 'r') as f:\n",
        "        hicat_hdr = f.readline().split(', ')\n",
        "        hicat_hdr[-1] = hicat_hdr[-1][:-1]\n",
        "    dr3_data = np.genfromtxt(norm_params_file, delimiter=', ', skip_header=1, dtype=str)\n",
        "    with open(norm_params_file, 'r') as f:\n",
        "        dr3_hdr = f.readline().split(', ')\n",
        "        dr3_hdr[-1] = dr3_hdr[-1][:-1]\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(14, 4), constrained_layout=True)\n",
        "\n",
        "    # x1 plot\n",
        "    set1 = sigma_clip(dr3_data[:, dr3_hdr.index('x1')].astype(float), sigma=sigma)\n",
        "    set2 = sigma_clip(hicat_data[:, hicat_hdr.index('x1')].astype(float), sigma=sigma)\n",
        "    ax[0].hist(set1, int((np.max(set1) - np.min(set1)) / st_width), label='DR3', color='#5AD2F4')\n",
        "    ax[0].hist(set2, int((np.max(set2) - np.min(set2)) / st_width), label='HiCAT', color='#62BEC1', alpha=0.75)\n",
        "    ax[0].axvline(x=np.median(set1), label=r'$\\tilde{x}_{DR3}$ = '+str(round(np.median(set1),2)),\n",
        "                  linewidth=2.5, color='#4bb0cc', linestyle='--')\n",
        "    ax[0].axvline(x=np.median(set2), label=r'$\\tilde{x}_{HiCAT}$ = '+str(round(np.median(set2),2)),\n",
        "                  linewidth=2.5, color='#52a1a3', linestyle=':')\n",
        "    ax[0].legend()\n",
        "    ax[0].set_title('Stretch [x1]')\n",
        "\n",
        "    # c plot\n",
        "    set1 = sigma_clip(dr3_data[:, dr3_hdr.index('c')].astype(float), sigma=sigma)\n",
        "    set2 = sigma_clip(hicat_data[:, hicat_hdr.index('c')].astype(float), sigma=sigma)\n",
        "    ax[1].hist(set1, int((np.max(set1) - np.min(set1)) / c_width), label='DR3', color='#5AD2F4')\n",
        "    ax[1].hist(set2, int((np.max(set2) - np.min(set2)) / c_width), label='HiCAT', color='#62BEC1', alpha=0.75)\n",
        "    ax[1].axvline(x=np.median(set1), label=r'$\\tilde{x}_{DR3}$ = '+str(round(np.median(set1),2)),\n",
        "                  linewidth=2.5, color='#4bb0cc', linestyle='--')\n",
        "    ax[1].axvline(x=np.median(set2), label=r'$\\tilde{x}_{HiCAT}$ = '+str(round(np.median(set2),2)),\n",
        "                  linewidth=2.5, color='#52a1a3', linestyle=':')\n",
        "    ax[1].legend()\n",
        "    ax[1].set_title('Color [c]')\n",
        "\n",
        "    # plt.suptitle('HiCAT 91bg-like Type Ia SNe v. DR3 Normal Type Ia SNe\\n SALT paramaters')\n",
        "    if len(save_loc) > 0:\n",
        "        print('[+++] Saved figure to...', save_loc)\n",
        "        plt.savefig(save_loc, dpi=300)\n",
        "    plt.show()\n",
        "    return\n",
        "def update_readme_plots():\n",
        "    # Update Mass Plots\n",
        "    resid_v_mass_med(path='output/combiend__snpy_params_cut.txt',\n",
        "                     title='Hubble Residual v. Host Stellar Mass of CSP-ATLAS-ZTF 91bg-like SNe Ia [SNooPy]',\n",
        "                     save_loc='saved/readme_plots/csp-atlas-ztf_snpy_resid_v_mass.png')\n",
        "    resid_v_mass_med(path='output/combiend__salt_params_cut.txt',\n",
        "                     title='Hubble Residual v. Host Stellar Mass of CSP-ATLAS-ZTF 91bg-like SNe Ia [SALT3]',\n",
        "                     save_loc='saved/readme_plots/csp-atlas-ztf_salt_resid_v_mass.png')\n",
        "    resid_v_mass_med(path='output/merged_params_cut.txt',\n",
        "                     title='Hubble Residual v. Host Stellar Mass of CSP-ATLAS-ZTF 91bg-like SNe Ia [SALT3-SNooPy]',\n",
        "                     save_loc='saved/readme_plots/merged_resid_v_mass.png')\n",
        "    resid_v_mass_med(path='txts/norm_10-11-24/normSNe_merged_10-11-24.txt',\n",
        "                     title='Hubble Residual v. Host Stellar Mass of Normal SNe Ia from CSP [SNooPy]',\n",
        "                     save_loc='saved/readme_plots/normIa_resid_v_mass.png')\n",
        "\n",
        "    # Update Redshift Plots\n",
        "    resid_v_z(path='output/combiend__snpy_params_cut.txt',\n",
        "              title='Hubble Residual v. CMB Redshift of CSP-ATLAS-ZTF 91bg-like SNe Ia [SNooPy]',\n",
        "              save_loc='saved/readme_plots/csp-atlas-ztf_snpy_resid_v_z.png')\n",
        "    resid_v_z(path='output/combiend__salt_params_cut.txt',\n",
        "              title='Hubble Residual v. CMB Redshift of CSP-ATLAS-ZTF 91bg-like SNe Ia [SALT3]',\n",
        "              save_loc='saved/readme_plots/csp-atlas-ztf_salt_resid_v_z.png')\n",
        "    resid_v_z(path='output/merged_params_cut.txt',\n",
        "              title='Hubble Residual v. CMB Redshift of CSP-ATLAS-ZTF 91bg-like SNe Ia [SALT3-SNooPy]',\n",
        "              save_loc='saved/readme_plots/merged_resid_v_z.png')\n",
        "\n",
        "    # Update Histograms\n",
        "    snpy_hist('output/combiend__snpy_params_cut.txt',\n",
        "              'txts/norm_10-11-24/normSNe_snpy_10-11-24.txt',\n",
        "              save_loc='saved/readme_plots/snpy_params_hicat_v_dr3.png')\n",
        "    salt_hist('output/combiend__salt_params_cut.txt',\n",
        "              'txts/norm_10-11-24/normSNe_salt_10-11-24.txt',\n",
        "              save_loc='saved/readme_plots/salt_params_hicat_v_dr3.png')\n",
        "    return"
      ],
      "metadata": {
        "id": "OVg6UYB6AP92"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysis Functions ------------------------------------------------------------------------------------------------ #\n",
        "def mass_step_calc(mu, mu_err, mass, z, cut=10):\n",
        "    if cut == 'median':\n",
        "        cut = round(np.median(mass), 4)\n",
        "\n",
        "    resid = mu - gen.current_cosmo().distmod(z).value\n",
        "\n",
        "    upper_resid = np.average(resid[mass > cut], weights=(1/(mu_err[mass > cut]**2)))\n",
        "    lower_resid = np.average(resid[mass < cut], weights=(1/(mu_err[mass < cut]**2)))\n",
        "\n",
        "    upper_resid_err = np.std(mu_err[mass > cut]) / np.sqrt(len(mu_err[mass > cut]))  # Using Standard Error Calc\n",
        "    lower_resid_err = np.std(mu_err[mass < cut]) / np.sqrt(len(mu_err[mass < cut]))\n",
        "\n",
        "    mass_step = np.abs(upper_resid - lower_resid)\n",
        "    mass_step_err = np.sqrt((lower_resid_err**2) + (upper_resid_err**2))\n",
        "\n",
        "\n",
        "    return ({'value': mass_step, 'err': mass_step_err},\n",
        "            {'lower_resid': {'value': lower_resid, 'err': lower_resid_err},\n",
        "             'upper_resid': {'value': upper_resid, 'err': upper_resid_err}})\n",
        "def dataset_analysis():\n",
        "    for d_set in ['CSP', 'ATLAS', 'ZTF', 'COMBINED']:\n",
        "        n_overlap = 0\n",
        "        all_names, all_z, all_dec, avg_mag, avg_mag_err = [], [], [], [], []\n",
        "        for algo in ['snpy', 'salt']:\n",
        "            if algo == 'snpy':\n",
        "                t_type = 'Tmax'\n",
        "            else:\n",
        "                t_type = 't0'\n",
        "            sys.stdout = open(os.devnull, 'w')  # unnecessary output\n",
        "            SNe = batch_load(d_set, algo)\n",
        "            sys.stdout = sys.__stdout__\n",
        "\n",
        "            for SN in SNe:\n",
        "                if SN.objname not in all_names:\n",
        "                    if d_set == 'COMBINED' and SN.origin == 'ATLAS-ZTF':\n",
        "                        n_overlap += 1\n",
        "                    all_names.append(SN.objname)\n",
        "                    all_z.append(SN.z_cmb)\n",
        "                    all_dec.append(SN.coords[1])\n",
        "                    avg_mag.append(np.average(SN.mag))\n",
        "                    time_clipped_dmag = SN.dmag[(SN.time > SN.params[t_type]['value']-5) & (SN.time < SN.params[t_type]['value']+5)]\n",
        "                    if len(time_clipped_dmag) != 0:\n",
        "                        avg_mag_err.append(np.average(time_clipped_dmag))\n",
        "\n",
        "        # print('Number of SNe | Redshift | Declination | Average Mag. | Average Mag. Err (+/-5 MJD)')\n",
        "        print(d_set, '&', '$'+str(len(all_names))+'$', '&',\n",
        "              '$' + str(round(np.min(all_z), 4))+'$ - $'+str(round(np.max(all_z), 4))+'$', '&',\n",
        "              '$' + str(round(np.min(all_dec), 6))+'$ - $'+str(round(np.max(all_dec), 6))+'$', '&',\n",
        "              '$' + str(round(np.min(avg_mag), 6)) + '$ - $' + str(round(np.max(avg_mag), 6)) + '$', '&',\n",
        "              '$' + str(round(np.min(avg_mag_err), 6)) + '$ - $' + str(round(np.max(avg_mag_err), 6)) + '$\\\\\\\\')\n",
        "        if d_set == 'COMBINED':\n",
        "            print('COMBINED Overlap:', n_overlap)\n",
        "    return"
      ],
      "metadata": {
        "id": "l0RuneQp_XvE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Smart Fit Functions ----------------------------------------------------------------------------------------------- #\n",
        "def smart_fit_help():\n",
        "    \"\"\"\n",
        "    Call to get examples of calls for smart_fit()\n",
        "    \"\"\"\n",
        "    print('===========================================================================================================')\n",
        "    print('Ex. Individual:', \"smart_fit(fit_type='indv', data_set='CSP', algo='snpy', path='data/CSP/SN2005ke_snpy.txt')\")\n",
        "    print('------')\n",
        "    print('Ex. Batch:', \"smart_fit(fit_type='batch', data_set='CSP', algo='snpy')\")\n",
        "    print('------')\n",
        "    print('Ex. Combined:', \"smart_fit(fit_type='combiend', algo='snpy', dmag_max=1.00)\")\n",
        "    print('===========================================================================================================')\n",
        "    return\n",
        "def smart_fit(fit_type, data_set='', algo='', path=None, save_loc='', dmag_max=0.00, dflux_max=0.00):\n",
        "    \"\"\"\n",
        "    A function to easily fit data using both algorithms.\n",
        "    :param fit_type: [str] type of fitting protocol to use\n",
        "    :param data_set: Default: 'CSP', [str] name of data set\n",
        "    :param algo: [str] Default: 'snpy', algorithms to fit data with (snpy/salt)\n",
        "    :param path: [str] Default: None, data location for individual fits (only call for fit_type='indv')\n",
        "    :param save_loc: [str] location to save parameter data of SNe fits\n",
        "    :param dmag_max: [float] Default: 0, magnitude error cut off for taking in data\n",
        "    :param dflux_max: [float] Default: 0,  flux error cut off for taking in data\n",
        "    :return: SN [list], Array of sn91bg() classes from fitting call. Returns list of 'None' if unsuccessful.\n",
        "    \"\"\"\n",
        "    fit_type = fit_type.lower()\n",
        "    if fit_type == 'indv':\n",
        "        tempSN = SN91bg().make_class(data_set=data_set, path=path, dmag_max=dmag_max, dflux_max=dflux_max)\n",
        "        tempSN.fit(algo)\n",
        "        SNe = [tempSN]\n",
        "        if SNe[0] is None:\n",
        "            print('[!!!] Fit failed!')\n",
        "            return [None]\n",
        "    elif fit_type == 'batch':\n",
        "        SNe = batch_fit(data_set, algo=algo,\n",
        "                        dmag_max=dmag_max, dflux_max=dflux_max)\n",
        "    elif fit_type == 'combiend':\n",
        "        SNe = combined_fit(algo=algo,\n",
        "                           dmag_max=dmag_max, dflux_max=dflux_max)\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            \"Invalid type selected ['indv'/'batch'/'combined']\")\n",
        "\n",
        "    # Saving\n",
        "    if fit_type != 'indv' and len(SNe) != 0:\n",
        "        if len(save_loc) == 0:\n",
        "            save_loc = 'output/'+fit_type+'_'+data_set.lower()+'_'+algo+'_'+'params.txt'\n",
        "        save_params_to_file(save_loc, SNe)  # Save params\n",
        "        sample_cutter(save_loc, algo)  # Cut sample\n",
        "    return SNe"
      ],
      "metadata": {
        "id": "yjj8qhIR_UTy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    start = systime.time()  # Runtime tracker\n",
        "\n",
        "    # update_readme_plots()\n",
        "\n",
        "    print('|---------------------------|\\n Run-time: ', round(systime.time() - start, 4), 'seconds\\n|---------------------------|')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUzIc_DX_S82",
        "outputId": "b0071671-7338-4df2-d621-f26a4c5bcd8a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|---------------------------|\n",
            " Run-time:  0.0 seconds\n",
            "|---------------------------|\n"
          ]
        }
      ]
    }
  ]
}